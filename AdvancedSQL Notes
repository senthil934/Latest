JSON function

JSON functions in Oracle are extensively used in real-time scenarios where structured and semi-structured data need to be managed, queried, and processed efficiently.
For example, 
1. a customer data table can store JSON to handle dynamic fields like preferences, settings, or metadata.

INSERT INTO customers (id, details)
VALUES (1, '{"name": "Alice", "preferences": {"theme": "dark", "language": "en"}}');

2. Modern applications frequently integrate with RESTful APIs that exchange data in JSON format. JSON functions in Oracle allow for seamless ingestion, querying, and transformation of API data.

Example: Storing API responses in Oracle for analytics.
INSERT INTO api_logs (response)
VALUES ('{"status": "success", "data": {"id": 123, "name": "Alice"}}');

3. E-commerce platforms often deal with products that have varying attributes. 
INSERT INTO products (product_id, attributes)
VALUES (1, '{"name": "Smartphone", "specs": {"RAM": "8GB", "Storage": "128GB"}}');

4. IoT devices generate large amounts of semi-structured JSON data. 
INSERT INTO sensor_data (device_id, readings)
VALUES (101, '{"temperature": 22.5, "humidity": 60}');

5. JSON is ideal for storing application logs, system events, or audit trails. These logs can then be queried for troubleshooting or analysis.

INSERT INTO app_logs (log_id, log_details)
VALUES (1, '{"timestamp": "2025-01-01T12:00:00Z", "level": "error", "message": "Database timeout"}');

1. Table Schema
We create a table named EMPLOYEE_DETAILS to store employee information, including JSON data.

Table Schema:
CREATE TABLE EMPLOYEE_DETAILS (
    EMP_ID NUMBER PRIMARY KEY,
    NAME VARCHAR2(100),
    JSON_DATA CLOB CHECK (JSON_DATA IS JSON)
);

2. Insert Sample Data
We insert JSON data into the JSON_DATA column.

INSERT INTO EMPLOYEE_DETAILS (EMP_ID, NAME, JSON_DATA) VALUES 
(101, 'Alice', '{"department": "HR", "skills": ["Recruitment", "Payroll"], "salary": 70000, "location": "NY"}');

INSERT INTO EMPLOYEE_DETAILS (EMP_ID, NAME, JSON_DATA) VALUES 
(102, 'Bob', '{"department": "IT", "skills": ["Java", "SQL", "Python"], "salary": 85000, "location": "LA"}');

INSERT INTO EMPLOYEE_DETAILS (EMP_ID, NAME, JSON_DATA) VALUES 
(103, 'Charlie', '{"department": "Finance", "skills": ["Accounting", "Excel"], "salary": 75000, "location": "SF"}');


3. Querying JSON Data
A. Extracting a Single Value (JSON_VALUE)
The JSON_VALUE function retrieves scalar values from JSON data.

Query: Get employee names along with their departments.

SELECT 
    EMP_ID,
    NAME,
    JSON_VALUE(JSON_DATA, '$.department') AS DEPARTMENT
FROM EMPLOYEE_DETAILS;

Output:

EMP_ID	NAME	DEPARTMENT
101	Alice	HR
102	Bob	IT
103	Charlie	Finance

B. Extracting Nested Array Data (JSON_TABLE)
The JSON_TABLE function extracts data from JSON arrays.

Query: List all skills of each employee.

SELECT 
    EMP_ID,
    NAME,
    jt.skill
FROM EMPLOYEE_DETAILS,
    JSON_TABLE(
        JSON_DATA,
        '$.skills[*]' COLUMNS(skill VARCHAR2(50) PATH '$')
    ) jt;

Output:

EMP_ID	NAME	SKILL
101	Alice	Recruitment
101	Alice	Payroll
102	Bob	Java
102	Bob	SQL
102	Bob	Python
103	Charlie	Accounting
103	Charlie	Excel

C. Checking Key Existence (JSON_EXISTS)
The JSON_EXISTS function checks if a specific key exists in JSON data.

Query: Find employees with a location key in their JSON data.

SELECT 
    EMP_ID,
    NAME
FROM EMPLOYEE_DETAILS
WHERE JSON_EXISTS(JSON_DATA, '$.location');

Output:

EMP_ID	NAME
101	Alice
102	Bob
103	Charlie

5. Aggregating JSON Data
A. Create a JSON Array from Rows (JSON_ARRAYAGG)
The JSON_ARRAYAGG function aggregates rows into a JSON array.

Query: Get a JSON array of all employee names.

SELECT JSON_ARRAYAGG(NAME) AS EMPLOYEE_NAMES
FROM EMPLOYEE_DETAILS;

Output:

EMPLOYEE_NAMES
["Alice", "Bob", "Charlie"]

CREATE TABLE STUDENTS (
    STUDENT_ID   NUMBER PRIMARY KEY,      -- Unique ID for each student
    STUDENT_NAME VARCHAR2(100) NOT NULL, -- Name of the student
    COURSE       VARCHAR2(50) NOT NULL,  -- Course the student is enrolled in
    GRADE        CHAR(1) CHECK (GRADE IN ('A', 'B', 'C', 'D', 'F')) -- Grade received (A-F)
);

INSERT INTO STUDENTS (STUDENT_ID, STUDENT_NAME, COURSE, GRADE) 
VALUES (1, 'Alice Johnson', 'Math', 'A');

INSERT INTO STUDENTS (STUDENT_ID, STUDENT_NAME, COURSE, GRADE) 
VALUES (2, 'Bob Smith', 'Science', 'B');

INSERT INTO STUDENTS (STUDENT_ID, STUDENT_NAME, COURSE, GRADE) 
VALUES (3, 'Charlie Brown', 'Math', 'B');

INSERT INTO STUDENTS (STUDENT_ID, STUDENT_NAME, COURSE, GRADE) 
VALUES (4, 'Daisy Carter', 'Science', 'A');


SELECT 
    COURSE,
    JSON_ARRAYAGG(
        JSON_OBJECT(
            'STUDENT_ID' VALUE STUDENT_ID,
            'STUDENT_NAME' VALUE STUDENT_NAME,
            'GRADE' VALUE GRADE
        )
    ) AS STUDENT_DETAILS_JSON
FROM STUDENTS
GROUP BY COURSE;

Explanation:
JSON_ARRAYAGG:

Aggregates rows into a JSON array.
Each row represents a student within a COURSE.
JSON_OBJECT:

Converts each row into a JSON object with key-value pairs (STUDENT_ID, STUDENT_NAME, and GRADE).
GROUP BY COURSE:

Groups the data by the COURSE column, so each COURSE gets its own JSON array of students.

------------------------------------------------------------------------------------

B. Create JSON Objects (JSON_OBJECTAGG)
The JSON_OBJECTAGG function creates a JSON object from key-value pairs.

CREATE TABLE EMPLOYEES (
    EMP_ID   NUMBER PRIMARY KEY,      -- Unique ID for each employee
    EMP_NAME VARCHAR2(100) NOT NULL, -- Name of the employee
    SALARY   NUMBER NOT NULL         -- Salary of the employee
);

INSERT INTO EMPLOYEES (EMP_ID, EMP_NAME, SALARY) 
VALUES (101, 'John Doe', 60000);

INSERT INTO EMPLOYEES (EMP_ID, EMP_NAME, SALARY) 
VALUES (102, 'Jane Smith', 75000);

INSERT INTO EMPLOYEES (EMP_ID, EMP_NAME, SALARY) 
VALUES (103, 'Alice Johnson', 50000);

1. Use JSON_OBJECTAGG to generate a single JSON object where EMP_ID is the key and other details are the value.

SELECT 
    JSON_OBJECTAGG(
        EMP_ID VALUE JSON_OBJECT(
            'EMP_NAME' VALUE EMP_NAME,
            'SALARY' VALUE SALARY
        )
    ) AS EMPLOYEES_JSON
FROM EMPLOYEES;

Query: Create a JSON object with employee names as keys and their departments as values.

SELECT JSON_OBJECTAGG(NAME VALUE JSON_VALUE(JSON_DATA, '$.department')) AS EMPLOYEE_DEPARTMENTS
FROM EMPLOYEE_DETAILS;

Output:

EMPLOYEE_DEPARTMENTS
{"Alice": "HR", "Bob": "IT", "Charlie": "Finance"}

6. Generating JSON from Columns
A. Generate JSON Object (JSON_OBJECT)
The JSON_OBJECT function creates JSON objects from column values.

Query: Create a JSON object for each employee.

SELECT 
    JSON_OBJECT(
        'EmployeeID' VALUE EMP_ID,
        'Name' VALUE NAME,
        'Details' VALUE JSON_DATA
    ) AS EMPLOYEE_JSON
FROM EMPLOYEE_DETAILS;

Output:

EMPLOYEE_JSON
{"EmployeeID": 101, "Name": "Alice", "Details": {"department": "HR", "skills": ["Recruitment"...}

7. Full Example for Complex Data Extraction
Query: Find employees with a salary above 75000 and list their skills.

SELECT 
    EMP_ID,
    NAME,
    JSON_VALUE(JSON_DATA, '$.salary') AS SALARY,
    jt.skill
FROM EMPLOYEE_DETAILS,
    JSON_TABLE(
        JSON_DATA,
        '$.skills[*]' COLUMNS(skill VARCHAR2(50) PATH '$')
    ) jt
WHERE JSON_VALUE(JSON_DATA, '$.salary') > 75000;

Output:

EMP_ID	NAME	SALARY	SKILL
102	Bob	90000	Java
102	Bob	90000	SQL
102	Bob	90000	Python


------------------------------------------------------------------------------------------
1. Complex Table Schema
We create a table called PROJECTS to store information about projects, team members, and their roles, with a nested JSON structure.

Table Schema:
CREATE TABLE PROJECTS (
    PROJECT_ID NUMBER PRIMARY KEY,
    PROJECT_NAME VARCHAR2(100),
    DETAILS CLOB CHECK (DETAILS IS JSON)
);

2. Insert Complex JSON Data
We insert nested JSON data with information about team members, their roles, tasks, and deadlines.

INSERT INTO PROJECTS (PROJECT_ID, PROJECT_NAME, DETAILS) VALUES 
(1, 'Apollo Mission', '{
    "team": [
        {"membername": "Alice", "role": "Manager", "tasks": [{"task": "Planning", "deadline": "2025-03-01"}, {"task": "Budget Approval", "deadline": "2025-02-15"}]},
        {"membername": "Bob", "role": "Engineer", "tasks": [{"task": "Design", "deadline": "2025-04-01"}]},
        {"membername": "Charlie", "role": "QA", "tasks": [{"task": "Testing", "deadline": "2025-05-01"}]}
    ],
    "budget": 500000,
    "status": "In Progress"
}');

INSERT INTO PROJECTS (PROJECT_ID, PROJECT_NAME, DETAILS) VALUES 
(2, 'Mars Rover', '{
    "team": [
        {"membername": "Diana", "role": "Scientist", "tasks": [{"task": "Research", "deadline": "2025-06-01"}]},
        {"membername": "Evan", "role": "Engineer", "tasks": [{"task": "Development", "deadline": "2025-07-15"}, {"task": "Integration", "deadline": "2025-08-01"}]},
        {"membername": "Frank", "role": "Manager", "tasks": [{"task": "Logistics", "deadline": "2025-05-15"}]}
    ],
    "budget": 750000,
    "status": "Planned"
}');

3. Querying and Transforming Data
A. Extract Nested Data Using JSON_TABLE
Query: List all tasks along with their deadlines and the assigned team member for all projects.

SELECT 
    PROJECT_NAME,
    jt.membername AS TEAM_MEMBER,
    jt.task AS TASK_NAME,
   jt.deadline AS DEADLINE
FROM PROJECTS,
    JSON_TABLE(
        DETAILS,
        '$.team[*]' 
        COLUMNS (
            membername VARCHAR2(100) PATH '$.membername',
            NESTED PATH '$.tasks[*]' COLUMNS (
                task VARCHAR2(100) PATH '$.task',
                deadline DATE PATH '$.deadline'
            )
        )
    ) jt;

Output:

PROJECT_NAME	TEAM_MEMBER	TASK_NAME	DEADLINE
Apollo Mission	Alice	Planning	2025-03-01
Apollo Mission	Alice	Budget Approval	2025-02-15
Apollo Mission	Bob	Design	2025-04-01
Apollo Mission	Charlie	Testing	2025-05-01
Mars Rover	Diana	Research	2025-06-01
Mars Rover	Evan	Development	2025-07-15
Mars Rover	Evan	Integration	2025-08-01
Mars Rover	Frank	Logistics	2025-05-15

Explanation of the Changes:
NESTED PATH: The NESTED PATH clause allows us to process the tasks array for each team member directly within the same JSON_TABLE expression.

We specify the $.tasks[*] path to extract the task and deadline fields from the nested tasks array for each team member.

Breakdown:
Main JSON_TABLE:
The outer JSON_TABLE extracts team member information (membername) from the $.team[*] path in the JSON document.

Nested JSON_TABLE:
The NESTED PATH clause inside the same JSON_TABLE extracts the task and deadline from the $.tasks[*] path.

B. Aggregate Data Using JSON_ARRAYAGG and JSON_OBJECTAGG
Query: Create a JSON array of all project names and their statuses.

SELECT JSON_ARRAYAGG(
    JSON_OBJECT(
        'ProjectName' VALUE PROJECT_NAME,
        'Status' VALUE JSON_VALUE(DETAILS, '$.status')
    )
) AS PROJECT_SUMMARY
FROM PROJECTS;

Output:

PROJECT_SUMMARY
[{"ProjectName":"Apollo Mission","Status":"In Progress"},{"ProjectName":"Mars Rover","Status":"Planned"}]

C. Filter Data Using JSON_EXISTS
Query: Find all projects where at least one team member has a task deadline in 2025-05.

SELECT PROJECT_NAME
FROM PROJECTS
WHERE JSON_EXISTS(DETAILS, '$.team[*].tasks[*]?(@.deadline like "2025-05%")');

Output:

PROJECT_NAME
Apollo Mission
Mars Rover

-------------------------------------------------------------------------------------------------------------------------------------------------------------

JSON_SCALAR Function in Oracle
In Oracle, the JSON_SCALAR function is used to extract a scalar value (such as a string, number, or boolean) from a JSON document stored in a CLOB or BLOB column. 

Oracle's JSON_SCALAR function isn't supported in Oracle Database versions before 12c, and even in Oracle 12c onwards, it may require additional configuration or syntax. In fact, the correct function to extract a scalar value from JSON in Oracle is typically json_value rather than JSON_SCALAR.

Correct Function: json_value
In Oracle, the json_value function is the correct way to extract scalar values from JSON data stored in a CLOB, VARCHAR2, or BLOB column.

1. Table Schema and Sample Data
Let's create a table called CUSTOMERS_JSON that contains a JSON column to store customer information in JSON format.

Table Schema: CUSTOMERS_JSON

CREATE TABLE CUSTOMERS_JSON (
    CUSTOMER_ID NUMBER PRIMARY KEY,
    CUSTOMER_NAME VARCHAR2(100),
    CUSTOMER_JSON CLOB
);

Insert Sample Data into CUSTOMERS_JSON
We will insert some sample customer data in JSON format into the CUSTOMERS_JSON table.

-- Sample data for CUSTOMERS_JSON table
INSERT INTO CUSTOMERS_JSON (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (1, 'John Doe', '{"customer_id": 1, "name": "John Doe", "email": "john.doe@example.com", "address": {"street": "123 Main St", "city": "New York"}}');

INSERT INTO CUSTOMERS_JSON (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (2, 'Jane Smith', '{"customer_id": 2, "name": "Jane Smith", "email": "jane.smith@domain.com", "address": {"street": "456 Oak St", "city": "Los Angeles"}}');

INSERT INTO CUSTOMERS_JSON (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (3, 'Michael Johnson', '{"customer_id": 3, "name": "Michael Johnson", "email": "michael.johnson@example.net", "address": {"street": "789 Pine St", "city": "Chicago"}}');

INSERT INTO CUSTOMERS_JSON (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (4, 'Emily Davis', '{"customer_id": 4, "name": "Emily Davis", "email": "emily.davis@domain.org", "address": {"street": "101 Maple St", "city": "San Francisco"}}');

In this case, the CUSTOMER_JSON column stores a JSON document representing each customer's information, including their customer_id, name, email, and address (which itself contains street and city).

SELECT CUSTOMER_ID, CUSTOMER_NAME,
       JSON_VALUE(CUSTOMER_JSON, '$.name') AS CUSTOMER_NAME_JSON
FROM CUSTOMERS_JSON;

SELECT CUSTOMER_ID, CUSTOMER_NAME,
       JSON_VALUE(CUSTOMER_JSON, '$.email') AS CUSTOMER_EMAIL_JSON
FROM CUSTOMERS_JSON;


SELECT CUSTOMER_ID, CUSTOMER_NAME,
       JSON_VALUE(CUSTOMER_JSON, '$.address.street') AS CUSTOMER_STREET_JSON,
       JSON_VALUE(CUSTOMER_JSON, '$.address.city') AS CUSTOMER_CITY_JSON
FROM CUSTOMERS_JSON;

SELECT CUSTOMER_ID, CUSTOMER_NAME,
       JSON_VALUE(CUSTOMER_JSON, '$.customer_id') AS CUSTOMER_ID_JSON
FROM CUSTOMERS_JSON;

------------------------------------------------------------------------------------------------------------------------------------------------------


JSON_QUERY Function in Oracle
The JSON_QUERY function in Oracle is used to extract an entire JSON object or array from a JSON document. Unlike JSON_SCALAR, which returns scalar values (like strings or numbers), JSON_QUERY can return JSON objects or arrays as a result.

Syntax

JSON_QUERY(json_expression, json_path)

json_expression: The JSON document or column containing JSON data.
json_path: The JSON path expression used to specify the part of the JSON document you want to extract.


Example 1: Extract the Entire Address Object from JSON
We will extract the address object from the JSON document using JSON_QUERY.

SELECT CUSTOMER_ID, CUSTOMER_NAME,
       JSON_QUERY(CUSTOMER_JSON, '$.address') AS CUSTOMER_ADDRESS_JSON
FROM CUSTOMERS_JSON;


Example 3: Extract an Array of Customer Names
You can use JSON_QUERY to extract arrays from a JSON document. Let's assume the CUSTOMER_JSON column has an array of phone numbers for each customer. We'll create a new version of the JSON data with an array of phone numbers for each customer.

First, let's modify the data and add phone numbers.

-- Adding an array of phone numbers to the customer JSON data

UPDATE CUSTOMERS_JSON
SET CUSTOMER_JSON = '{"customer_id": 1, "name": "John Doe", "email": "john.doe@example.com", "address": {"street": "123 Main St", "city": "New York"}, "phone_numbers": ["123-456-7890", "987-654-3210"]}'
WHERE CUSTOMER_ID = 1;

UPDATE CUSTOMERS_JSON
SET CUSTOMER_JSON = '{"customer_id": 2, "name": "Jane Smith", "email": "jane.smith@domain.com", "address": {"street": "456 Oak St", "city": "Los Angeles"}, "phone_numbers": ["555-123-4567"]}'
WHERE CUSTOMER_ID = 2;

UPDATE CUSTOMERS_JSON
SET CUSTOMER_JSON = '{"customer_id": 3, "name": "Michael Johnson", "email": "michael.johnson@example.net", "address": {"street": "789 Pine St", "city": "Chicago"}, "phone_numbers": ["444-555-6666", "333-444-5555"]}'
WHERE CUSTOMER_ID = 3;

Now, we will use JSON_QUERY to extract the phone_numbers array.

SELECT CUSTOMER_ID, CUSTOMER_NAME,
       JSON_QUERY(CUSTOMER_JSON, '$.phone_numbers') AS CUSTOMER_PHONE_NUMBERS_JSON
FROM CUSTOMERS_JSON;

Explanation:

$.phone_numbers: This JSON path expression extracts the entire phone_numbers array from the JSON document.

Output:

CUSTOMER_ID	CUSTOMER_NAME	CUSTOMER_PHONE_NUMBERS_JSON
1	John Doe	["123-456-7890", "987-654-3210"]
2	Jane Smith	["555-123-4567"]
3	Michael Johnson	["444-555-6666", "333-444-5555"]

In this case, JSON_QUERY returns the phone_numbers array for each customer.

----------------------------------------------------------------------------------------------------------------------------------------------------
ISJSON Function in Oracle
The ISJSON function in Oracle is used to check if a given string or column contains valid JSON data. It returns a boolean result: TRUE if the input is a valid JSON document and FALSE otherwise.

This function is useful when you need to validate whether a column or string contains well-formed JSON data before performing JSON-related operations.

Syntax

ISJSON(expression)

expression: The input expression (column, string, etc.) to check for valid JSON. This can be a string or a column of type CLOB or VARCHAR.

1. Table Schema and Sample Data
Let's create a table CUSTOMERS_JSON_VALID that stores customer data in JSON format. We'll add a column that will store JSON data as well as a column to store customer names.

Table Schema: CUSTOMERS_JSON_VALID

CREATE TABLE CUSTOMERS_JSON_VALID (
    CUSTOMER_ID NUMBER PRIMARY KEY,
    CUSTOMER_NAME VARCHAR2(100),
    CUSTOMER_JSON CLOB
);

Insert Sample Data into CUSTOMERS_JSON_VALID
We'll insert both valid and invalid JSON data into the CUSTOMER_JSON column.

-- Valid JSON data
INSERT INTO CUSTOMERS_JSON_VALID (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (1, 'John Doe', '{"customer_id": 1, "name": "John Doe", "email": "john.doe@example.com"}');

-- Invalid JSON data (missing closing brace)
INSERT INTO CUSTOMERS_JSON_VALID (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (2, 'Jane Smith', '{"customer_id": 2, "name": "Jane Smith", "email": "jane.smith@domain.com"');

-- Valid JSON data
INSERT INTO CUSTOMERS_JSON_VALID (CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON)
VALUES (3, 'Michael Johnson', '{"customer_id": 3, "name": "Michael Johnson", "email": "michael.johnson@example.net"}');

In this example:

Valid JSON: The first and third entries have valid JSON.
Invalid JSON: The second entry has invalid JSON because it has a missing closing brace.

2. Using ISJSON to Check for Valid JSON
Now, we will use the ISJSON function to check whether the data in the CUSTOMER_JSON column is valid JSON.

Example 1: Check if CUSTOMER_JSON is Valid JSON

SELECT CUSTOMER_ID, CUSTOMER_NAME,
       CUSTOMER_JSON IS JSON AS IS_VALID_JSON
FROM CUSTOMERS_JSON_VALID;

Explanation:

The query checks each CUSTOMER_JSON value to see if it's valid JSON.

The ISJSON function returns TRUE for valid JSON and FALSE for invalid JSON.

Output:

CUSTOMER_ID	CUSTOMER_NAME	IS_VALID_JSON
1	John Doe	TRUE
2	Jane Smith	FALSE
3	Michael Johnson	TRUE

In this case, the second row has invalid JSON (missing closing brace), so ISJSON returns FALSE for it.

Example 2: Filter Only Valid JSON Data
You can use the ISJSON function in a WHERE clause to filter rows that contain valid JSON.

SELECT CUSTOMER_ID, CUSTOMER_NAME, CUSTOMER_JSON
FROM CUSTOMERS_JSON_VALID
WHERE CUSTOMER_JSON IS JSON = TRUE;

Explanation:

The query filters rows where the CUSTOMER_JSON column contains valid JSON.

Output:

CUSTOMER_ID	CUSTOMER_NAME	CUSTOMER_JSON
1	John Doe	{"customer_id": 1, "name": "John Doe", "email": "john.doe@example.com"}
3	Michael Johnson	{"customer_id": 3, "name": "Michael Johnson", "email": "michael.johnson@example.net"}

Only rows with valid JSON are returned in the result.


-------------------------------------------------------------------------------------------
In Oracle, you can modify JSON data using the JSON_TRANSFORM function, introduced in Oracle 21c. This function allows you to update, add, or remove elements within a JSON document. Here's a detailed example of how to use it, including schema creation, inserting data, and updating JSON using JSON_TRANSFORM.

1. Table Schema and Sample Data
Create a Table with a JSON Column

CREATE TABLE employees1 (
    id NUMBER PRIMARY KEY,
    details CLOB CHECK (details IS JSON)
);

Insert Sample Data

INSERT INTO employees1 (id, details) VALUES (1, '{"name": "Alice", "age": 30, "address": {"city": "New York", "zip": "10001"}}');

INSERT INTO employees1(id, details) VALUES (2, '{"name": "Bob", "age": 25, "address": {"city": "San Francisco", "zip": "94105"}}');

2. Example Queries with JSON_TRANSFORM
a. Update a Value in the JSON
Modify the age of an employee:

UPDATE employees1
SET details = JSON_TRANSFORM(details, SET '$.age' = 31)
WHERE id = 1;

-- Verify the change
SELECT details FROM employees1 WHERE id = 1;
-- Output: {"name": "Alice", "age": 31, "address": {"city": "New York", "zip": "10001"}}

b. Add a New Key-Value Pair
Add a department key to the JSON:

UPDATE employees1
SET details = JSON_TRANSFORM(details, SET '$.department' = 'HR')
WHERE id = 1;

-- Verify the change
SELECT details FROM employees1 WHERE id = 1;
-- Output: {"name": "Alice", "age": 31, "address": {"city": "New York", "zip": "10001"}, "department": "HR"}

c. Remove a Key from the JSON
Remove the address key:

UPDATE employees1
SET details = JSON_TRANSFORM(details, REMOVE '$.address')
WHERE id = 2;

-- Verify the change
SELECT details FROM employees1 WHERE id = 2;
-- Output: {"name": "Bob", "age": 25}

d. Modify Nested JSON
Update the city inside the address object:

UPDATE employees1
SET details = JSON_TRANSFORM(details, SET '$.address.city' = 'Los Angeles')
WHERE id = 1;

-- Verify the change
SELECT details FROM employees1 WHERE id = 1;

-- Output: {"name": "Alice", "age": 31, "address": {"city": "Los Angeles", "zip": "10001"}, "department": "HR"}

e. Add an Array to the JSON
Add a new key skills as an array:

UPDATE employees1
SET details = JSON_TRANSFORM(details, SET '$.skills' = JSON_ARRAY('SQL', 'PL/SQL'))
WHERE id = 1;

-- Verify the change
SELECT details FROM employees1 WHERE id = 1;
-- Output: {"name": "Alice", "age": 31, "address": {"city": "Los Angeles", "zip": "10001"}, "department": "HR", "skills": ["SQL", "PL/SQL"]}

f. Append to an Array
Add a new skill to the skills array:

UPDATE employees1
SET details = JSON_TRANSFORM(details, APPEND '$.skills' = 'Python')
WHERE id = 1;

-- Verify the change
SELECT details FROM employees1 WHERE id = 1;

-- Output: {"name": "Alice", "age": 31, "address": {"city": "Los Angeles", "zip": "10001"}, "department": "HR", "skills": ["SQL", "PL/SQL", "Python"]}

3. Example: Retrieve Data
Retrieve specific elements from the modified JSON:

-- Retrieve the updated age
SELECT JSON_VALUE(details, '$.age') AS age FROM employees1 WHERE id = 1;

-- Retrieve the list of skills
SELECT JSON_QUERY(details, '$.skills') AS skills FROM employees1 WHERE id = 1;

-----------------------------------------------------------------------------------------------
In Oracle, there isn't a direct equivalent to SQL Server's OPENJSON function, which is used to parse JSON and return it as a relational result set. However, Oracle provides a similar functionality using the JSON_TABLE function, which maps JSON data to relational rows and columns.

Here’s an example of how to use JSON_TABLE in Oracle to achieve what OPENJSON does in SQL Server:

1. Table Schema and Sample Data
Create a Table with JSON Data

CREATE TABLE orders (
    id NUMBER PRIMARY KEY,
    order_details CLOB CHECK (order_details IS JSON)
);

Insert Sample Data

INSERT INTO orders (id, order_details) VALUES (1, '{"order_id": 101, "customer": "Alice", "items": [{"product": "Laptop", "price": 1200}, {"product": "Mouse", "price": 25}]}');

INSERT INTO orders (id, order_details) VALUES (2, '{"order_id": 102, "customer": "Bob", "items": [{"product": "Keyboard", "price": 50}, {"product": "Monitor", "price": 200}]}');

2. Using JSON_TABLE to Parse JSON
Extract JSON as Relational Data
Map JSON data from the order_details column to rows and columns:

SELECT *
FROM orders,
     JSON_TABLE(
         order_details,
         '$'
         COLUMNS (
             order_id NUMBER PATH '$.order_id',
             customer VARCHAR2(50) PATH '$.customer'
         )
     ) jt;

Output:

ID	ORDER_ID	CUSTOMER
1	101	Alice
2	102	Bob

3. Extract Nested JSON Data
Unnest JSON Arrays
Use JSON_TABLE to extract items within the items array as rows:

SELECT o.id AS order_id, jt.product, jt.price
FROM orders o,
     JSON_TABLE(
         o.order_details,
         '$.items[*]'
         COLUMNS (
             product VARCHAR2(50) PATH '$.product',
             price NUMBER PATH '$.price'
         )
     ) jt;
Output:

ORDER_ID	PRODUCT	PRICE
1	Laptop	1200
1	Mouse	25
2	Keyboard	50
2	Monitor	200

4. Combining Parent and Child Data
Retrieve parent-level data along with nested array data:

SELECT o.id AS order_id, jt.product, jt.price, jt.customer
FROM orders o,
     JSON_TABLE(
         o.order_details,
         '$'
         COLUMNS (
             customer VARCHAR2(50) PATH '$.customer',
             NESTED PATH '$.items[*]'
             COLUMNS (
                 product VARCHAR2(50) PATH '$.product',
                 price NUMBER PATH '$.price'
             )
         )
     ) jt;
Output:

ORDER_ID	CUSTOMER	PRODUCT	PRICE
1	Alice	Laptop	1200
1	Alice	Mouse	25
2	Bob	Keyboard	50
2	Bob	Monitor	200

5. Real-Time Scenarios
Scenario: Generate an Invoice Report
To create an invoice report showing the total amount for each order:


SELECT o.id AS order_id, jt.customer, SUM(jt.price) AS total_amount
FROM orders o,
     JSON_TABLE(
         o.order_details,
         '$'
         COLUMNS (
             customer VARCHAR2(50) PATH '$.customer',
             NESTED PATH '$.items[*]'
             COLUMNS (
                 price NUMBER PATH '$.price'
             )
         )
     ) jt
GROUP BY o.id, jt.customer;

Output:

ORDER_ID	CUSTOMER	TOTAL_AMOUNT
1	Alice	1225
2	Bob	250


------------------------------------------------------------------------------------------
In Oracle, JSON_TEXTCONTAINS is a condition used to search for a specific text string in a JSON document. It is especially useful for filtering rows where a JSON attribute contains a specific value.

Here’s an example demonstrating its use, including table creation, data insertion, and a query using JSON_TEXTCONTAINS:

1. Table Schema and Sample Data
Create a Table with JSON Data

CREATE TABLE products (
    id NUMBER PRIMARY KEY,
    product_details CLOB CHECK (product_details IS JSON)
);

Insert Sample Data

INSERT INTO products (id, product_details) 
VALUES (1, '{"name": "Laptop", "category": "Electronics", "specs": {"brand": "Dell", "color": "Black"}}');

INSERT INTO products (id, product_details) 
VALUES (2, '{"name": "Chair", "category": "Furniture", "specs": {"brand": "Ikea", "color": "Brown"}}');

INSERT INTO products (id, product_details) 
VALUES (3, '{"name": "Smartphone", "category": "Electronics", "specs": {"brand": "Apple", "color": "White"}}');

-To use JSON_TEXTCONTAINS(), create a JSON search index on the JSON column.

CREATE SEARCH INDEX products_json_idx
ON products (product_details)
FOR JSON;

2. Query Using JSON_TEXTCONTAINS
a. Search for a Specific Text in JSON
Find all products in the "Electronics" category:

SELECT id, product_details
FROM products
WHERE JSON_TEXTCONTAINS(product_details, '$.category', 'Electronics');

Output:

ID	PRODUCT_DETAILS
1	{"name": "Laptop", "category": "Electronics", "specs": {"brand": "Dell", "color": "Black"}}
3	{"name": "Smartphone", "category": "Electronics", "specs": {"brand": "Apple", "color": "White"}}

b. Search for Nested JSON Attributes
Find all products where the brand is "Apple":

SELECT id, product_details
FROM products
WHERE JSON_TEXTCONTAINS(product_details, '$.specs.brand', 'Apple');

Output:

ID	PRODUCT_DETAILS
3	{"name": "Smartphone", "category": "Electronics", "specs": {"brand": "Apple", "color": "White"}}

c. Search with Case-Insensitive Matching
By default, JSON_TEXTCONTAINS is case-sensitive. To perform a case-insensitive search, use the UPPER or LOWER functions.

Find products where the color is "white" (case-insensitive):

SELECT id, product_details
FROM products
WHERE JSON_TEXTCONTAINS(product_details, '$.specs.color', 'White');

3. Combining with Other Conditions
You can combine JSON_TEXTCONTAINS with standard SQL conditions for more complex queries.

Find all products in "Electronics" with a brand of "Dell":

SELECT id, product_details
FROM products
WHERE JSON_TEXTCONTAINS(product_details, '$.category', 'Electronics')
  AND JSON_TEXTCONTAINS(product_details, '$.specs.brand', 'Dell');

Output:

ID	PRODUCT_DETAILS
1	{"name": "Laptop", "category": "Electronics", "specs": {"brand": "Dell", "color": "Black"}}

4. Real-Time Scenarios
Scenario 1: Product Search in E-commerce
Users can search for products in specific categories, brands, or attributes.

Scenario 2: Log Analysis
Find log entries where a specific error message or keyword is present in a JSON log stored in a database.
------------------------------------------------------------------------------------------------

window functions in Oracle let you perform calculations on a group of rows, but without combining them into a single row like normal aggregation functions (like SUM() or AVG()) do. Instead, these functions allow you to work with each row individually while still looking at related rows to do the calculation.

For example, imagine you have a list of employees with their salaries, and you want to:

Rank employees by salary (without collapsing the list into just the top-ranked employee).
Get the total salary of everyone in the same department, but still keep the individual employee rows.

Window function/Analytic function
    The ROW_NUMBER() function in Oracle is an analytic function that assigns a unique sequential number to each row in a result set, based on a specified ordering of rows. It's commonly used for tasks like pagination, deduplication, or ranking rows.

Syntax:

ROW_NUMBER() OVER ([PARTITION BY column1, column2, ...] ORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...)

PARTITION BY (optional): Divides the data into groups (partitions) where the row numbering restarts for each partition.
ORDER BY: Specifies the order in which rows are assigned row numbers.

Example Use Cases
1. Basic Row Numbering
Assign a row number to each row in a table based on a specific column's order.

Schema:

CREATE TABLE employees_analytic (
    employee_id NUMBER,
    first_name VARCHAR2(50),
    department_id NUMBER,
    salary NUMBER
);


INSERT INTO employees_analytic (employee_id, first_name, department_id, salary) 
VALUES 
    (1, 'Alice', 10, 5000),
    (2, 'Bob', 10, 7000),
    (3, 'Charlie', 20, 6000),
    (4, 'David', 20, 8000),
    (5, 'Eve', 20, 7500);

Data:

EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY
1	Alice	10	5000
2	Bob	10	7000
3	Charlie	20	6000
4	David	20	8000
5	Eve	20	7500

Query:

SELECT 
    ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num,
    employee_id,
    first_name,
    salary
FROM 
    employees_analytic;

Output:

ROW_NUM	EMPLOYEE_ID	FIRST_NAME	SALARY
1	4	David	8000
2	5	Eve	7500
3	2	Bob	7000
4	3	Charlie	6000
5	1	Alice	5000

2. Row Number with Partition
Restart row numbering for each department.

Query:

SELECT 
    ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY salary DESC) AS row_num_within_dept,
    employee_id,
    first_name,
    department_id,
    salary
FROM 
    employees_analytic;

Output:

ROW_NUM_WITHIN_DEPT	EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY
1	2	Bob	10	7000
2	1	Alice	10	5000
1	4	David	20	8000
2	5	Eve	20	7500
3	3	Charlie	20	6000

3. Deduplication
Remove duplicate rows based on specific columns and keep only the first occurrence.

Scenario: You want to keep only the highest salary for employees with duplicate first names.

Query:

SELECT employee_id, first_name, salary
FROM (
    SELECT 
        employee_id,
        first_name,
        salary,
        ROW_NUMBER() OVER (PARTITION BY first_name ORDER BY salary DESC) AS row_num
    FROM 
        employees_analytic
) sub
WHERE row_num = 1;

Explanation:

Partition the rows by first_name.
Use ROW_NUMBER() to assign numbers based on salary (highest first).
Filter rows where ROW_NUM = 1 to keep only the highest salary for each name.

4. Pagination
Fetch a specific page of results (e.g., rows 6–10) for a web application.

Query:

SELECT *
FROM (
    SELECT 
        ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num,
        employee_id,
        first_name,
        salary
    FROM 
        employees_analytic
) sub
WHERE row_num BETWEEN 6 AND 10;

5. Combine with Other Analytic Functions
You can use ROW_NUMBER() alongside other analytic functions like SUM() or RANK().

Example: Rank employees and assign unique row numbers for employees with the same salary.

Query:

SELECT 
    employee_id,
    first_name,
    salary,
    RANK() OVER (ORDER BY salary DESC) AS rank,
    ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	RANK	ROW_NUM
4	David	8000	1	1
5	Eve	7500	2	2
2	Bob	7000	3	3
3	Charlie	6000	4	4
1	Alice	5000	5	5

Key Features
The ROW_NUMBER() function is often used for creating custom numbering for rows.
Unlike RANK() and DENSE_RANK(), ROW_NUMBER() does not assign the same number to ties; it always generates a unique number for each row.

-------------------------------------------------------------------------------------------------
The RANK() function in Oracle is an analytic function that assigns a rank to each row in a result set based on the specified order. It allows ties by assigning the same rank to rows with the same value in the ordered column(s). However, the ranks are not consecutive when ties occur (i.e., the next rank skips numbers).

Syntax:

RANK() OVER ([PARTITION BY column1, column2, ...] ORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...)

PARTITION BY (optional): Divides the data into groups (partitions), where the ranking restarts for each partition.
ORDER BY: Specifies the order used to assign ranks.

Example Use Cases
1. Basic Ranking
Rank employees based on their salary.

SELECT 
    employee_id,
    first_name,
    salary,
    RANK() OVER (ORDER BY salary DESC) AS rank
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	RANK
4	David	8000	1
5	Eve	7500	2
2	Bob	7000	3
3	Charlie	6000	4
1	Alice	5000	5

2. Ranking with Ties
Assign ranks while allowing ties (e.g., if two employees have the same salary, they get the same rank).

Data (Modified):

EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY
1	Alice	10	5000
2	Bob	10	7000
3	Charlie	20	7000
4	David	20	8000
5	Eve	20	7500

Query:

SELECT 
    employee_id,
    first_name,
    salary,
    RANK() OVER (ORDER BY salary DESC) AS rank
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	RANK
4	David	8000	1
5	Eve	7500	2
2	Bob	7000	3
3	Charlie	7000	3
1	Alice	5000	5

3. Ranking within Partitions
Rank employees within their departments.

Query:
SELECT 
    employee_id,
    first_name,
    department_id,
    salary,
    RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS rank_within_dept
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY	RANK_WITHIN_DEPT
2	Bob	10	7000	1
1	Alice	10	5000	2
4	David	20	8000	1
5	Eve	20	7500	2
3	Charlie	20	7000	3

4. Skip Numbers in Ranking
If multiple rows have the same rank, the next rank skips by the count of tied rows.

Example: In the previous result, both Bob and Charlie have a rank of 3, so the next rank is 5 (not 4). This is the key difference between RANK() and DENSE_RANK().

Difference Between RANK() and DENSE_RANK()
Function	Behavior for Ties	Example (Salaries: 8000, 7500, 7000, 7000, 5000)
RANK()	Skips ranks after ties	1, 2, 3, 3, 5
DENSE_RANK	No skipped ranks	1, 2, 3, 3, 4

5. Pagination with RANK
Use RANK() to fetch the top 3 highest-paid employees, even if ties occur.

Query:

SELECT *
FROM (
    SELECT 
        employee_id,
        first_name,
        salary,
        RANK() OVER (ORDER BY salary DESC) AS rank
    FROM 
        employees_analytic
) sub
WHERE rank <= 3;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	RANK
4	David	8000	1
5	Eve	7500	2
2	Bob	7000	3
3	Charlie	7000	3

Key Features
RANK() is ideal when you need to account for ties and can tolerate skipped ranks.
Works well for leaderboard-style rankings and reporting tasks.
To avoid skipped ranks, use DENSE_RANK().
------------------------------------------------------------------------------------------------

The DENSE_RANK() function in Oracle is an analytic function that assigns a rank to each row in a result set based on the specified ordering. Unlike RANK(), DENSE_RANK() does not skip any ranks when there are ties; it assigns consecutive ranks even when duplicate values exist.

Syntax:

DENSE_RANK() OVER ([PARTITION BY column1, column2, ...] ORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...)

PARTITION BY (optional): Divides the data into groups (partitions) where ranking restarts for each partition.
ORDER BY: Specifies the order used to assign ranks.

Use Cases and Examples
1. Basic Dense Ranking
Rank employees based on their salary.

SELECT 
    employee_id,
    first_name,
    salary,
    DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	DENSE_RANK
4	David	8000	1
5	Eve	7500	2
2	Bob	7000	3
3	Charlie	7000	3
1	Alice	5000	4

2. Ranking within Partitions
Rank employees within their departments.

Query:

SELECT 
    employee_id,
    first_name,
    department_id,
    salary,
    DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS rank_within_dept
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY	RANK_WITHIN_DEPT
2	Bob	10	7000	1
1	Alice	10	5000	2
4	David	20	8000	1
5	Eve	20	7500	2
3	Charlie	20	7000	3

3. Handling Ties
DENSE_RANK() assigns the same rank to rows with the same value but ensures no skipped ranks.

Comparison with RANK():
When there are ties, RANK() skips numbers, while DENSE_RANK() does not.

Data:

SALARY	RANK()	DENSE_RANK()
8000	1	1
7500	2	2
7000	3	3
7000	3	3
5000	5	4

4. Pagination
Retrieve rows for specific pages, considering ties. For example, fetch all employees in the top 2 salary ranks.

Query:

SELECT *
FROM (
    SELECT 
        employee_id,
        first_name,
        salary,
        DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank
    FROM 
        employees_analytic
) sub
WHERE dense_rank <= 2;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	DENSE_RANK
4	David	8000	1
5	Eve	7500	2

5. Comparison of DENSE_RANK() and ROW_NUMBER()
ROW_NUMBER() assigns a unique number to each row, regardless of ties.
DENSE_RANK() gives the same rank to tied rows but does not skip numbers.

SELECT 
    employee_id,
    first_name,
    salary,
    ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num,
    DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	ROW_NUM	DENSE_RANK
4	David	8000	1	1
5	Eve	7500	2	2
2	Bob	7000	3	3
3	Charlie	7000	4	3
1	Alice	5000	5	4

Key Features
DENSE_RANK() is useful when you want consistent ranking without gaps.
Ideal for ranking tasks where ties exist, and skipped ranks are not acceptable.
Works well in scenarios like ranking products, scores, or salaries.

-------------------------------------------------------------------------------------------------

The LAG() function in Oracle is an analytic function used to access data from a previous row in the result set, without the need for a self-join. It is often used for comparing values between rows, calculating differences, or performing trend analysis.

Syntax:

LAG(column_name, [offset], [default_value]) 
    OVER ([PARTITION BY column1, column2, ...] ORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...)

column_name: The column from which to fetch the previous row's value.
offset (optional): The number of rows to look back (default is 1).
default_value (optional): A value to return if there is no previous row (default is NULL).
PARTITION BY (optional): Divides the data into partitions, where the function operates independently for each partition.
ORDER BY: Specifies the order of rows within the partition.

Examples
1. Compare Values with the Previous Row
Fetch the previous row's salary to compare it with the current row's salary.

SELECT 
    employee_id,
    first_name,
    salary,
    LAG(salary) OVER (ORDER BY salary) AS previous_salary
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	PREVIOUS_SALARY
1	Alice	5000	NULL
3	Charlie	6000	5000
2	Bob	7000	6000
5	Eve	7500	7000
4	David	8000	7500

2. Calculate Differences Between Rows
Find the difference in salary between the current row and the previous row.

SELECT 
    employee_id,
    first_name,
    salary,
    LAG(salary) OVER (ORDER BY salary) AS previous_salary,
    salary - LAG(salary) OVER (ORDER BY salary) AS salary_difference
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	PREVIOUS_SALARY	SALARY_DIFFERENCE
1	Alice	5000	NULL	NULL
3	Charlie	6000	5000	1000
2	Bob	7000	6000	1000
5	Eve	7500	7000	500
4	David	8000	7500	500

3. Partition Data
Restart the LAG() function for each department.

SELECT 
    employee_id,
    first_name,
    department_id,
    salary,
    LAG(salary) OVER (PARTITION BY department_id ORDER BY salary) AS previous_salary_in_dept
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY	PREVIOUS_SALARY_IN_DEPT
1	Alice	10	5000	NULL
2	Bob	10	7000	5000
3	Charlie	20	6000	NULL
5	Eve	20	7500	6000
4	David	20	8000	7500

4. Custom Offset and Default Value
Fetch the value from 2 rows back and use a default value when no previous row exists.

SELECT 
    employee_id,
    first_name,
    salary,
    LAG(salary, 2, 0) OVER (ORDER BY salary) AS salary_2_rows_back
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	SALARY_2_ROWS_BACK
1	Alice	5000	0
3	Charlie	6000	0
2	Bob	7000	5000
5	Eve	7500	6000
4	David	8000	7000

5. Identify Trends
Determine if salaries are increasing or decreasing compared to the previous row.

SELECT 
    employee_id,
    first_name,
    salary,
    CASE 
        WHEN salary > LAG(salary) OVER (ORDER BY salary) THEN 'INCREASE'
        WHEN salary < LAG(salary) OVER (ORDER BY salary) THEN 'DECREASE'
        ELSE 'NO CHANGE'
    END AS salary_trend
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	SALARY_TREND
1	Alice	5000	NO CHANGE
3	Charlie	6000	INCREASE
2	Bob	7000	INCREASE
5	Eve	7500	INCREASE
4	David	8000	INCREASE

Key Features
The LAG() function is very useful for comparisons and trend analysis between rows.
Helps in calculating running differences or changes across ordered rows.
Works seamlessly with PARTITION BY to group and analyze data.

-----------------------------------------------------------------------------------------------

The LEAD() function in Oracle is an analytic function used to access data from a subsequent row in the result set, without requiring a self-join. It is commonly used for comparing values between the current and future rows, or for calculating differences, trends, and forecasting.

Syntax:

LEAD(column_name, [offset], [default_value]) 
    OVER ([PARTITION BY column1, column2, ...] ORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...)

column_name: The column from which to fetch the next row's value.
offset (optional): The number of rows to look ahead (default is 1).
default_value (optional): A value to return if there is no subsequent row (default is NULL).
PARTITION BY (optional): Divides the data into partitions, where the function operates independently for each partition.
ORDER BY: Specifies the order of rows within the partition.

Examples
1. Compare Current Row with the Next Row
Fetch the next row's salary to compare it with the current row's salary.

SELECT 
    employee_id,
    first_name,
    salary,
    LEAD(salary) OVER (ORDER BY salary) AS next_salary
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	NEXT_SALARY
1	Alice	5000	6000
3	Charlie	6000	7000
2	Bob	7000	7500
5	Eve	7500	8000
4	David	8000	NULL

2. Calculate Differences Between Rows
Find the difference in salary between the current row and the next row.

SELECT 
    employee_id,
    first_name,
    salary,
    LEAD(salary) OVER (ORDER BY salary) AS next_salary,
    LEAD(salary) OVER (ORDER BY salary) - salary AS salary_difference
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	NEXT_SALARY	SALARY_DIFFERENCE
1	Alice	5000	6000	1000
3	Charlie	6000	7000	1000
2	Bob	7000	7500	500
5	Eve	7500	8000	500
4	David	8000	NULL	NULL

3. Partition Data
Restart the LEAD() function for each department.

SELECT 
    employee_id,
    first_name,
    department_id,
    salary,
    LEAD(salary) OVER (PARTITION BY department_id ORDER BY salary) AS next_salary_in_dept
FROM 
   employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	DEPARTMENT_ID	SALARY	NEXT_SALARY_IN_DEPT
1	Alice	10	5000	7000
2	Bob	10	7000	NULL
3	Charlie	20	6000	7500
5	Eve	20	7500	8000
4	David	20	8000	NULL

4. Custom Offset and Default Value
Fetch the value from 2 rows ahead, and use a default value if no subsequent row exists.

SELECT 
    employee_id,
    first_name,
    salary,
    LEAD(salary, 2, 0) OVER (ORDER BY salary) AS salary_2_rows_ahead
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	SALARY_2_ROWS_AHEAD
1	Alice	5000	7000
3	Charlie	6000	7500
2	Bob	7000	8000
5	Eve	7500	0
4	David	8000	0

5. Identify Trends
Determine if salaries are increasing or decreasing compared to the next row.

SELECT 
    employee_id,
    first_name,
    salary,
    CASE 
        WHEN salary < LEAD(salary) OVER (ORDER BY salary) THEN 'INCREASE'
        WHEN salary > LEAD(salary) OVER (ORDER BY salary) THEN 'DECREASE'
        ELSE 'NO CHANGE'
    END AS salary_trend
FROM 
    employees_analytic;

Output:

EMPLOYEE_ID	FIRST_NAME	SALARY	SALARY_TREND
1	Alice	5000	INCREASE
3	Charlie	6000	INCREASE
2	Bob	7000	INCREASE
5	Eve	7500	INCREASE
4	David	8000	NO CHANGE

Key Features
The LEAD() function is useful for:
Forecasting future values.
Comparing the current row with upcoming rows.
Trend analysis and sequential calculations.
It works seamlessly with PARTITION BY to group and analyze data independently.
--------------------------------------------------------------------------------------

Window functions like ROW_NUMBER, RANK, and DENSE_RANK in Oracle are incredibly useful when you need to perform analytical computations across a partition or subset of data. Below is a detailed example demonstrating their use with aggregations.

1. Table Schema and Sample Data
Create a Table

CREATE TABLE sales (
    sale_id NUMBER PRIMARY KEY,
    customer_id NUMBER,
    product_id NUMBER,
    sale_amount NUMBER,
    sale_date DATE
);

Insert Sample Data

INSERT INTO sales (sale_id, customer_id, product_id, sale_amount, sale_date)
VALUES (1, 101, 1, 500, DATE '2025-01-01');

INSERT INTO sales (sale_id, customer_id, product_id, sale_amount, sale_date)
VALUES (2, 102, 2, 300, DATE '2025-01-02');

INSERT INTO sales (sale_id, customer_id, product_id, sale_amount, sale_date)
VALUES (3, 101, 3, 400, DATE '2025-01-03');

INSERT INTO sales (sale_id, customer_id, product_id, sale_amount, sale_date)
VALUES (4, 103, 1, 600, DATE '2025-01-04');

INSERT INTO sales (sale_id, customer_id, product_id, sale_amount, sale_date)
VALUES (5, 101, 2, 700, DATE '2025-01-05');

2. Using ROW_NUMBER, RANK, and DENSE_RANK with Aggregations
a. Using ROW_NUMBER
Find the latest sale for each customer based on sale_date:


SELECT *
FROM (
    SELECT 
        customer_id,
        product_id,
        sale_amount,
        sale_date,
        ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY sale_date DESC) AS rn
    FROM sales
) t
WHERE rn = 1;
Output:

CUSTOMER_ID	PRODUCT_ID	SALE_AMOUNT	SALE_DATE	RN
101	2	700	2025-01-05	1
102	2	300	2025-01-02	1
103	1	600	2025-01-04	1
b. Using RANK
Rank customers by their highest sale amount:


SELECT *
FROM (
    SELECT 
        customer_id,
        sale_amount,
        RANK() OVER (PARTITION BY customer_id ORDER BY sale_amount DESC) AS rnk
    FROM sales
) t
WHERE rnk = 1;
Output:

CUSTOMER_ID	SALE_AMOUNT	RNK
101	700	1
102	300	1
103	600	1
c. Using DENSE_RANK
Find customers who share the same rank for their highest sale amount:


SELECT *
FROM (
    SELECT 
        customer_id,
        sale_amount,
        DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY sale_amount DESC) AS drnk
    FROM sales
) t
WHERE drnk = 1;
The results would look similar to RANK in this specific case, but DENSE_RANK ensures no gaps in rank numbers if there are ties.

d. Combining with Aggregations
Find the total sales for each customer and rank them by their total sales:


SELECT customer_id, total_sales, RANK() OVER (ORDER BY total_sales DESC) AS rnk
FROM (
    SELECT 
        customer_id,
        SUM(sale_amount) AS total_sales
    FROM sales
    GROUP BY customer_id
) t;
Output:

CUSTOMER_ID	TOTAL_SALES	RNK
101	1600	1
103	600	2
102	300	3
3. Real-Time Scenarios
Scenario 1: Sales Leaderboard
Identify the top 3 customers with the highest total sales:

SELECT *
FROM (
    SELECT customer_id, total_sales, RANK() OVER (ORDER BY total_sales DESC) AS rnk
    FROM (
        SELECT 
            customer_id,
            SUM(sale_amount) AS total_sales
        FROM sales
        GROUP BY customer_id
    )
) t
WHERE rnk <= 3;
Scenario 2: Top Products for Each Customer
Find the most purchased product for each customer:


SELECT *
FROM (
    SELECT 
        customer_id,
        product_id,
        SUM(sale_amount) AS total_amount,
        RANK() OVER (PARTITION BY customer_id ORDER BY SUM(sale_amount) DESC) AS rnk
    FROM sales
    GROUP BY customer_id, product_id
) t
WHERE rnk = 1;

4. Explanation of Functions
ROW_NUMBER: Assigns a unique sequential number to rows within a partition.

Example: Useful for finding the first or last entry.
RANK: Assigns a rank to rows, leaving gaps in rank numbers for ties.

Example: Useful for identifying distinct rankings.
DENSE_RANK: Similar to RANK, but without gaps in rank numbers.

Example: Useful when ties shouldn't cause gaps.

------------------------------------------------------------------------------------------

ARRAY_AGG Function in Oracle
     The function ARRAY_AGG() is not natively supported in Oracle. Use JSON_ARRAYAGG() for JSON array results.

SELECT 
    DEPARTMENT_ID, 
    JSON_ARRAYAGG(FIRST_NAME ORDER BY FIRST_NAME) AS EMPLOYEE_NAMES
FROM 
    EMPLOYEES_ANALYTIC
GROUP BY 
    DEPARTMENT_ID;


-----------------------------------------------------------------------------------------------

Oracle Pivot

Why Use Pivot and Unpivot in Oracle?
Both PIVOT and UNPIVOT are powerful operations in Oracle SQL that help in transforming and restructuring data, allowing for better analysis, reporting, and presentation. Here’s why they are useful:

1. Use Case for PIVOT
The PIVOT operation is used to transform rows into columns. It's often used when you want to aggregate data and convert unique values from a specific column (usually a categorical value) into individual columns for easier analysis. The main reasons for using PIVOT include:

A. Easier Reporting
Summary Representation: When you need to summarize data (e.g., sales figures) across multiple categories (e.g., products, years), using a pivot can help turn the data into a more readable, column-based format for reports.

Compare Across Categories: When you're comparing different items (e.g., products, regions) across various time periods or other categories (e.g., sales by month or year), PIVOT can make the data more accessible.

Example:
Imagine you have sales data in a table like this:

Region	Product	Year	Sales Amount
North	Laptop	2021	50000
North	Mobile	2021	30000
South	Laptop	2021	40000
South	Mobile	2021	25000

You may want to pivot the data so you can see the sales amount for each product across years. The resulting output would look like this:

Region	Laptop_2021	Mobile_2021
North	50000	30000
South	40000	25000

This makes it easy to compare sales for each product across different years.

2. Use Case for UNPIVOT
The UNPIVOT operation is the reverse of PIVOT. It is used to transform columns into rows. It's useful when you have a wide table (with many columns) and you want to normalize or unroll the data into a more long-format structure for easier processing or analysis.

A. Normalize Data
Flatten Data: When you have a table where multiple columns represent values for different periods (e.g., monthly data in separate columns), you might need to unpivot it into a single column representing the values with a corresponding period column.

Reorganize Data for Analysis: Unpivoting is also helpful when you need to restructure data for use in tools like data warehouses or reporting platforms that work better with long-format (normalized) data.

Example:
Assume you have monthly sales data in a table like this:

Product	Jan_Sales	Feb_Sales	Mar_Sales
Laptop	5000	6000	7000
Mobile	3000	3500	4000

You might want to unpivot the data so that the sales data for each month is represented as a row instead of a column. After unpivoting, you would get:

Product	Month	Sales
Laptop	Jan	5000
Laptop	Feb	6000
Laptop	Mar	7000
Mobile	Jan	3000
Mobile	Feb	3500
Mobile	Mar	4000

This long-format data is often more useful for time-series analysis, creating reports, or applying statistical models.

3. Why Pivot and Unpivot Are Important
A. Simplify Data Presentation
Pivot: Useful for summarizing data across multiple categories in a way that’s easier to present and understand.
Unpivot: Helps in restructuring wide tables into long format, making it easier to perform analysis or load the data into reporting tools.

B. Data Aggregation
Pivot allows aggregation of data (such as SUM, AVG, COUNT, etc.) and makes it easy to compare categories across different dimensions (such as sales by year, product, or region).
Unpivot can be useful in cases where the data is aggregated and needs to be broken down into individual components for more granular analysis.

C. Flexible Reporting
Pivot is particularly useful for dashboards and reports that need to show a summary of data across multiple variables in columns.
Unpivot is useful for generating detailed breakdowns of data, especially when dealing with wide data sets with multiple columns for each period, category, or dimension.

D. Data Transformation
Pivoting and unpivoting are often part of the ETL (Extract, Transform, Load) process when moving data into a different structure or preparing it for analysis.
They make it possible to reshape data without changing the underlying values, just changing the structure to suit the requirements of a particular analysis.

4. Example of Practical Scenarios
Scenario 1: Pivoting for Sales by Year
A company has sales data across regions and wants to see the year-wise total sales for each product.
Pivoting allows transforming the data such that each year becomes a column, and the total sales for each product in each year becomes the corresponding value.

Scenario 2: Unpivoting for Time-Series Analysis
A company has monthly sales data in separate columns (Jan_Sales, Feb_Sales, etc.) for each product.
Unpivoting will help convert these monthly sales columns into rows, allowing for easier analysis and charting of time-series data.

5. Key Differences Between PIVOT and UNPIVOT
Feature	PIVOT	UNPIVOT
Operation	Converts rows into columns	     Converts columns into rows
Use Case	Summarizing and comparing data 	Normalizing data for easier analysis and reporting
               across categories
Aggregation 	Often involves aggregation (e.g., SUM, AVG)	No aggregation, just restructuring of data
Data Orientation	Wide to narrow (more columns)	  Narrow to wide (more rows)

Conclusion
PIVOT is used when you want to summarize data or transform unique row values into column headers for easier comparison.
UNPIVOT is used when you need to normalize data, converting multiple columns into rows, which is ideal for time-series analysis or restructuring wide datasets.

CREATE TABLE sales_data (
    year INT,
    month VARCHAR2(3),  -- We store month as a string (e.g., 'Jan', 'Feb', etc.)
    revenue DECIMAL(10, 2),
    quantity INT,
    profit DECIMAL(10, 2)
);

INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2023, 'Jan', 1000, 50, 200);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2023, 'Jan', 1500, 100, 250);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2023, 'Feb', 1500, 70, 300);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2023, 'Mar', 2000, 100, 400);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2024, 'Jan', 1200, 60, 250);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2024, 'Feb', 1800, 80, 350);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2024, 'Mar', 2200, 90, 500);
INSERT INTO sales_data (year, month, revenue, quantity, profit) VALUES (2024, 'Mar', 3000, 100, 300);

Syntax:
SELECT *
FROM (
  SELECT <grouping_columns>, <pivot_column>, <aggregation_column>
  FROM <table_name>
)
PIVOT (
  <aggregation_function>(<aggregation_column>) 
  FOR <pivot_column> IN (<pivot_values>)
);


Explanation:
<grouping_columns>: These are the columns you want to group by (e.g., year, region).
<pivot_column>: The column whose unique values will become new columns in the result (e.g., month).
<aggregation_column>: The column to aggregate (e.g., revenue, sales).
<aggregation_function>: The function used to aggregate the values (e.g., SUM, AVG, COUNT).
<pivot_values>: The specific values from the pivot_column that you want to turn into columns (e.g., 'Jan', 'Feb', 'Mar').

Syntax:

SELECT <columns_to_keep>, <pivoted_column> AS <new_column_name>, <pivoted_value> AS <new_value_name>
FROM (
  SELECT <columns_to_keep>, <column1>, <column2>, <column3>, ...
  FROM <table_name>
)
UNPIVOT (
  <pivoted_value> FOR <pivoted_column> IN (<column1>, <column2>, <column3>, ...)
);

Explanation:
<columns_to_keep>: These are the columns that remain unchanged (i.e., the grouping columns).
<pivoted_column>: This will be the name of the new column that will contain the column names you are unpivoting (e.g., Jan, Feb, Mar).
<pivoted_value>: This will be the new column that contains the values from the original columns you are unpivoting (e.g., revenue).
<column1>, <column2>, <column3>, ...: These are the columns you want to unpivot.


1. convert the months into columns and show the total revenue for each month by year using pivot

SELECT *
FROM (
  SELECT year, month, revenue
  FROM sales_data
)
PIVOT (
  SUM(revenue) FOR month IN ('Jan' AS Jan, 'Feb' AS Feb, 'Mar' AS Mar)
);

2. UNPIVOT operator converts columns back into rows.

SELECT year, month, revenue
FROM (
  SELECT year, Jan, Feb, Mar
  FROM (
    SELECT year, month, revenue
    FROM sales_data
  )
  PIVOT (
    SUM(revenue) FOR month IN ('Jan' AS Jan, 'Feb' AS Feb, 'Mar' AS Mar)
  )
)
UNPIVOT (
  revenue FOR month IN (Jan, Feb, Mar)
);

3. count the number of sales (rather than summing revenue) for each month and year.

SELECT *
FROM (
  SELECT year, month, revenue
  FROM sales_data
)
PIVOT (
  COUNT(revenue) FOR month IN ('Jan' AS Jan, 'Feb' AS Feb, 'Mar' AS Mar)
);

4. you want both the SUM and AVG (average) of revenue for each year and month.

SELECT *
FROM (
  SELECT year, month, revenue
  FROM sales_data
)
PIVOT (
  SUM(revenue) AS total_revenue, AVG(revenue) AS avg_revenue
  FOR month IN ('Jan' AS Jan, 'Feb' AS Feb, 'Mar' AS Mar)
);

5. convert the revenue, quantity, and profit columns into rows for analysis.

SELECT year, month, metric, value
FROM (
  SELECT year, month, revenue, quantity, profit
  FROM sales_data
)
UNPIVOT (
  value FOR metric IN (revenue, quantity, profit)
);

6. we will calculate the total revenue (SUM(revenue)) and the number of sales transactions (COUNT(revenue)) for each month.

SELECT *
FROM (
  SELECT year, month, revenue
  FROM sales_data
)
PIVOT (
  SUM(revenue) AS total_revenue, 
  COUNT(revenue) AS total_sales
  FOR month IN ('Jan' AS Jan, 'Feb' AS Feb, 'Mar' AS Mar)
);

7.  convert multiple columns (revenue, quantity, profit) into rows for detailed analysis.

SELECT year, month, metric, value
FROM (
  SELECT year, month, revenue, quantity, profit
  FROM sales_data
)
UNPIVOT (
  value FOR metric IN (revenue, quantity, profit)
);

8. we want to filter out the quantity column and only unpivot the revenue and profit columns.

SELECT year, month, metric, value
FROM (
  SELECT year, month, revenue, profit
  FROM sales_data
)
UNPIVOT (
  value FOR metric IN (revenue, profit)
);

-----------------------------------------------------------------------------------------
CTE(Comman Table Expression)

WITH Clause in Oracle (Common Table Expressions - CTEs)
The WITH clause in Oracle allows you to define Common Table Expressions (CTEs). A CTE is a temporary result set that you can reference within a SELECT, INSERT, UPDATE, or DELETE statement. It is useful for simplifying complex queries and improving readability.

Syntax for WITH Clause

WITH CTE_name AS (
    -- SQL Query for the CTE
    SELECT column1, column2, ...
    FROM table_name
    WHERE condition
)
SELECT column1, column2
FROM CTE_name
WHERE condition;

CTE_name: The name of the CTE, which can be referenced in the main query.
SQL Query for the CTE: The query that defines the CTE. It can be any valid SELECT statement.
Main Query: The query that uses the CTE result.


Example 1: Simple WITH Clause
Let's use the WITH clause to calculate the average salary for each department and then find employees who earn more than the average salary in their respective departments.

WITH DepartmentAvgSalary AS (
    SELECT DEPARTMENT_ID, AVG(SALARY) AS AVG_SALARY
    FROM EMPLOYEES_ANALYTIC
    GROUP BY DEPARTMENT_ID
)
SELECT e.FIRST_NAME, e.SALARY, e.DEPARTMENT_ID, d.AVG_SALARY
FROM EMPLOYEES_ANALYTIC e
JOIN DepartmentAvgSalary d ON e.DEPARTMENT_ID = d.DEPARTMENT_ID
WHERE e.SALARY > d.AVG_SALARY;

Explanation:

The WITH clause defines a CTE DepartmentAvgSalary which calculates the average salary for each department.
The main query selects employees whose salary is greater than the average salary for their department.

Output:

EMPLOYEE_NAME	SALARY	DEPARTMENT_ID	AVG_SALARY
Jane Smith	60000	20	60000
Michael Johnson	55000	10	50000

Example 2: Multiple CTEs in the WITH Clause
You can define multiple CTEs within the same WITH clause. For example, let's calculate the total salary for each department and find departments where the total salary exceeds a threshold.

WITH DepartmentAvgSalary AS (
    SELECT DEPARTMENT_ID, AVG(SALARY) AS AVG_SALARY
    FROM EMPLOYEES_ANALYTIC
    GROUP BY DEPARTMENT_ID
),
DepartmentTotalSalary AS (
    SELECT DEPARTMENT_ID, SUM(SALARY) AS TOTAL_SALARY
    FROM EMPLOYEES_ANALYTIC
    GROUP BY DEPARTMENT_ID
)
SELECT e.DEPARTMENT_ID, e.FIRST_NAME, e.SALARY, d.AVG_SALARY, t.TOTAL_SALARY
FROM EMPLOYEES_ANALYTIC e
JOIN DepartmentAvgSalary d ON e.DEPARTMENT_ID = d.DEPARTMENT_ID
JOIN DepartmentTotalSalary t ON e.DEPARTMENT_ID = t.DEPARTMENT_ID
WHERE t.TOTAL_SALARY > 15000;

Explanation:

The WITH clause defines two CTEs:
DepartmentAvgSalary: Calculates the average salary for each department.
DepartmentTotalSalary: Calculates the total salary for each department.
The main query joins these CTEs and filters departments with total salaries greater than 150,000.


Recursive and Non-Recursive Expressions in Oracle
In Oracle, recursive and non-recursive expressions are commonly used with hierarchical queries. These types of queries are often used to handle parent-child relationships in data, such as organizational charts, folder structures, or bill-of-materials relationships. Oracle provides the CONNECT BY clause for hierarchical queries, and within this, there are recursive and non-recursive parts.

6️⃣ Real-World Use Cases
🔹 Corporate Structures (CEO → Managers → Employees)
🔹 Bill of Materials (BOM) (Product → Subcomponents → Raw Materials)
🔹 Multi-Level Categories (Electronics → Laptops → Gaming Laptops)
🔹 Order Dependencies (Order → Suborders → Shipping Stages)

Syntax of Recursive Query in Oracle
Oracle supports recursive queries using connect by:

1. Hierarchical Query (CONNECT BY) – Oracle-specific

Syntax:

SELECT column_names
FROM table_name
START WITH condition  -- Defines the root (starting point)
CONNECT BY PRIOR parent_column = child_column
ORDER SIBLINGS BY column_name;


Recursive Query in Oracle for Product Categories (Using CONNECT BY and WITH RECURSIVE)
Let's consider a multi-level product category hierarchy where each category can have subcategories.

🛒 Scenario: Product Categories
A company sells products under a hierarchical category structure:

Electronics
📱 Mobiles
      Smartphones
      Feature Phones
💻 Laptops
      Gaming Laptops
      Business Laptops
Furniture
      🛏 Beds
      🪑 Chairs

Each category is stored in a self-referencing table (categories).

1️⃣ Create Table and Insert Sample Data

CREATE TABLE categories (
    category_id NUMBER PRIMARY KEY,
    category_name VARCHAR2(100),
    parent_category_id NUMBER REFERENCES categories(category_id) -- Self-referencing FK
);

INSERT INTO categories VALUES (1, 'Electronics', NULL);
INSERT INTO categories VALUES (2, 'Mobiles', 1);
INSERT INTO categories VALUES (3, 'Laptops', 1);
INSERT INTO categories VALUES (4, 'Smartphones', 2);
INSERT INTO categories VALUES (5, 'Feature Phones', 2);
INSERT INTO categories VALUES (6, 'Gaming Laptops', 3);
INSERT INTO categories VALUES (7, 'Business Laptops', 3);
INSERT INTO categories VALUES (8, 'Furniture', NULL);
INSERT INTO categories VALUES (9, 'Beds', 8);
INSERT INTO categories VALUES (10, 'Chairs', 8);


2️⃣ Recursive Query Using CONNECT BY

SELECT LEVEL, 
       LPAD(' ', LEVEL * 3) || category_name AS category_hierarchy,
       category_id, parent_category_id
FROM categories
START WITH parent_category_id IS NULL  -- Root Categories
CONNECT BY PRIOR category_id = parent_category_id
ORDER SIBLINGS BY category_name;

🔹 Output:

LEVEL | CATEGORY_HIERARCHY       | CATEGORY_ID | PARENT_CATEGORY_ID
----------------------------------------------------------------
1     | Electronics              | 1          | NULL
2     |    Laptops               | 3          | 1
3     |       Business Laptops   | 7          | 3
3     |       Gaming Laptops     | 6          | 3
2     |    Mobiles               | 2          | 1
3     |       Feature Phones     | 5          | 2
3     |       Smartphones        | 4          | 2
1     | Furniture               | 8          | NULL
2     |    Beds                 | 9          | 8
2     |    Chairs               | 10         | 8
✅ Hierarchical structure preserved
✅ LEVEL indicates category depth
✅ ORDER SIBLINGS BY ensures alphabetical ordering


2. Recursive Query in Oracle for Order Dependencies (Using CONNECT BY and WITH RECURSIVE)
A real-world scenario where recursive queries are useful is order dependencies in an Order Management System. Orders often have sub-orders, which depend on other orders to be completed first.

📦 Scenario: Order Processing Dependencies
A company processes orders where some orders are dependent on previous orders before they can be completed.

Example hierarchy:

Order 100 (Main Order)
  Order 101 (Depends on 100)
    Order 103 (Depends on 101)
  Order 102 (Depends on 100)

Each order and its dependencies are stored in a self-referencing table (orders).

1️⃣ Create Table and Insert Sample Data

CREATE TABLE orders (
    order_id NUMBER PRIMARY KEY,
    order_name VARCHAR2(100),
    parent_order_id NUMBER REFERENCES orders(order_id) -- Self-referencing FK
);

INSERT INTO orders VALUES (100, 'Main Order', NULL);
INSERT INTO orders VALUES (101, 'Processing Sub-Order A', 100);
INSERT INTO orders VALUES (102, 'Processing Sub-Order B', 100);
INSERT INTO orders VALUES (103, 'Shipment Order', 101);
INSERT INTO orders VALUES (104, 'Final QC Check', 103);

2️⃣ Recursive Query Using CONNECT BY

SELECT LEVEL, 
       LPAD(' ', LEVEL * 3) || order_name AS order_hierarchy,
       order_id, parent_order_id
FROM orders
START WITH parent_order_id IS NULL  -- Root Orders
CONNECT BY PRIOR order_id = parent_order_id
ORDER SIBLINGS BY order_name;

LEVEL | ORDER_HIERARCHY            | ORDER_ID | PARENT_ORDER_ID
-------------------------------------------------------------------
1     | Main Order                 | 100      | NULL
2     |    Processing Sub-Order A   | 101      | 100
3     |       Shipment Order        | 103      | 101
4     |          Final QC Check     | 104      | 103
2     |    Processing Sub-Order B   | 102      | 100

✅ Hierarchy structure is preserved
✅ LEVEL indicates the order dependency depth
✅ ORDER SIBLINGS BY ensures sorted orders



1. Example Scenario: Organization Hierarchy
Let’s create a simple organization structure to demonstrate both recursive and non-recursive queries.

Table Schema
We’ll create a table called EMPLOYEES to represent an organizational hierarchy, where each employee has a manager (parent-child relationship).

CREATE TABLE EMPLOYEES_RECUR (
    EMPLOYEE_ID NUMBER PRIMARY KEY,
    EMPLOYEE_NAME VARCHAR2(100),
    MANAGER_ID NUMBER,
    JOB_TITLE VARCHAR2(100)
);

Insert Sample Data
Here’s some sample data for employees, showing who reports to whom:

INSERT INTO EMPLOYEES_RECUR (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, JOB_TITLE) 
VALUES (1, 'John Doe', NULL, 'CEO');

INSERT INTO EMPLOYEES_RECUR (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, JOB_TITLE) 
VALUES (2, 'Jane Smith', 1, 'VP of Sales');

INSERT INTO EMPLOYEES_RECUR (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, JOB_TITLE) 
VALUES (3, 'Michael Johnson', 1, 'VP of Marketing');

INSERT INTO EMPLOYEES_RECUR (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, JOB_TITLE) 
VALUES (4, 'Emily Davis', 2, 'Sales Manager');

INSERT INTO EMPLOYEES_RECUR (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, JOB_TITLE) 
VALUES (5, 'David Brown', 2, 'Sales Representative');

INSERT INTO EMPLOYEES_RECUR (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, JOB_TITLE) 
VALUES (6, 'Linda Clark', 3, 'Marketing Manager');

Here, John Doe is the CEO (no manager), and other employees have managers represented by MANAGER_ID.

2. Non-Recursive Query
A non-recursive query returns the initial set of rows from the hierarchical data, usually representing the root node in the hierarchy (e.g., the CEO or the top-level manager).

Non-Recursive Query Example (Get the Root Employees - CEO)

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE
FROM EMPLOYEES_RECUR
WHERE MANAGER_ID IS NULL;

This query will return the root node of the hierarchy:

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE
1	John Doe	CEO

In this case, John Doe is the only employee with no manager, making him the root of the hierarchy.

3. Recursive Query
A recursive query in Oracle typically uses the CONNECT BY clause, which allows you to navigate through the hierarchical data and return rows in a hierarchical order.

The recursive part of the query defines how to find child rows based on parent rows.

Recursive Query Example (Get the Entire Hierarchy)

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE, MANAGER_ID
FROM EMPLOYEES_RECUR
START WITH MANAGER_ID IS NULL  -- Non-recursive: Starting point (CEO)
CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID;  -- Recursive: Navigate down the hierarchy

Explanation:

Non-Recursive Expression (START WITH): This is where the query starts. In this case, it starts with the employee who has no manager (MANAGER_ID IS NULL), i.e., the CEO.

Recursive Expression (CONNECT BY): This defines how to navigate the hierarchy. The PRIOR keyword refers to the parent row, and CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID means that for each employee, their manager is the prior employee.

Output:

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE	MANAGER_ID
1	John Doe	CEO	NULL
2	Jane Smith	VP of Sales	1
4	Emily Davis	Sales Manager	2
5	David Brown	Sales Representative	2
3	Michael Johnson	VP of Marketing	1
6	Linda Clark	Marketing Manager	3

This query returns all employees in a hierarchical structure, starting from the CEO and traversing down the chain of command.

4. Using LEVEL in Recursive Queries
The LEVEL pseudo column is automatically generated in recursive queries, representing the depth of the current row in the hierarchy.

Recursive Query with LEVEL (Get Hierarchy and Depth Level)

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE, MANAGER_ID, LEVEL
FROM EMPLOYEES_RECUR
START WITH MANAGER_ID IS NULL
CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID;

Output:

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE	MANAGER_ID	LEVEL
1	John Doe	CEO	NULL	1
2	Jane Smith	VP of Sales	1	2
4	Emily Davis	Sales Manager	2	3
5	David Brown	Sales Representative	2	3
3	Michael Johnson	VP of Marketing	1	2
6	Linda Clark	Marketing Manager	3	3

In this query, LEVEL shows the depth of each employee in the hierarchy, with the CEO at level 1, the VPs at level 2, and so on.

5. Non-Recursive Query with Recursive Part
You can also combine non-recursive and recursive queries to handle complex hierarchical structures. For example, you might want to get all employees under a specific manager but also include their details without performing a full hierarchy traversal.

Example: Non-Recursive + Recursive Query (Get Employees under a Specific Manager)

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE, MANAGER_ID
FROM EMPLOYEES_RECUR
START WITH EMPLOYEE_ID = 2  -- Non-recursive: Starting with the employee (Jane Smith)
CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID;  -- Recursive: Find employees under Jane

Output:

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE	MANAGER_ID
2	Jane Smith	VP of Sales	1
4	Emily Davis	Sales Manager	2
5	David Brown	Sales Representative	2

This query starts with Jane Smith and recursively finds her subordinates (employees under her).

Conclusion
Non-Recursive Part: Initializes the query (e.g., starting with the root of the hierarchy like the CEO or a specific manager).

Recursive Part: Defines how to find the child rows and navigate through the hierarchy.
Using recursive queries with the CONNECT BY clause allows you to efficiently manage hierarchical data, making it easy to query and analyze data such as organizational structures, bill-of-materials, or product hierarchies.



Recursive and Non-Recursive Expressions in Oracle - Complex Example
In this example, we'll explore a more complex hierarchical structure using recursive and non-recursive expressions. The structure will represent a company's organizational hierarchy, but we'll add a few more layers, like departments, teams, and employee levels.

Let's imagine a multi-level company hierarchy where each employee reports to a manager. Employees may belong to different departments and teams. Our goal is to create a complex structure and explore how to query it with both recursive and non-recursive expressions.

1. Table Schema and Data
We will create two tables: one for employees and one for departments.

Table 1: EMPLOYEES

CREATE TABLE EMPLOYEES (
    EMPLOYEE_ID NUMBER PRIMARY KEY,
    EMPLOYEE_NAME VARCHAR2(100),
    MANAGER_ID NUMBER,
    DEPARTMENT_ID NUMBER,
    JOB_TITLE VARCHAR2(100)
);

Table 2: DEPARTMENTS

CREATE TABLE DEPARTMENTS (
    DEPARTMENT_ID NUMBER PRIMARY KEY,
    DEPARTMENT_NAME VARCHAR2(100)
);

Inserting Sample Data into DEPARTMENTS

-- Departments
INSERT INTO DEPARTMENTS (DEPARTMENT_ID, DEPARTMENT_NAME) VALUES (1, 'Sales');
INSERT INTO DEPARTMENTS (DEPARTMENT_ID, DEPARTMENT_NAME) VALUES (2, 'Marketing');
INSERT INTO DEPARTMENTS (DEPARTMENT_ID, DEPARTMENT_NAME) VALUES (3, 'Engineering');
INSERT INTO DEPARTMENTS (DEPARTMENT_ID, DEPARTMENT_NAME) VALUES (4, 'Human Resources');

Inserting Sample Data into EMPLOYEES

-- Employees: EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE
INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (1, 'John Doe', NULL, 1, 'CEO');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (2, 'Jane Smith', 1, 1, 'VP of Sales');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (3, 'Michael Johnson', 1, 2, 'VP of Marketing');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (4, 'Emily Davis', 2, 1, 'Sales Manager');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (5, 'David Brown', 2, 1, 'Sales Representative');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (6, 'Linda Clark', 3, 2, 'Marketing Manager');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (7, 'William White', 3, 2, 'Marketing Specialist');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (8, 'James Taylor', 6, 2, 'Marketing Associate');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (9, 'Sarah Green', 1, 3, 'VP of Engineering');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (10, 'Alice Brown', 9, 3, 'Engineering Manager');

INSERT INTO EMPLOYEES (EMPLOYEE_ID, EMPLOYEE_NAME, MANAGER_ID, DEPARTMENT_ID, JOB_TITLE) 
VALUES (11, 'Robert Lee', 10, 3, 'Senior Software Engineer');

2. Non-Recursive Query
A non-recursive query retrieves the root of the hierarchy or the top-level rows in the hierarchy.

For example, to retrieve the top-level managers (in this case, the CEO and VPs), you would use a non-recursive query to find employees who don't have a manager.

Non-Recursive Query Example

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE
FROM EMPLOYEES
WHERE MANAGER_ID IS NULL;

This query will return the root employees (those with MANAGER_ID IS NULL):

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE
1	John Doe	CEO
2	Jane Smith	VP of Sales
3	Michael Johnson	VP of Marketing
9	Sarah Green	VP of Engineering

3. Recursive Query
A recursive query is used to retrieve hierarchical data by navigating down the tree (e.g., finding all employees who report to a specific manager). The recursive expression helps to traverse through the hierarchy.

Recursive Query Example (Full Hierarchy)

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE, MANAGER_ID, DEPARTMENT_ID, LEVEL
FROM EMPLOYEES
START WITH MANAGER_ID IS NULL  -- Non-recursive part: Start from CEO (no manager)
CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID;  -- Recursive part: Navigate the hierarchy

Explanation:

Non-Recursive Expression: The START WITH MANAGER_ID IS NULL expression identifies the top-level employee (CEO) as the starting point.

Recursive Expression: The CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID part defines the recursive relationship, indicating that the query should find employees whose MANAGER_ID matches the EMPLOYEE_ID of the previous row.

Output:

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE	MANAGER_ID	DEPARTMENT_ID	LEVEL
1	John Doe	CEO	NULL	1	1
2	Jane Smith	VP of Sales	1	1	2
4	Emily Davis	Sales Manager	2	1	3
5	David Brown	Sales Representative	2	1	3
3	Michael Johnson	VP of Marketing	1	2	2
6	Linda Clark	Marketing Manager	3	2	3
7	William White	Marketing Specialist	3	2	3
8	James Taylor	Marketing Associate	6	2	4
9	Sarah Green	VP of Engineering	1	3	2
10	Alice Brown	Engineering Manager	9	3	3
11	Robert Lee	Senior Software Engineer	10	3	4

Explanation of the Output:

The LEVEL column shows the depth of each employee in the hierarchy.
The hierarchy starts from the CEO (Level 1) and traverses down to the Senior Software Engineer (Level 4).

4. Recursive Query with Additional Criteria
You can add more filters or conditions to your recursive queries. For instance, to retrieve only employees in the Sales department and their subordinates:

Recursive Query for Sales Department

SELECT EMPLOYEE_ID, EMPLOYEE_NAME, JOB_TITLE, MANAGER_ID, DEPARTMENT_ID, LEVEL
FROM EMPLOYEES
WHERE DEPARTMENT_ID = 1  -- Non-recursive: Only Sales department
START WITH MANAGER_ID IS NULL  -- Non-recursive: Start from CEO
CONNECT BY PRIOR EMPLOYEE_ID = MANAGER_ID;  -- Recursive: Get subordinates

Output:

EMPLOYEE_ID	EMPLOYEE_NAME	JOB_TITLE	MANAGER_ID	DEPARTMENT_ID	LEVEL
1	John Doe	CEO	NULL	1	1
2	Jane Smith	VP of Sales	1	1	2
4	Emily Davis	Sales Manager	2	1	3
5	David Brown	Sales Representative	2	1	3

This query returns all employees within the Sales department (Department ID 1) and their subordinates.


CREATE TABLE categories (
    category_id NUMBER PRIMARY KEY,
    category_name VARCHAR2(100),
    parent_category_id NUMBER REFERENCES categories(category_id) -- Self-referencing foreign key
);

INSERT INTO categories VALUES (1, 'Electronics', NULL);
INSERT INTO categories VALUES (2, 'Mobiles', 1);
INSERT INTO categories VALUES (3, 'Laptops', 1);
INSERT INTO categories VALUES (4, 'Smartphones', 2);
INSERT INTO categories VALUES (5, 'Feature Phones', 2);
INSERT INTO categories VALUES (6, 'Gaming Laptops', 3);
INSERT INTO categories VALUES (7, 'Business Laptops', 3);
INSERT INTO categories VALUES (8, 'Accessories', 1);
INSERT INTO categories VALUES (9, 'Chargers', 8);
INSERT INTO categories VALUES (10, 'Cables', 8);


SQL> SELECT LPAD(' ', LEVEL * 3) || category_name AS category_structure,
  2         category_id, parent_category_id, LEVEL
  3  FROM categories
  4  START WITH parent_category_id IS NULL
  5  CONNECT BY PRIOR category_id = parent_category_id;

CATEGORY_STRUCTURE        CATEGORY_ID PARENT_CATEGORY_ID      LEVEL
------------------------- ----------- ------------------ ----------
   Electronics                      1                             1
      Mobiles                       2                  1          2
         Smartphones                4                  2          3
         Feature Phones             5                  2          3
      Laptops                       3                  1          2
         Gaming Laptops             6                  3          3
         Business Laptops           7                  3          3
      Accessories                   8                  1          2
         Chargers                   9                  8          3
         Cables                    10                  8          3


Problem: Sibling categories (Mobiles and Laptops) are not sorted alphabetically.

SELECT LPAD(' ', LEVEL * 3) || category_name AS category_structure,
       category_id, parent_category_id, LEVEL
FROM categories
START WITH parent_category_id IS NULL
CONNECT BY PRIOR category_id = parent_category_id
ORDER SIBLINGS BY category_name;

CATEGORY_STRUCTURE      | CATEGORY_ID | PARENT_CATEGORY_ID | LEVEL
--------------------------------------------------------------
Electronics            | 1           | NULL               | 1
   Laptops            | 3           | 1                  | 2
      Business Laptops| 7           | 3                  | 3
      Gaming Laptops  | 6           | 3                  | 3
   Mobiles            | 2           | 1                  | 2
      Feature Phones  | 5           | 2                  | 3
      Smartphones     | 4           | 2                  | 3

In Oracle hierarchical queries, ORDER SIBLINGS BY is used with CONNECT BY to ensure that child nodes maintain a specific order under the same parent.

Why Use ORDER SIBLINGS BY?
By default, CONNECT BY does not guarantee an order for child rows under the same parent.

ORDER BY sorts the entire result set, not just siblings.
ORDER SIBLINGS BY sorts child records under the same parent.

------------------------------------------------------------------------------

REGEXP Functions in Oracle
In Oracle, the REGEXP functions allow you to use regular expressions to search and manipulate strings. These functions are particularly useful for pattern matching, validation, and data extraction. The most commonly used REGEXP functions are:

REGEXP_LIKE: Checks if a string matches a regular expression pattern.
REGEXP_INSTR: Returns the position of the first match of a regular expression.
REGEXP_SUBSTR: Extracts the substring that matches a regular expression.
REGEXP_REPLACE: Replaces the substring that matches a regular expression.
REGEXP_COUNT: Counts the number of times the regular expression matches a string.

1. Table Schema and Sample Data
We will use the CUSTOMERS table to demonstrate the REGEXP functions. This table stores customer information, including their phone numbers and email addresses.

Table Schema: CUSTOMERS

CREATE TABLE CUSTOMERS (
    CUSTOMER_ID NUMBER PRIMARY KEY,
    CUSTOMER_NAME VARCHAR2(100),
    PHONE_NUMBER VARCHAR2(15),
    EMAIL VARCHAR2(100)
);

Insert Sample Data into CUSTOMERS
We will insert some sample data into the CUSTOMERS table with phone numbers and emails that we will manipulate and search using REGEXP functions.

-- Sample data for CUSTOMERS table
INSERT INTO CUSTOMERS (CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER, EMAIL)
VALUES (1, 'John Doe', '123-456-7890', 'john.doe@example.com');

INSERT INTO CUSTOMERS (CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER, EMAIL)
VALUES (2, 'Jane Smith', '987-654-3210', 'jane.smith@domain.org');

INSERT INTO CUSTOMERS (CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER, EMAIL)
VALUES (3, 'Michael Johnson', '555-123-4567', 'michael.johnson@example.net');

INSERT INTO CUSTOMERS (CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER, EMAIL)
VALUES (4, 'Emily Davis', '444-222-8888', 'emily.davis@domain.edu');

INSERT INTO CUSTOMERS (CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER, EMAIL)
VALUES (5, 'David Brown', '333-444-5555', 'david.brown@website.com');

2. REGEXP Functions Usage
Let's explore various REGEXP functions using the CUSTOMERS table data.

Example 1: REGEXP_LIKE
The REGEXP_LIKE function checks if a string matches a given regular expression pattern. It returns TRUE if the string matches the pattern and FALSE otherwise.

Check if Phone Numbers Follow a Specific Pattern
We will check if the phone numbers follow the pattern XXX-XXX-XXXX, where X is a digit.

SELECT CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER
FROM CUSTOMERS
WHERE REGEXP_LIKE(PHONE_NUMBER, '^\d{3}-\d{3}-\d{4}$');

Explanation:

^\d{3}-\d{3}-\d{4}$: This pattern matches a string that starts (^) and ends ($) with three digits (\d{3}), followed by a hyphen (-), then another three digits, another hyphen, and four digits.
The REGEXP_LIKE function will return TRUE if the phone number matches this pattern.

Output:

CUSTOMER_ID	CUSTOMER_NAME	PHONE_NUMBER
1	John Doe	123-456-7890
2	Jane Smith	987-654-3210
3	Michael Johnson	555-123-4567
4	Emily Davis	444-222-8888
5	David Brown	333-444-5555

Example 2: REGEXP_INSTR
The REGEXP_INSTR function returns the position of the first occurrence of a pattern in a string.

Find the Position of the First Digit in Phone Number
We will use REGEXP_INSTR to find the position of the first digit in the PHONE_NUMBER column.

SELECT CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER,
       REGEXP_INSTR(PHONE_NUMBER, '\d', 1, 1) AS FIRST_DIGIT_POSITION
FROM CUSTOMERS;

Explanation:

\d: Represents any digit.

REGEXP_INSTR(PHONE_NUMBER, '\d', 1, 1): Finds the position of the first digit in the PHONE_NUMBER field.
1 is the starting position for the search.
The second 1 specifies that we want the position of the first occurrence.

Output:

CUSTOMER_ID	CUSTOMER_NAME	PHONE_NUMBER	FIRST_DIGIT_POSITION
1	John Doe	123-456-7890	1
2	Jane Smith	987-654-3210	1
3	Michael Johnson	555-123-4567	1
4	Emily Davis	444-222-8888	1
5	David Brown	333-444-5555	1

Example 3: REGEXP_SUBSTR
The REGEXP_SUBSTR function extracts the substring that matches a regular expression pattern.

Extract the First 3 Digits from Phone Number
We will use REGEXP_SUBSTR to extract the first three digits from the PHONE_NUMBER.

SELECT CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER,
       REGEXP_SUBSTR(PHONE_NUMBER, '\d{3}', 1, 1) AS FIRST_THREE_DIGITS
FROM CUSTOMERS;
Explanation:

\d{3}: This pattern matches exactly three digits.
REGEXP_SUBSTR(PHONE_NUMBER, '\d{3}', 1, 1): Extracts the first occurrence of three digits from the PHONE_NUMBER.

Output:

CUSTOMER_ID	CUSTOMER_NAME	PHONE_NUMBER	FIRST_THREE_DIGITS
1	John Doe	123-456-7890	123
2	Jane Smith	987-654-3210	987
3	Michael Johnson	555-123-4567	555
4	Emily Davis	444-222-8888	444
5	David Brown	333-444-5555	333

Example 4: REGEXP_REPLACE
The REGEXP_REPLACE function replaces substrings that match a regular expression pattern with a specified string.

Remove Non-Digit Characters from Phone Numbers
We will use REGEXP_REPLACE to remove any non-digit characters from the PHONE_NUMBER field.

SELECT CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER,
       REGEXP_REPLACE(PHONE_NUMBER, '[^\d]', '') AS CLEANED_PHONE_NUMBER
FROM CUSTOMERS;

Explanation:

[^\d]: This pattern matches any character that is not a digit.
REGEXP_REPLACE(PHONE_NUMBER, '[^\d]', ''): Replaces any non-digit character with an empty string (i.e., removes it).

Output:

CUSTOMER_ID	CUSTOMER_NAME	PHONE_NUMBER	CLEANED_PHONE_NUMBER
1	John Doe	123-456-7890	1234567890
2	Jane Smith	987-654-3210	9876543210
3	Michael Johnson	555-123-4567	5551234567
4	Emily Davis	444-222-8888	4442228888
5	David Brown	333-444-5555	3334445555

Example 5: REGEXP_COUNT
The REGEXP_COUNT function counts the number of occurrences of a pattern in a string.

Count the Number of Digits in the Phone Number
We will use REGEXP_COUNT to count the number of digits in the PHONE_NUMBER field.

SELECT CUSTOMER_ID, CUSTOMER_NAME, PHONE_NUMBER,
       REGEXP_COUNT(PHONE_NUMBER, '\d') AS DIGIT_COUNT
FROM CUSTOMERS;

Explanation:

\d: Matches any digit.
REGEXP_COUNT(PHONE_NUMBER, '\d'): Counts the number of digits in the PHONE_NUMBER field.
Output:

CUSTOMER_ID	CUSTOMER_NAME	PHONE_NUMBER	DIGIT_COUNT
1	John Doe	123-456-7890	10
2	Jane Smith	987-654-3210	10
3	Michael Johnson	555-123-4567	10
4	Emily Davis	444-222-8888	10
5	David Brown	333-444-5555	10

While Oracle does not have direct functions named REGEXP_CONTAINS, REGEXP_EXTRACT, or REGEXP_EXTRACT_ALL as they exist in other databases, equivalent functionality can be achieved using Oracle's regular expression functions.

1. Table Schema and Sample Data
Create a Table

CREATE TABLE employees_regexp (
    emp_id NUMBER PRIMARY KEY,
    emp_name VARCHAR2(100),
    emp_email VARCHAR2(100)
);

Insert Sample Data

INSERT INTO employees_regexp (emp_id, emp_name, emp_email)
VALUES (1, 'Alice Johnson', 'alice.johnson@example.com');

INSERT INTO employees_regexp (emp_id, emp_name, emp_email)
VALUES (2, 'Bob Smith', 'bob_smith@sample.org');

INSERT INTO employees_regexp (emp_id, emp_name, emp_email)
VALUES (3, 'Charlie Brown', 'charlie.brown@workplace.net');

2. Equivalent of REGEXP_CONTAINS
Check if a Pattern Exists in a Column
Use REGEXP_LIKE to determine if a pattern exists in a column. For example, find employees whose email domain is "example.com":

SELECT emp_id, emp_name, emp_email
FROM employees_regexp
WHERE REGEXP_LIKE(emp_email, '@example\.com$');

Output:

EMP_ID	EMP_NAME	EMP_EMAIL
1	Alice Johnson	alice.johnson@example.com

3. Equivalent of REGEXP_EXTRACT
Extract a Specific Pattern
Use REGEXP_SUBSTR to extract a part of the text that matches a pattern. For example, extract the domain from email addresses:

SELECT emp_id, emp_name, REGEXP_SUBSTR(emp_email, '@[^.]+') AS email_domain
FROM employees_regexp;

Output:

EMP_ID	EMP_NAME	EMAIL_DOMAIN
1	Alice Johnson	@example
2	Bob Smith	@sample
3	Charlie Brown	@workplace


5. Practical Examples
Scenario 1: Validate Email Addresses
Find rows with invalid email formats:

SELECT emp_id, emp_email
FROM employees_regexp
WHERE NOT REGEXP_LIKE(emp_email, '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$');

Scenario 2: Extract Top-Level Domains
Extract the top-level domain (e.g., .com, .org, .net) from email addresses:


SELECT emp_id, emp_email, REGEXP_SUBSTR(emp_email, '\.[a-z]{2,}$') AS top_level_domain
FROM employees_regexp;

Output:

EMP_ID	EMP_EMAIL	TOP_LEVEL_DOMAIN
1	alice.johnson@example.com	.com
2	bob_smith@sample.org	.org
3	charlie.brown@workplace.net	.net
------------------------------------------------------------------------------------------------
In Oracle, metadata refers to the data that describes the structure, constraints, relationships, and properties of the database schema. Oracle maintains a set of system tables (also known as data dictionary tables) that store metadata about the database objects. These system tables are essential for understanding the internal workings of the Oracle database.

1. Common Oracle Metadata Tables (Data Dictionary Views)
Oracle provides several views in the SYS schema to access metadata about the database. These are often referred to as the data dictionary or system catalog views.

Below are some of the key system tables/views in Oracle:

a. DBA Views (Requires DBA privileges)
DBA_TABLES: Provides information about all tables in the database.

SELECT * FROM DBA_TABLES WHERE OWNER = 'HR';

DBA_TAB_COLUMNS: Provides information about all columns in all tables in the database.

SELECT * FROM DBA_TAB_COLUMNS WHERE TABLE_NAME = 'EMPLOYEES';

DBA_INDEXES: Provides information about all indexes in the database.

SELECT * FROM DBA_INDEXES WHERE TABLE_NAME = 'EMPLOYEES';

DBA_USERS: Displays information about all users in the database.

SELECT * FROM DBA_USERS;

DBA_OBJECTS: Displays information about all objects (tables, views, indexes, etc.) in the database.

SELECT * FROM DBA_OBJECTS WHERE OBJECT_TYPE = 'TABLE';

DBA_CONSTRAINTS: Displays information about constraints (primary key, foreign key, check, etc.).

SELECT * FROM DBA_CONSTRAINTS WHERE TABLE_NAME = 'EMPLOYEES';

b. ALL Views (Accessible to all users)
ALL_TABLES: Provides information about all tables the user has access to.

SELECT * FROM ALL_TABLES;

ALL_TAB_COLUMNS: Provides information about columns in all tables the user has access to.

SELECT * FROM ALL_TAB_COLUMNS WHERE TABLE_NAME = 'EMPLOYEES';

ALL_OBJECTS: Displays information about all objects the user has access to.

SELECT * FROM ALL_OBJECTS WHERE OBJECT_TYPE = 'VIEW';

ALL_CONSTRAINTS: Displays information about constraints on tables the user has access to.

SELECT * FROM ALL_CONSTRAINTS WHERE TABLE_NAME = 'EMPLOYEES';

c. USER Views (Accessible to the current user)
USER_TABLES: Provides information about the tables owned by the current user.

SELECT * FROM USER_TABLES;

USER_TAB_COLUMNS: Provides information about columns in tables owned by the current user.

SELECT * FROM USER_TAB_COLUMNS WHERE TABLE_NAME = 'EMPLOYEES';

USER_OBJECTS: Displays information about all objects owned by the current user.

SELECT * FROM USER_OBJECTS WHERE OBJECT_TYPE = 'TABLE';

USER_CONSTRAINTS: Displays information about constraints on tables owned by the current user.

SELECT * FROM USER_CONSTRAINTS WHERE TABLE_NAME = 'EMPLOYEES';

2. Key Metadata Tables (Detailed Overview)
Here are some of the most useful metadata tables/views in Oracle:

a. ALL_TAB_COLUMNS
Purpose: Lists all the columns of the tables accessible to the user.

Important columns:
OWNER: The schema that owns the table.
TABLE_NAME: The name of the table.
COLUMN_NAME: The name of the column.
DATA_TYPE: The data type of the column.
DATA_LENGTH: The length of the column.
NULLABLE: Whether the column allows NULL values.

Example:

SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPE, DATA_LENGTH, NULLABLE
FROM ALL_TAB_COLUMNS
WHERE OWNER = 'HR' AND TABLE_NAME = 'EMPLOYEES';

b. ALL_TABLES
Purpose: Lists all the tables accessible to the user.
Important columns:
OWNER: The schema that owns the table.
TABLE_NAME: The name of the table.
TABLESPACE_NAME: The tablespace in which the table resides.
NUM_ROWS: The number of rows in the table (updated via ANALYZE command).

Example:

SELECT TABLE_NAME, NUM_ROWS
FROM ALL_TABLES
WHERE OWNER = 'HR';

c. ALL_INDEXES
Purpose: Lists all indexes accessible to the user.
Important columns:
INDEX_NAME: The name of the index.
TABLE_NAME: The name of the table associated with the index.
UNIQUENESS: Indicates whether the index is unique or not.

Example:

SELECT INDEX_NAME, TABLE_NAME, UNIQUENESS
FROM ALL_INDEXES
WHERE OWNER = 'HR';

d. DBA_OBJECTS
Purpose: Displays all objects (tables, views, indexes, etc.) in the database.
Important columns:
OBJECT_NAME: The name of the object.
OBJECT_TYPE: The type of the object (TABLE, VIEW, INDEX, etc.).
OWNER: The schema that owns the object.

Example:

SELECT OBJECT_NAME, OBJECT_TYPE
FROM DBA_OBJECTS
WHERE OWNER = 'HR';

e. DBA_USERS
Purpose: Provides information about all users in the database.
Important columns:
USERNAME: The name of the user.
USER_ID: The ID of the user.
ACCOUNT_STATUS: The status of the account (OPEN, LOCKED, etc.).

Example:

SELECT USERNAME, ACCOUNT_STATUS
FROM DBA_USERS;

f. DBA_CONSTRAINTS
Purpose: Lists all constraints (primary key, foreign key, check constraints, etc.) in the database.

Important columns:
CONSTRAINT_NAME: The name of the constraint.
CONSTRAINT_TYPE: The type of the constraint (P for primary key, R for foreign key, C for check, etc.).
TABLE_NAME: The table on which the constraint is applied.
SEARCH_CONDITION: The condition for check constraints.

Example:

SELECT CONSTRAINT_NAME, CONSTRAINT_TYPE, TABLE_NAME
FROM DBA_CONSTRAINTS
WHERE TABLE_NAME = 'EMPLOYEES';

g. DBA_TAB_PRIVS
Purpose: Lists all table privileges granted to users.
Important columns:
GRANTEE: The user or role that has been granted the privilege.
TABLE_NAME: The name of the table.
PRIVILEGE: The type of privilege (SELECT, INSERT, UPDATE, DELETE).

Example:

SELECT GRANTEE, TABLE_NAME, PRIVILEGE
FROM DBA_TAB_PRIVS
WHERE TABLE_NAME = 'EMPLOYEES';

h. DBA_VIEWS
Purpose: Provides information about views in the database.
Important columns:
VIEW_NAME: The name of the view.
TEXT_LENGTH: The length of the view's defining query.
TEXT: The SQL query that defines the view.

Example:

SELECT VIEW_NAME, TEXT
FROM DBA_VIEWS
WHERE VIEW_NAME = 'EMPLOYEE_VIEW';

3. Querying Metadata Tables
To effectively query metadata tables, use the following guidelines:

JOIN metadata tables for comprehensive analysis. For example, you can join DBA_TABLES with DBA_TAB_COLUMNS to get a list of columns for each table.

Example (Get column names and data types for all tables):

SELECT T.TABLE_NAME, C.COLUMN_NAME, C.DATA_TYPE
FROM DBA_TABLES T
JOIN DBA_TAB_COLUMNS C
  ON T.TABLE_NAME = C.TABLE_NAME
WHERE T.OWNER = 'HR';

Use WHERE clauses to filter data by specific schemas, tables, or columns.

Combine GROUP BY and COUNT to analyze the structure and distribution of database objects.

---------------------------------------------------------------------------------------------------------------------------------------------------------

JSON functions
Scenario: Product Catalog
We will create a PRODUCTS table to store product details, including information about product attributes (like color, size) and customer reviews (like rating, comment) in a nested JSON format.

1. Table Schema

CREATE TABLE PRODUCTS (
    PRODUCT_ID NUMBER PRIMARY KEY,
    PRODUCT_NAME VARCHAR2(100),
    DETAILS CLOB CHECK (DETAILS IS JSON)
);

2. Inserting Sample Data
We'll insert data for multiple products, with JSON details about the product's attributes and reviews.

INSERT INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, DETAILS) VALUES 
(1, 'Smartphone', '{
    "attributes": {
        "color": "Black",
        "size": "6.1 inches",
        "battery": "4000mAh"
    },
    "reviews": [
        {"rating": 4, "comment": "Good product, value for money."},
        {"rating": 5, "comment": "Excellent performance!"}
    ],
    "price": 599.99
}');

INSERT INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, DETAILS) VALUES 
(2, 'Laptop', '{
    "attributes": {
        "color": "Silver",
        "size": "15.6 inches",
        "battery": "5000mAh"
    },
    "reviews": [
        {"rating": 3, "comment": "Average performance."},
        {"rating": 4, "comment": "Great value for money."}
    ],
    "price": 999.99
}');

3. Querying JSON Data Using Oracle JSON Functions
We will now perform some practical queries to extract data from the JSON column DETAILS using Oracle's JSON functions.

A. Extracting Product Attributes (Color, Size, and Battery)
We can use the JSON_VALUE function to extract specific product attributes like color, size, and battery from the DETAILS JSON column.

SELECT 
    PRODUCT_NAME,
    JSON_VALUE(DETAILS, '$.attributes.color') AS COLOR,
    JSON_VALUE(DETAILS, '$.attributes.size') AS SIZE,
    JSON_VALUE(DETAILS, '$.attributes.battery') AS BATTERY
FROM PRODUCTS;

Expected Output:

PRODUCT_NAME	COLOR	SIZE	BATTERY
Smartphone	Black	6.1 inches	4000mAh
Laptop	Silver	15.6 inches	5000mAh

B. Extracting Product Reviews (Rating and Comment)
We can use the JSON_TABLE function to extract reviews from the nested reviews array, including the rating and comment fields.


SELECT 
    PRODUCT_NAME,
    jt.rating AS REVIEW_RATING,
    jt.comment AS REVIEW_COMMENT
FROM PRODUCTS,
    JSON_TABLE(
        DETAILS,
        '$.reviews[*]' 
        COLUMNS (
            rating NUMBER PATH '$.rating',
            comment VARCHAR2(255) PATH '$.comment'
        )
    ) jt;

Expected Output:

PRODUCT_NAME	REVIEW_RATING	REVIEW_COMMENT
Smartphone	4	Good product, value for money.
Smartphone	5	Excellent performance!
Laptop	3	Average performance.
Laptop	4	Great value for money.

C. Filtering Products Based on Price and Rating
Suppose you want to find products with a price greater than $600 and average customer rating greater than 4.

We can use a combination of JSON_VALUE and JSON_TABLE to extract the relevant information.

SELECT 
    PRODUCT_NAME,
    JSON_VALUE(DETAILS, '$.price') AS PRICE,
    AVG(jt.rating) AS AVG_RATING
FROM PRODUCTS,
    JSON_TABLE(
        DETAILS,
        '$.reviews[*]' 
        COLUMNS (
            rating NUMBER PATH '$.rating'
        )
    ) jt
GROUP BY PRODUCT_NAME, JSON_VALUE(DETAILS, '$.price')
HAVING JSON_VALUE(DETAILS, '$.price') > 600 AND AVG(jt.rating) > 4;

Expected Output:

PRODUCT_NAME	PRICE	AVG_RATING
Laptop	999.99	3.5
(Note: This query calculates the average rating for each product and filters based on the price and rating condition.)

D. Extracting All Reviews for a Specific Product (Smartphone)
To get all reviews for a specific product (e.g., Smartphone), you can use JSON_TABLE to extract all reviews as separate rows.

SELECT 
    jt.rating AS REVIEW_RATING,
    jt.comment AS REVIEW_COMMENT
FROM PRODUCTS,
    JSON_TABLE(
        DETAILS,
        '$.reviews[*]' 
        COLUMNS (
            rating NUMBER PATH '$.rating',
            comment VARCHAR2(255) PATH '$.comment'
        )
    ) jt
WHERE PRODUCT_NAME = 'Smartphone';

Expected Output:

REVIEW_RATING	REVIEW_COMMENT
4	Good product, value for money.
5	Excellent performance!

----------------------------------------------------------------------------------------------------------------------------------------------------------
AIRPORT SYSTEM

CREATE TABLE Airports (
    airport_id INT PRIMARY KEY,          
    airport_name VARCHAR(100),            
    city VARCHAR(100),                    
    country VARCHAR(100),                 
    iata_code VARCHAR(3)                  
);

CREATE TABLE Flights (
    flight_id INT PRIMARY KEY,                
    flight_number VARCHAR(10),                
    departure_airport_id INT,                 
    arrival_airport_id INT,                    
    departure_time DATE,                   
    arrival_time DATE,                     
    status VARCHAR(20),                        
    FOREIGN KEY (departure_airport_id) REFERENCES Airports(airport_id),
    FOREIGN KEY (arrival_airport_id) REFERENCES Airports(airport_id)
);

CREATE TABLE Passengers (
    passenger_id INT PRIMARY KEY,           
    first_name VARCHAR(50),                 
    last_name VARCHAR(50),                 
    email VARCHAR(100),                     
    phone_number VARCHAR(15)               
);

CREATE TABLE Bookings (
    booking_id INT PRIMARY KEY,              
    passenger_id INT,                       
    flight_id INT,                           
    booking_date DATE,                   
    seat_number VARCHAR(10),                 
    FOREIGN KEY (passenger_id) REFERENCES Passengers(passenger_id),
    FOREIGN KEY (flight_id) REFERENCES Flights(flight_id)
);


INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(1, 'John F. Kennedy', 'New York', 'USA', 'JFK');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(2, 'Heathrow', 'London', 'UK', 'LHR');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(3, 'Changi', 'Singapore', 'Singapore', 'SIN');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(4, 'Dubai International', 'Dubai', 'UAE', 'DXB');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(5, 'Los Angeles Intl', 'Los Angeles', 'USA', 'LAX');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(6, 'Paris Charles de Gaulle', 'Paris', 'France', 'CDG');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(7, 'Tokyo Narita', 'Tokyo', 'Japan', 'NRT');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(8, 'Sydney Kingsford Smith', 'Sydney', 'Australia', 'SYD');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(9, 'Frankfurt International', 'Frankfurt', 'Germany', 'FRA');
INSERT INTO Airports (airport_id, airport_name, city, country, iata_code) VALUES(10, 'Barcelona El Prat', 'Barcelona', 'Spain', 'BCN');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(101, 'AA100', 1, 2, TO_DATE('2025-03-01 10:00:00', 'YYYY-MM-DD HH24:MI:SS'), TO_DATE('2025-03-01 20:00:00', 'YYYY-MM-DD HH24:MI:SS'), 'On time');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(102, 'BA200', 2, 3, to_date('2025-03-02 14:00:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-02 23:55:00','YYYY-MM-DD HH24:MI:SS'), 'Delayed');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(103, 'SQ300', 3, 1, to_date('2025-03-02 18:30:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-02 22:00:00','YYYY-MM-DD HH24:MI:SS'), 'On time');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(104, 'EK400', 4, 5, to_date('2025-03-03 07:00:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-03 12:30:00','YYYY-MM-DD HH24:MI:SS'), 'On time');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(105, 'AA500', 1, 4, to_date('2025-03-04 16:00:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-04 23:00:00','YYYY-MM-DD HH24:MI:SS'), 'Cancelled');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(106, 'AF600', 6, 9, to_date('2025-03-05 11:30:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-05 18:00:00','YYYY-MM-DD HH24:MI:SS'), 'On time');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(107, 'JL700', 7, 10, to_date('2025-03-06 09:15:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-06 13:30:00','YYYY-MM-DD HH24:MI:SS'), 'Delayed');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(108, 'QF800', 8, 1, to_date('2025-03-07 12:00:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-07 22:00:00','YYYY-MM-DD HH24:MI:SS'), 'On time');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(109, 'LH900', 9, 6, to_date('2025-03-08 14:45:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-08 20:30:00','YYYY-MM-DD HH24:MI:SS'), 'On time');

INSERT INTO Flights (flight_id, flight_number, departure_airport_id, arrival_airport_id, departure_time, arrival_time, status) VALUES
(110, 'IB1000', 10, 4, to_date('2025-03-09 16:00:00','YYYY-MM-DD HH24:MI:SS'), to_date('2025-03-09 22:45:00','YYYY-MM-DD HH24:MI:SS'), 'Cancelled');


INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(1, 'John', 'Doe', 'john.doe@email.com', '1234567890');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(2, 'Jane', 'Smith', 'jane.smith@email.com', '9876543210');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(3, 'Mark', 'Taylor', 'mark.taylor@email.com', '5556667777');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(4, 'Emily', 'Davis', 'emily.davis@email.com', '1112233445');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(5, 'Steve', 'Harris', 'steve.harris@email.com', '5551112233');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(6, 'Laura', 'Wilson', 'laura.wilson@email.com', '4445556666');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(7, 'David', 'Brown', 'david.brown@email.com', '7778889999');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(8, 'Anna', 'Johnson', 'anna.johnson@email.com', '6667778888');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(9, 'Kevin', 'Martinez', 'kevin.martinez@email.com', '3334445555');
INSERT INTO Passengers (passenger_id, first_name, last_name, email, phone_number) VALUES
(10, 'Sophia', 'Anderson', 'sophia.anderson@email.com', '2223334444');

INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(1, 1, 101, to_date('2025-02-25 12:00:00','YYYY-MM-DD HH24:MI:SS'), '12A');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(2, 2, 102, to_date('2025-02-26 14:00:00','YYYY-MM-DD HH24:MI:SS'), '15B');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(3, 3, 103, to_date('2025-02-27 08:30:00','YYYY-MM-DD HH24:MI:SS'), '7C');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(4, 1, 104, to_date('2025-02-27 09:00:00','YYYY-MM-DD HH24:MI:SS'), '22D');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(5, 4, 104, to_date('2025-02-28 09:30:00','YYYY-MM-DD HH24:MI:SS'), '22E');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(6, 5, 105, to_date('2025-03-01 10:00:00','YYYY-MM-DD HH24:MI:SS'), '18F');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(7, 2, 104, to_date('2025-02-27 08:45:00','YYYY-MM-DD HH24:MI:SS'), '16A');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(8, 5, 103, to_date('2025-02-28 14:30:00','YYYY-MM-DD HH24:MI:SS'), '30B');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(9, 6, 106, to_date('2025-03-01 11:45:00','YYYY-MM-DD HH24:MI:SS'), '5C');
INSERT INTO Bookings (booking_id, passenger_id, flight_id, booking_date, seat_number) VALUES
(10, 7, 107, to_date('2025-03-02 10:30:00','YYYY-MM-DD HH24:MI:SS'), '3D');


1. Write a query to find all flights departing from a specific airport (e.g., JFK) and their details.

SELECT f.flight_number, f.departure_time, f.arrival_time, a1.airport_name AS departure_airport, a2.airport_name AS arrival_airport
FROM Flights f
JOIN Airports a1 ON f.departure_airport_id = a1.airport_id
JOIN Airports a2 ON f.arrival_airport_id = a2.airport_id
WHERE a1.airport_name = 'John F. Kennedy';

AA100|2025-03-01 10:00:00|2025-03-01 20:00:00|John F. Kennedy|Heathrow
AA500|2025-03-04 16:00:00|2025-03-04 23:00:00|John F. Kennedy|Dubai International

2.  Write a query to list all passengers who have a booking on a specific flight (e.g., Flight BA200).

SELECT p.first_name, p.last_name, b.seat_number
FROM Passengers p
JOIN Bookings b ON p.passenger_id = b.passenger_id
WHERE b.flight_id = (SELECT flight_id FROM Flights WHERE flight_number = 'BA200');

Jane|Smith|15B

3. Write a query to find all flights arriving at a specific airport called Heathrow and the total number of bookings for each.

SELECT f.flight_number, COUNT(b.booking_id) AS total_bookings
FROM Flights f
LEFT JOIN Bookings b ON f.flight_id = b.flight_id
WHERE f.arrival_airport_id = (SELECT airport_id FROM Airports WHERE airport_name = 'Heathrow')
GROUP BY f.flight_number;

AA100|1

4. Write a query to list the names of passengers who have booked a flight that has been delayed and sort passenger name in ascending order

SELECT p.first_name||' '||p.last_name as passenger_name
FROM Passengers p
JOIN Bookings b ON p.passenger_id = b.passenger_id
JOIN Flights f ON b.flight_id = f.flight_id
WHERE f.status = 'Delayed'
order by passenger_name;

David Brown
Jane Smith

5. Write a query to get the flights that have at least one booking from a specific passenger 'John Doe'.

SELECT f.flight_number, f.departure_time, f.arrival_time
FROM Flights f
JOIN Bookings b ON f.flight_id = b.flight_id
JOIN Passengers p ON b.passenger_id = p.passenger_id
WHERE p.first_name = 'John' AND p.last_name = 'Doe';


AA100|2025-03-01|2025-03-01
EK400|2025-03-03|2025-03-03

6. Write a query to list all flights from JFK and their booking details (including seat numbers and passenger names, departure and arrival time).

SELECT f.flight_number, p.first_name, p.last_name, b.seat_number, f.departure_time, f.arrival_time
FROM Flights f
JOIN Bookings b ON f.flight_id = b.flight_id
JOIN Passengers p ON b.passenger_id = p.passenger_id
WHERE f.departure_airport_id = (SELECT airport_id FROM Airports WHERE airport_name = 'John F. Kennedy');


AA100|John|Doe|12A|2025-03-01 10:00:00|2025-03-01 20:00:00
AA500|Steve|Harris|18F|2025-03-04 16:00:00|2025-03-04 23:00:00

7. Write a query to find all flights that have both delayed and on-time status, and count how many passengers have booked each of these flights and sort based on flight number in ascending order

SELECT f.flight_number, f.status, COUNT(b.booking_id) AS total_bookings
FROM Flights f
JOIN Bookings b ON f.flight_id = b.flight_id
WHERE f.status IN ('Delayed', 'On time')
GROUP BY f.flight_number, f.status
order by f.flight_number;

AA100|On time|1
AF600|On time|1
BA200|Delayed|1
EK400|On time|3
JL700|Delayed|1
SQ300|On time|2


8. Write a query to list all flights and their passenger count, sorted by the number of passengers in descending order.

SELECT f.flight_number, COUNT(b.booking_id) AS passenger_count
FROM Flights f
LEFT JOIN Bookings b ON f.flight_id = b.flight_id
GROUP BY f.flight_number
ORDER BY passenger_count DESC;


EK400|3
SQ300|2
JL700|1
BA200|1
AF600|1
AA500|1
AA100|1
QF800|0
LH900|0
IB1000|0

9. Write a query to get the total number of bookings for flights arriving at each airport and sort based on airport names in descending order.

SELECT a.airport_name, COUNT(b.booking_id) AS total_bookings
FROM Airports a
JOIN Flights f ON a.airport_id = f.arrival_airport_id
LEFT JOIN Bookings b ON f.flight_id = b.flight_id
GROUP BY a.airport_name
ORDER BY a.airport_name desc;

Paris Charles de Gaulle|0
Los Angeles Intl|3
John F. Kennedy|2
Heathrow|1
Frankfurt International|1
Dubai International|1
Changi|1
Barcelona El Prat|1

10. Write a query to counts the number of cancelled flights at each airport, whether they are departures or arrivals and sort based on airport name in ascending order.

SELECT a.airport_name, COUNT(f.flight_id) AS cancelled_flights
FROM Airports a
JOIN Flights f ON a.airport_id = f.departure_airport_id OR a.airport_id = f.arrival_airport_id
WHERE f.status = 'Cancelled'
GROUP BY a.airport_name
ORDER BY a.airport_name;

Barcelona El Prat|1
Dubai International|2
John F. Kennedy|1

11. Write a query to find the most popular departure airport based on the number of bookings and sort based on number of bookings in descending order (use LIMIT to get top most airport).

SELECT a.airport_name, COUNT(b.booking_id) AS total_bookings
FROM Airports a
JOIN Flights f ON a.airport_id = f.departure_airport_id
LEFT JOIN Bookings b ON f.flight_id = b.flight_id
GROUP BY a.airport_name
ORDER BY total_bookings DESC;
LIMIT 1;

Dubai International|3

12. Write a query to list the passengers who have booked the flight from 'LHR' (Heathrow) to 'SIN' (Changi).

SELECT p.first_name, p.last_name, p.email, b.seat_number
FROM Passengers p
JOIN Bookings b ON p.passenger_id = b.passenger_id
JOIN Flights f ON b.flight_id = f.flight_id
JOIN Airports a1 ON f.departure_airport_id = a1.airport_id
JOIN Airports a2 ON f.arrival_airport_id = a2.airport_id
WHERE a1.iata_code = 'LHR' AND a2.iata_code = 'SIN';


Jane|Smith|jane.smith@email.com|15B

13. Write a query to list the airports with the highest number of departing flights (use LIMIT to get top most airport)

SELECT a.airport_name, COUNT(f.flight_id) AS num_departures
FROM Airports a
JOIN Flights f ON a.airport_id = f.departure_airport_id
GROUP BY a.airport_name
ORDER BY num_departures DESC
LIMIT 1;

John F. Kennedy|2

14. Write a query to find the total number of flights departing from each airport and sort based on airport name in descending order

SELECT a.airport_name, COUNT(f.flight_id) AS total_flights
FROM Airports a
JOIN Flights f ON a.airport_id = f.departure_airport_id
GROUP BY a.airport_name
ORDER BY a.airport_name desc;

Tokyo Narita|1
Sydney Kingsford Smith|1
Paris Charles de Gaulle|1
John F. Kennedy|2
Heathrow|1
Frankfurt International|1
Dubai International|1
Changi|1
Barcelona El Prat|1
            
15. Write a query to list all passengers who have not booked any flights and sort based on passenger name in ascending order

SELECT p.first_name||' '||p.last_name as passenger_name
FROM Passengers p
LEFT JOIN Bookings b ON p.passenger_id = b.passenger_id
WHERE b.booking_id IS NULL
order by passenger_name;

Anna Johnson
Kevin Martinez
Sophia Anderson

16. Write a query to find all flights that have no passengers (i.e., no bookings) and sort based on flight number in ascending order

SELECT f.flight_number
FROM Flights f
LEFT JOIN Bookings b ON f.flight_id = b.flight_id
WHERE b.booking_id IS NULL
order by f.flight_number;

IB1000
LH900
QF800

----------------------------------------------------------------------------------------------------------------------------------------------------------

EVENT SYSTEM

An Event Management System (EMS) is a software application or platform designed to handle the planning, organization, and management of events. It manages various aspects of events, such as sessions, participants, registrations, speakers, and events themselves. The system stores and organizes data in a set of interrelated tables, helping users to efficiently track and manage event-related activities.

1. Events Table (events)
event_id	event_name	event_date	location	description
1	Tech Conference 2025	2025-05-15	San Francisco	Tech conference covering AI, ML, and Blockchain
2	Business Summit 2025	2025-06-10	New York	A summit for entrepreneurs and business leaders
3	Digital Marketing Expo	2025-07-05	Los Angeles	Event focusing on digital marketing trends and strategies
4	Cybersecurity Forum	2025-08-20	Chicago	Forum on the latest cybersecurity threats and solutions
5	HealthTech Innovation Summit	2025-09-25	Boston	Summit showcasing innovations in healthcare technology
6	AI for Good 2025	2025-10-15	Seattle	Conference exploring AI applications for social impact
7	Blockchain Summit 2025	2025-11-10	Austin	Summit on blockchain technologies and the future of cryptocurrencies
8	Startup Expo 2025	2025-12-01	San Francisco	Expo for new startup ventures and entrepreneurial networking
________________________________________
2. Participants Table (participants)
participant_id	first_name	last_name	email	phone_number	registration_date
1	John	Doe	john.doe@example.com	123-456-7890	2025-01-10
2	Jane	Smith	jane.smith@example.com	987-654-3210	2025-01-12
3	Alice	Johnson	alice.johnson@example.com	555-234-6789	2025-01-15
4	Bob	Williams	bob.williams@example.com	555-789-1234	2025-01-20
5	Charlie	Brown	charlie.brown@example.com	555-456-7890	2025-01-22
6	David	White	david.white@example.com	123-987-6543	2025-01-25
7	Emily	Green	emily.green@example.com	234-567-8901	2025-01-28
8	George	King	george.king@example.com	987-321-6540	2025-02-01
9	Lucas	Lee	lucas.lee@example.com	112-345-6789	2025-02-05
10	Sophia	Martinez	sophia.martinez@example.com	223-456-7890	2025-02-08
________________________________________
3. Speakers Table (speakers)
speaker_id	first_name	last_name	bio	email
1	Dr. Sarah	Lee	Expert in AI and Machine Learning	sarah.lee@tech.com
2	Mark	Taylor	Business strategist with 20 years of experience	mark.taylor@biz.com
3	Jessica	Adams	Digital marketing expert and consultant	jessica.adams@marketing.com
4	James	King	Cybersecurity analyst with expertise in threat management	james.king@security.com
5	Dr. Emily	Parker	Innovator in health technology and digital health solutions	emily.parker@healthtech.com
6	Dr. Michael	Rodriguez	AI researcher with a focus on healthcare applications	michael.rodriguez@ai.com
7	David	Brown	Blockchain expert with industry-leading insights	david.brown@blockchain.com
8	Karen	Robinson	Cybersecurity solutions provider for tech enterprises	karen.robinson@security.com
________________________________________
4. Sessions Table (sessions)
session_id	event_id	speaker_id	session_name	session_start_time	session_end_time
1	1	1	AI in 2025	2025-05-15 10:00:00	2025-05-15 11:00:00
2	1	3	The Future of Digital Marketing	2025-05-15 11:30:00	2025-05-15 12:30:00
3	2	2	Entrepreneurship in the 21st Century	2025-06-10 09:00:00	2025-06-10 10:30:00
4	3	3	Maximizing ROI through Digital Strategies	2025-07-05 11:00:00	2025-07-05 12:30:00
5	4	4	Securing the Digital Future	2025-08-20 10:00:00	2025-08-20 11:00:00
6	5	5	Innovating Healthcare through Technology	2025-09-25 09:00:00	2025-09-25 10:30:00
7	6	6	AI for Social Good	2025-10-15 11:00:00	2025-10-15 12:30:00
8	7	7	Blockchain Revolution	2025-11-10 09:00:00	2025-11-10 10:30:00
9	8	2	Building the Startup Ecosystem	2025-12-01 10:00:00	2025-12-01 11:30:00
10	8	3	Marketing for Startups	2025-12-01 12:00:00	2025-12-01 13:30:00
________________________________________
5. Registrations Table (registrations)
registration_id	participant_id	session_id	registration_date
1	1	1	2025-01-10
2	1	2	2025-01-12
3	1	3	2025-01-15
4	2	4	2025-01-20
5	2	5	2025-01-22
6	3	6	2025-01-23
7	4	7	2025-01-25
8	5	8	2025-01-28
9	6	9	2025-02-01
10	7	10	2025-02-05
11	8	1	2025-02-10
12	9	2	2025-02-12
13	9	3	2025-02-14
14	10	4	2025-02-18
15	10	5	2025-02-20





-- Events table
CREATE TABLE events (
    event_id NUMBER PRIMARY KEY,
    event_name VARCHAR2(100) NOT NULL,
    event_date DATE NOT NULL,
    location VARCHAR2(100),
    description VARCHAR2(255)
);

-- Participants table
CREATE TABLE participants (
    participant_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    email VARCHAR2(100) UNIQUE NOT NULL,
    phone_number VARCHAR2(15),
    registration_date DATE
);

-- Speakers table
CREATE TABLE speakers (
    speaker_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    bio VARCHAR2(255),
    email VARCHAR2(100) UNIQUE NOT NULL
);

-- Sessions table
CREATE TABLE sessions (
    session_id NUMBER PRIMARY KEY,
    event_id NUMBER REFERENCES events(event_id),
    speaker_id NUMBER REFERENCES speakers(speaker_id),
    session_name VARCHAR2(100),
    session_start_time DATE,
    session_end_time DATE
);

-- Registrations table
CREATE TABLE registrations (
    registration_id NUMBER PRIMARY KEY,
    participant_id NUMBER REFERENCES participants(participant_id),
    session_id NUMBER REFERENCES sessions(session_id),
    registration_date DATE
);


-- Insert Multiple Events
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES (1, 'Tech Conference 2025', '2025-05-15', 'San Francisco', 'Tech conference covering AI, ML, and Blockchain');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES(2, 'Business Summit 2025', '2025-06-10', 'New York', 'A summit for entrepreneurs and business leaders');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES(3, 'Digital Marketing Expo', '2025-07-05', 'Los Angeles', 'Event focusing on digital marketing trends and strategies');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES(4, 'Cybersecurity Forum', '2025-08-20', 'Chicago', 'Forum on the latest cybersecurity threats and solutions');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES(5, 'HealthTech Innovation Summit', '2025-09-25', 'Boston', 'Summit showcasing innovations in healthcare technology');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES(6, 'AI for Good 2025', '2025-10-15', 'Seattle', 'Conference exploring AI applications for social impact');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES(7, 'Blockchain Summit 2025', '2025-11-10', 'Austin', 'Summit on blockchain technologies and the future of cryptocurrencies');
INSERT INTO events (event_id, event_name, event_date, location, description) VALUES
(8, 'Startup Expo 2025', '2025-12-01', 'San Francisco', 'Expo for new startup ventures and entrepreneurial networking');


-- Insert Participants
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(1, 'John', 'Doe', 'john.doe@example.com', '123-456-7890', '2025-01-10');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(2, 'Jane', 'Smith', 'jane.smith@example.com', '987-654-3210', '2025-01-12');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(3, 'Alice', 'Johnson', 'alice.johnson@example.com', '555-234-6789', '2025-01-15');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(4, 'Bob', 'Williams', 'bob.williams@example.com', '555-789-1234', '2025-01-20');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(5, 'Charlie', 'Brown', 'charlie.brown@example.com', '555-456-7890', '2025-01-22');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(6, 'David', 'White', 'david.white@example.com', '123-987-6543', '2025-01-25');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(7, 'Emily', 'Green', 'emily.green@example.com', '234-567-8901', '2025-01-28');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(8, 'George', 'King', 'george.king@example.com', '987-321-6540', '2025-02-01');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(9, 'Lucas', 'Lee', 'lucas.lee@example.com', '112-345-6789', '2025-02-05');
INSERT INTO participants (participant_id, first_name, last_name, email, phone_number, registration_date) VALUES 
(10, 'Sophia', 'Martinez', 'sophia.martinez@example.com', '223-456-7890', '2025-02-08');


-- Insert Speakers
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES 
(1, 'Dr. Sarah', 'Lee', 'Expert in AI and Machine Learning', 'sarah.lee@tech.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(2, 'Mark', 'Taylor', 'Business strategist with 20 years of experience', 'mark.taylor@biz.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(3, 'Jessica', 'Adams', 'Digital marketing expert and consultant', 'jessica.adams@marketing.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(4, 'James', 'King', 'Cybersecurity analyst with expertise in threat management', 'james.king@security.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(5, 'Dr. Emily', 'Parker', 'Innovator in health technology and digital health solutions', 'emily.parker@healthtech.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(6, 'Dr. Michael', 'Rodriguez', 'AI researcher with a focus on healthcare applications', 'michael.rodriguez@ai.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(7, 'David', 'Brown', 'Blockchain expert with industry-leading insights', 'david.brown@blockchain.com');
INSERT INTO speakers (speaker_id, first_name, last_name, bio, email) VALUES
(8, 'Karen', 'Robinson', 'Cybersecurity solutions provider for tech enterprises', 'karen.robinson@security.com');


-- Insert Sessions
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES 
(1, 1, 1, 'AI in 2025', '2025-05-15 10:00:00', '2025-05-15 11:00:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(2, 1, 3, 'The Future of Digital Marketing','2025-05-15 11:30:00', '2025-05-15 12:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(3, 2, 2, 'Entrepreneurship in the 21st Century', '2025-06-10 09:00:00', '2025-06-10 10:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(4, 3, 3, 'Maximizing ROI through Digital Strategies', '2025-07-05 11:00:00', '2025-07-05 12:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(5, 4, 4, 'Securing the Digital Future', '2025-08-20 10:00:00', '2025-08-20 11:00:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(6, 5, 5, 'Innovating Healthcare through Technology', '2025-09-25 09:00:00', '2025-09-25 10:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(7, 6, 6, 'AI for Social Good','2025-10-15 11:00:00', '2025-10-15 12:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(8, 7, 7, 'Blockchain Revolution', '2025-11-10 09:00:00', '2025-11-10 10:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(9, 8, 2, 'Building the Startup Ecosystem', '2025-12-01 10:00:00', '2025-12-01 11:30:00');
INSERT INTO sessions (session_id, event_id, speaker_id, session_name, session_start_time, session_end_time) VALUES
(10, 8, 3, 'Marketing for Startups','2025-12-01 12:00:00', '2025-12-01 13:30:00');


-- Insert Registrations
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(1, 1, 1, '2025-01-10');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(2, 1, 2, '2025-01-12');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(3, 1, 3, '2025-01-15');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(4, 2, 4, '2025-01-20');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(5, 2, 5, '2025-01-22');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(6, 3, 6, '2025-01-23');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(7, 4, 7, '2025-01-25');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(8, 5, 8, '2025-01-28');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(9, 6, 9, '2025-02-01');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(10, 7, 10, '2025-02-05');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(11, 8, 1, '2025-02-10');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(12, 9, 2, '2025-02-12');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(13, 9, 3, '2025-02-14');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(14, 10, 4, '2025-02-18');
INSERT INTO registrations (registration_id, participant_id, session_id, registration_date) VALUES 
(15, 10, 5, '2025-02-20');


1. Write a query to find all events that have sessions with a specific speaker Dr. Sarah Lee

SELECT e.event_name, e.event_date, e.location
FROM events e
JOIN sessions s ON e.event_id = s.event_id
JOIN speakers sp ON s.speaker_id = sp.speaker_id
WHERE sp.first_name = 'Dr. Sarah' AND sp.last_name = 'Lee';  

2. Write a query to count the number of participants who registered for each session and sort based on session name in ascending order

SELECT s.session_name, COUNT(r.registration_id) AS num_participants
FROM sessions s
LEFT JOIN registrations r ON s.session_id = r.session_id
GROUP BY s.session_name
order by s.session_name;

AI for Social Good|1
AI in 2025|2
Blockchain Revolution|1
Building the Startup Ecosystem|1
Entrepreneurship in the 21st Century|2
Innovating Healthcare through Technology|1
Marketing for Startups|1
Maximizing ROI through Digital Strategies|2
Securing the Digital Future|2
The Future of Digital Marketing|2

3. Write a query to finds the participant who has registered for the highest number of sessions (Use LIMIT)

SELECT p.first_name, p.last_name, COUNT(r.registration_id) AS num_sessions
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
GROUP BY p.first_name, p.last_name
ORDER BY num_sessions DESC
limit 1;

4. Write a query to list all participants who are registered for a specific event called Tech Conference 2025

SELECT p.first_name, p.last_name, p.email, p.registration_date
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
JOIN events e ON s.event_id = e.event_id
WHERE e.event_name = 'Tech Conference 2025';


John|Doe|john.doe@example.com|2025-01-10
John|Doe|john.doe@example.com|2025-01-10
George|King|george.king@example.com|2025-02-01
Lucas|Lee|lucas.lee@example.com|2025-02-05

5. Write a query to list sessions where the number of registrations is greater than or equal to 2 and sort based on session name in descending order

SELECT s.session_name, COUNT(r.registration_id) AS num_registrations
FROM sessions s
JOIN registrations r ON s.session_id = r.session_id
GROUP BY s.session_name
HAVING COUNT(r.registration_id) >= 2
order by s.session_name desc;

The Future of Digital Marketing|2
Securing the Digital Future|2
Maximizing ROI through Digital Strategies|2
Entrepreneurship in the 21st Century|2
AI in 2025|2

6. Write a query to find participants who have registered for sessions in more than one event.

SELECT p.first_name, p.last_name, COUNT(DISTINCT s.event_id) AS num_events
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
GROUP BY p.first_name, p.last_name
HAVING COUNT(DISTINCT s.event_id) > 1;


Jane|Smith|2
John|Doe|2
Lucas|Lee|2
Sophia|Martinez|2

7. Write a query to find the total number of sessions conducted per speaker

SELECT sp.first_name, sp.last_name, COUNT(s.session_id) AS total_sessions
FROM speakers sp
JOIN sessions s ON sp.speaker_id = s.speaker_id
GROUP BY sp.first_name, sp.last_name
ORDER BY total_sessions DESC;

Jessica|Adams|3
Mark|Taylor|2
David|Brown|1
Dr. Emily|Parker|1
Dr. Michael|Rodriguez|1
Dr. Sarah|Lee|1
James|King|1

8. Write a query to find the speaker(s) with the most sessions scheduled 


SELECT sp.first_name, sp.last_name, COUNT(s.session_id) AS num_sessions
FROM speakers sp
JOIN sessions s ON sp.speaker_id = s.speaker_id
GROUP BY sp.first_name, sp.last_name
ORDER BY num_sessions DESC
LIMIT 1;

9. Write a query to find the participant who registered the latest for any session

SELECT p.first_name, p.last_name, MAX(r.registration_date) AS latest_registration
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
GROUP BY p.first_name, p.last_name
ORDER BY latest_registration DESC
LIMIT 1;

Sophia|Martinez|2025-02-20


10. Write a query to find events where more than 2 participants are registered for every session in the event

SELECT e.event_name
FROM events e
JOIN sessions s ON e.event_id = s.event_id
LEFT JOIN registrations r ON s.session_id = r.session_id
GROUP BY e.event_name
HAVING COUNT(r.registration_id) > 2;

Tech Conference 2025

11. Write a query to find the participants who registered for the session with the earliest start time across all events

SELECT p.first_name, p.last_name
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
WHERE s.session_start_time = (
    SELECT MIN(session_start_time) FROM sessions
)
GROUP BY p.first_name, p.last_name;

George|King
John|Doe


12. Write a query to show participants who have registered for multiple sessions within the same event.

SELECT p.first_name || ' ' || p.last_name AS participant_name, e.event_name
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
JOIN events e ON s.event_id = e.event_id
GROUP BY p.first_name, p.last_name, e.event_name
HAVING COUNT(DISTINCT s.session_id) > 1;

John Doe|Tech Conference 2025


13. Write a query which returns events with the highest and lowest number of unique participants based on registration.

SELECT e.event_name, COUNT(DISTINCT r.participant_id) AS unique_participants
FROM events e
JOIN sessions s ON e.event_id = s.event_id
LEFT JOIN registrations r ON s.session_id = r.session_id
GROUP BY e.event_name
ORDER BY unique_participants DESC;  

Tech Conference 2025|3
Startup Expo 2025|2
Digital Marketing Expo|2
Cybersecurity Forum|2
Business Summit 2025|2
HealthTech Innovation Summit|1
Blockchain Summit 2025|1
AI for Good 2025|1


14. Write a query to show the top 3 most active participants who have attended the most sessions.

SELECT p.first_name || ' ' || p.last_name AS participant_name,
       COUNT(DISTINCT s.session_id) AS sessions_attended
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
GROUP BY p.first_name, p.last_name
ORDER BY sessions_attended DESC
LIMIT 3;


John Doe|3
Jane Smith|2
Lucas Lee|2

15. Write a query to find the events where the majority of sessions have fewer than 10 participants and sort event name in ascending order

SELECT e.event_name
FROM events e
JOIN sessions s ON e.event_id = s.event_id
LEFT JOIN (SELECT session_id, COUNT(*) AS session_participants
           FROM registrations r
           GROUP BY session_id) session_counts
ON s.session_id = session_counts.session_id
GROUP BY e.event_name
HAVING AVG(CASE WHEN session_participants < 10 THEN 1 ELSE 0 END) > 0.5
order by e.event_name;

AI for Good 2025
Blockchain Summit 2025
Business Summit 2025
Cybersecurity Forum
Digital Marketing Expo
HealthTech Innovation Summit
Startup Expo 2025
Tech Conference 2025


16. Write a query to find the events where the number of participants exceeds the number of sessions and sort event name in ascending order

SELECT e.event_name, 
       COUNT(DISTINCT r.participant_id) AS total_participants, 
       COUNT(DISTINCT s.session_id) AS total_sessions
FROM events e
JOIN sessions s ON e.event_id = s.event_id
JOIN registrations r ON s.session_id = r.session_id
GROUP BY e.event_name
HAVING COUNT(DISTINCT r.participant_id) > COUNT(DISTINCT s.session_id)
order by e.event_name;


Business Summit 2025|2|1
Cybersecurity Forum|2|1
Digital Marketing Expo|2|1
Tech Conference 2025|3|2

17. Write a query to find all participants who have attended all sessions of a particular event

SELECT p.first_name || ' ' || p.last_name AS participant_name, 
       e.event_name
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
JOIN events e ON s.event_id = e.event_id
WHERE e.event_name = 'Digital Marketing Expo'
GROUP BY p.first_name, p.last_name, e.event_name
HAVING COUNT(DISTINCT s.session_id) = (SELECT COUNT(*) 
                                        FROM sessions 
                                        WHERE event_id = (SELECT event_id 
                                                          FROM events 
                                                          WHERE event_name = 'Digital Marketing Expo'));

Jane Smith|Digital Marketing Expo
Sophia Martinez|Digital Marketing Expo

18. Write a query to find the participant with the highest number of session registrations in a specific event called Startup Expo 2025

SELECT p.first_name || ' ' || p.last_name AS participant_name, 
       e.event_name, 
       COUNT(r.registration_id) AS session_count
FROM participants p
JOIN registrations r ON p.participant_id = r.participant_id
JOIN sessions s ON r.session_id = s.session_id
JOIN events e ON s.event_id = e.event_id
WHERE e.event_name = 'Startup Expo 2025'
GROUP BY p.first_name, p.last_name, e.event_name
ORDER BY session_count DESC;


Emily Green|Startup Expo 2025|1
David White|Startup Expo 2025|1

19. Write a query to find the speaker who has the most sessions in the events that are held in a specific city San Francisco

SELECT sp.first_name || ' ' || sp.last_name AS speaker_name, 
       COUNT(s.session_id) AS total_sessions
FROM speakers sp
JOIN sessions s ON sp.speaker_id = s.speaker_id
JOIN events e ON s.event_id = e.event_id
WHERE e.location = 'San Francisco'
GROUP BY sp.first_name, sp.last_name
ORDER BY total_sessions DESC
LIMIT 1;

Jessica Adams|2
        
SELECT sp.first_name || ' ' || sp.last_name AS speaker_name, 
       SUM(COUNT(r.registration_id)) AS total_attendees
FROM speakers sp
JOIN sessions s ON sp.speaker_id = s.speaker_id
JOIN registrations r ON s.session_id = r.session_id
GROUP BY sp.first_name, sp.last_name
ORDER BY total_attendees DESC;

20. Write a query which return the session name(s) with the least number of attendees, showing the session name and the number of attendees and sort session name in ascending order

SELECT s.session_name, COUNT(r.registration_id) AS total_registrations
FROM sessions s
JOIN registrations r ON s.session_id = r.session_id
GROUP BY s.session_name
HAVING COUNT(r.registration_id) = (
    SELECT MIN(session_count)
    FROM (
        SELECT COUNT(r.registration_id) AS session_count
        FROM sessions s
        JOIN registrations r ON s.session_id = r.session_id
        GROUP BY s.session_name
    )
)
order by s.session_name;

AI for Social Good|1
Blockchain Revolution|1
Building the Startup Ecosystem|1
Innovating Healthcare through Technology|1
Marketing for Startups|1


21. Write a query to find the total number of participants and sessions for each event for a specific date range between Jan 1 2025 to Dec 31 2025


SELECT e.event_name,
       COUNT(DISTINCT s.session_id) AS total_sessions,
       COUNT(DISTINCT r.participant_id) AS total_participants
FROM events e
JOIN sessions s ON e.event_id = s.event_id
JOIN registrations r ON s.session_id = r.session_id
WHERE s.session_start_time BETWEEN '2025-01-01' AND '2025-12-31'
GROUP BY e.event_name
ORDER BY total_participants DESC;


Tech Conference 2025|2|3
Startup Expo 2025|2|2
Digital Marketing Expo|1|2
Cybersecurity Forum|1|2
Business Summit 2025|1|2
HealthTech Innovation Summit|1|1
Blockchain Summit 2025|1|1
AI for Good 2025|1|1

---------------------------------------------------------------------------------------------------------------------------------------------------------
Joins Handson

-- Books Table
CREATE TABLE Books (
    Book_ID NUMBER PRIMARY KEY,
    Title VARCHAR2(255) NOT NULL,
    Author VARCHAR2(255) NOT NULL,
    Genre VARCHAR2(100),
    Published_Year NUMBER
);

-- Members Table
CREATE TABLE Members (
    Member_ID NUMBER PRIMARY KEY,
    Name VARCHAR2(255) NOT NULL,
    Join_Date DATE NOT NULL,
    Membership_Type VARCHAR2(50) CHECK (Membership_Type IN ('Regular', 'Premium'))
);

-- Borrowing Table
CREATE TABLE Borrowing (
    Borrow_ID NUMBER PRIMARY KEY,
    Member_ID NUMBER,
    Book_ID NUMBER,
    Borrow_Date DATE NOT NULL,
    Return_Date DATE NULL,
    CONSTRAINT fk_member FOREIGN KEY (Member_ID) REFERENCES Members(Member_ID),
    CONSTRAINT fk_book FOREIGN KEY (Book_ID) REFERENCES Books(Book_ID)
);


INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (1, 'The Great Gatsby', 'F. Scott Fitzgerald', 'Fiction', 1925);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (2, 'To Kill a Mockingbird', 'Harper Lee', 'Fiction', 1960);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (3, '1984', 'George Orwell', 'Dystopian', 1949);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (4, 'The Catcher in the Rye', 'J.D. Salinger', 'Fiction', 1951);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (5, 'Moby Dick', 'Herman Melville', 'Adventure', 1851);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (6, 'Pride and Prejudice', 'Jane Austen', 'Romance', 1813);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (7, 'The Hobbit', 'J.R.R. Tolkien', 'Fantasy', 1937);
INSERT INTO Books (Book_ID, Title, Author, Genre, Published_Year) VALUES (8, 'War and Peace', 'Leo Tolstoy', 'Historical Fiction', 1869);



INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (101, 'Alice Johnson', TO_DATE('2023-01-15', 'YYYY-MM-DD'), 'Regular');
INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (102, 'Bob Smith', TO_DATE('2022-07-22', 'YYYY-MM-DD'), 'Premium');
INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (103, 'Charlie Davis', TO_DATE('2021-11-05', 'YYYY-MM-DD'), 'Regular');
INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (104, 'David Brown', TO_DATE('2024-02-01', 'YYYY-MM-DD'), 'Premium');
INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (105, 'Emily White', TO_DATE('2022-05-10', 'YYYY-MM-DD'), 'Regular');
INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (106, 'Frank Miller', TO_DATE('2023-03-12', 'YYYY-MM-DD'), 'Regular');
INSERT INTO Members (Member_ID, Name, Join_Date, Membership_Type) VALUES (107, 'Grace Adams', TO_DATE('2022-09-30', 'YYYY-MM-DD'), 'Premium');



INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1001, 101, 1, TO_DATE('2024-01-01', 'YYYY-MM-DD'), TO_DATE('2024-01-10', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1002, 102, 2, TO_DATE('2024-01-05', 'YYYY-MM-DD'), TO_DATE('2024-01-15', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1003, 103, 3, TO_DATE('2023-12-20', 'YYYY-MM-DD'), NULL); -- Not returned yet

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1004, 104, 4, TO_DATE('2024-02-01', 'YYYY-MM-DD'), TO_DATE('2024-02-10', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1005, 105, 5, TO_DATE('2024-01-15', 'YYYY-MM-DD'), NULL); -- Not returned yet

-- Alice Johnson (Member_ID: 101) borrowed multiple books on different dates
INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1006, 101, 3, TO_DATE('2024-02-05', 'YYYY-MM-DD'), TO_DATE('2024-02-15', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1007, 101, 5, TO_DATE('2024-03-01', 'YYYY-MM-DD'), NULL); -- Not returned yet

-- Bob Smith (Member_ID: 102) borrowed the same book twice at different times
INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1008, 102, 2, TO_DATE('2023-12-10', 'YYYY-MM-DD'), TO_DATE('2023-12-20', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1009, 102, 2, TO_DATE('2024-02-20', 'YYYY-MM-DD'), NULL); -- Not returned yet

-- New member Frank Miller (Member_ID: 106) borrowed multiple books
INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1010, 106, 6, TO_DATE('2024-01-25', 'YYYY-MM-DD'), TO_DATE('2024-02-02', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1011, 106, 8, TO_DATE('2024-02-15', 'YYYY-MM-DD'), NULL); -- Not returned yet

-- Grace Adams (Member_ID: 107) borrowed multiple books
INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1012, 107, 7, TO_DATE('2023-11-20', 'YYYY-MM-DD'), TO_DATE('2023-11-30', 'YYYY-MM-DD'));

INSERT INTO Borrowing (Borrow_ID, Member_ID, Book_ID, Borrow_Date, Return_Date) 
VALUES (1013, 107, 1, TO_DATE('2024-01-18', 'YYYY-MM-DD'), TO_DATE('2024-01-28', 'YYYY-MM-DD'));


1. List all books borrowed by each member along with member details

SELECT m.Member_ID, m.Name, b.Book_ID, b.Title, br.Borrow_Date, br.Return_Date
FROM Members m
JOIN Borrowing br ON m.Member_ID = br.Member_ID
JOIN Books b ON br.Book_ID = b.Book_ID
ORDER BY m.Name, br.Borrow_Date;


2. Find members who have borrowed more than 3 books

SELECT Member_ID, Name
FROM Members
WHERE Member_ID IN (
    SELECT Member_ID
    FROM Borrowing
    GROUP BY Member_ID
    HAVING COUNT(Book_ID) > 3
);

3. Find books that have never been borrowed

SELECT Title, Author
FROM Books
WHERE Book_ID NOT IN (SELECT DISTINCT Book_ID FROM Borrowing);

4. Find the most recent book borrowed by each member

SELECT Member_ID, Book_ID, Borrow_Date,
       ROW_NUMBER() OVER (PARTITION BY Member_ID ORDER BY Borrow_Date DESC) AS rnk
FROM Borrowing
WHERE rnk = 1;

5. Calculate the total number of books borrowed by each member over time

SELECT Member_ID, Borrow_Date,
       COUNT(Book_ID) OVER (PARTITION BY Member_ID ORDER BY Borrow_Date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS Running_Total
FROM Borrowing;

6.  List the top 5 most borrowed books

SELECT Title, COUNT(br.Book_ID) AS Borrow_Count
FROM Books b
JOIN Borrowing br ON b.Book_ID = br.Book_ID
GROUP BY Title
ORDER BY COUNT(br.Book_ID) DESC
FETCH FIRST 5 ROWS ONLY;

7. Find members who borrowed books continuously for at least 3 months

SELECT Member_ID, Name, COUNT(DISTINCT TO_CHAR(Borrow_Date, 'YYYY-MM')) AS Months_Active
FROM Members m
JOIN Borrowing br ON m.Member_ID = br.Member_ID
GROUP BY m.Member_ID, m.Name
HAVING COUNT(DISTINCT TO_CHAR(Borrow_Date, 'YYYY-MM')) >= 3;

8. Find all overdue books (Return Date is NULL and Borrowed more than 30 days ago)

SELECT m.Name, b.Title, br.Borrow_Date
FROM Borrowing br
JOIN Members m ON br.Member_ID = m.Member_ID
JOIN Books b ON br.Book_ID = b.Book_ID
WHERE br.Return_Date IS NULL 
AND br.Borrow_Date < SYSDATE - 30;

9.  Find Books Borrowed by Premium Members Only

SELECT DISTINCT b.Title
FROM Books b
JOIN Borrowing bor ON b.Book_ID = bor.Book_ID
JOIN Members m ON bor.Member_ID = m.Member_ID
WHERE m.Membership_Type = 'Premium';


10. Find Books That Have Never Been Borrowed

SELECT b.Book_ID, b.Title
FROM Books b
LEFT JOIN Borrowing bor ON b.Book_ID = bor.Book_ID
WHERE bor.Borrow_ID IS NULL;



JSON Function handson

Order Management System - Schema and Table Data
1. Create the Tables

-- Creating customers table
CREATE TABLE customers (
    customer_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    email VARCHAR2(100)
);

-- Creating orders table with a JSON column for order details
CREATE TABLE orders (
    order_id NUMBER PRIMARY KEY,
    customer_id NUMBER,
    order_date DATE,
    total_amount NUMBER,
    order_details CLOB CHECK (order_details IS JSON),
    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)
);

-- Creating order_items table for order line items
CREATE TABLE order_items (
    order_item_id NUMBER PRIMARY KEY,
    order_id NUMBER,
    product_id NUMBER,
    quantity NUMBER,
    price NUMBER,
    FOREIGN KEY (order_id) REFERENCES orders(order_id)
);

2. Insert Sample Data

-- Inserting customers data
INSERT INTO customers (customer_id, first_name, last_name, email)
VALUES (101, 'John', 'Doe', 'john.doe@example.com');
INSERT INTO customers (customer_id, first_name, last_name, email)
VALUES (102, 'Jane', 'Smith', 'jane.smith@example.com');

-- Inserting orders data with JSON in order_details column
INSERT INTO orders (order_id, customer_id, order_date, total_amount, order_details)
VALUES (1001, 101, TO_DATE('2025-01-01', 'YYYY-MM-DD'), 2500,
    '{"status": "Shipped", "shipping_address": "123 Elm Street, Springfield, IL", "products": [{"product_id": 2001, "product_name": "Laptop", "quantity": 1, "price": 1500}, {"product_id": 2002, "product_name": "Headphones", "quantity": 1, "price": 1000}]}'
);

INSERT INTO orders (order_id, customer_id, order_date, total_amount, order_details)
VALUES (1002, 102, TO_DATE('2025-01-05', 'YYYY-MM-DD'), 1800,
    '{"status": "Processing", "shipping_address": "456 Oak Road, Chicago, IL", "products": [{"product_id": 2003, "product_name": "Smartphone", "quantity": 1, "price": 800}, {"product_id": 2004, "product_name": "Charger", "quantity": 1, "price": 200}, {"product_id": 2005, "product_name": "Case", "quantity": 1, "price": 100}]}'
);

-- Inserting order_items data (products in the order)
INSERT INTO order_items (order_item_id, order_id, product_id, quantity, price)
VALUES (1, 1001, 2001, 1, 1500);
INSERT INTO order_items (order_item_id, order_id, product_id, quantity, price)
VALUES (2, 1001, 2002, 1, 1000);
INSERT INTO order_items (order_item_id, order_id, product_id, quantity, price)
VALUES (3, 1002, 2003, 1, 800);
INSERT INTO order_items (order_item_id, order_id, product_id, quantity, price)
VALUES (4, 1002, 2004, 1, 200);
INSERT INTO order_items (order_item_id, order_id, product_id, quantity, price)
VALUES (5, 1002, 2005, 1, 100);

1. Extract the order status and shipping address from the order_details JSON column for each order.

SELECT order_id,
       JSON_VALUE(order_details, '$.status') AS order_status,
       JSON_VALUE(order_details, '$.shipping_address') AS shipping_address
FROM orders;

2. Use the JSON_TABLE() function to flatten the products array and extract the product details such as product_id, product_name, quantity, and price for each order.

SELECT o.order_id, jt.product_id, jt.product_name, jt.quantity, jt.price
FROM orders o,
     JSON_TABLE(
         o.order_details,
         '$.products[*]' COLUMNS (
             product_id NUMBER PATH '$.product_id',
             product_name VARCHAR2(100) PATH '$.product_name',
             quantity NUMBER PATH '$.quantity',
             price NUMBER PATH '$.price'
         )
     ) jt;

3. Change the status of the order with order_id = 1001 to "Delivered" using JSON_TRANSFORM().

UPDATE orders
SET order_details = JSON_TRANSFORM(order_details, '$.status', 'Delivered')
WHERE order_id = 1001;

4. Use JSON functions to calculate the total value of products (i.e., the sum of prices times quantities) in each order.

SELECT order_id,
       SUM(JSON_VALUE(order_details, '$.products[*].price') * JSON_VALUE(order_details, '$.products[*].quantity')) AS total_product_value
FROM orders
GROUP BY order_id;


5. Use the JSON_EXISTS() function to check if an order contains a product of the "Electronics" category.

SELECT order_id
FROM orders
WHERE JSON_EXISTS(order_details, '$.products[?(@.category == "Electronics")]');

6. If a product has no price in the order_details JSON, return "Price not available" as the default.

SELECT order_id,
       JSON_VALUE(order_details, '$.products[0].price', 'Price not available') AS product_price
FROM orders
WHERE order_id = 1002;

7. Aggregate all the products across orders into a single JSON array.

SELECT JSON_ARRAYAGG(
           JSON_OBJECT('order_id' VALUE order_id, 
                       'product_id' VALUE jt.product_id,
                       'product_name' VALUE jt.product_name,
                       'quantity' VALUE jt.quantity,
                       'price' VALUE jt.price)
       ) AS products
FROM orders o,
     JSON_TABLE(
         o.order_details,
         '$.products[*]' COLUMNS (
             product_id NUMBER PATH '$.product_id',
             product_name VARCHAR2(100) PATH '$.product_name',
             quantity NUMBER PATH '$.quantity',
             price NUMBER PATH '$.price'
         )
     ) jt;


8. Find orders that contain multiple products and calculate the total price for each order based on the products in the JSON array.

SELECT o.order_id,
       SUM(jt.price * jt.quantity) AS total_price
FROM orders o,
     JSON_TABLE(
         o.order_details,
         '$.products[*]' COLUMNS (
             product_id NUMBER PATH '$.product_id',
             quantity NUMBER PATH '$.quantity',
             price NUMBER PATH '$.price'
         )
     ) jt
GROUP BY o.order_id
HAVING COUNT(jt.product_id) > 1;

9. Find the sum of product prices for all orders by extracting the price for each product in the order_details JSON column.

SELECT order_id,
       SUM(JSON_VALUE(order_details, '$.products[*].price')) AS total_product_value
FROM orders
GROUP BY order_id;

10. Retrieve both the status and shipping_address from the order_details JSON column and the total amount for the order.

SELECT order_id,
       JSON_VALUE(order_details, '$.status') AS order_status,
       JSON_VALUE(order_details, '$.shipping_address') AS shipping_address,
       total_amount
FROM orders;

11. Retrieve all orders that contain a product with a specific product_name (e.g., "Laptop").

SELECT order_id, customer_id, order_date, total_amount
FROM orders
WHERE JSON_EXISTS(order_details, '$.products[?(@.product_name == "Laptop")]');

---------------------------------------------------------------------------------------------------------------------------------------------------------
Academy Management system

1. Adding a JSON Column to the students Table

ALTER TABLE students ADD (student_details CLOB);

2. Insert Data into the students Table (with JSON)

INSERT INTO students (student_id, first_name, last_name, student_details)
VALUES
(101, 'John', 'Doe', '{"address": {"street": "123 Main St", "city": "New York", "zip": "10001"}, "enrollment_date": "2023-01-15", "courses": [{"course_id": 1, "course_name": "Mathematics", "fee": 500}, {"course_id": 2, "course_name": "Physics", "fee": 600}]}');

INSERT INTO students (student_id, first_name, last_name, student_details)
VALUES
(102, 'Jane', 'Smith', '{"address": {"street": "456 Oak St", "city": "San Francisco", "zip": "94101"}, "enrollment_date": "2022-11-20", "courses": [{"course_id": 3, "course_name": "Biology", "fee": 550}, {"course_id": 4, "course_name": "Chemistry", "fee": 650}]}');

3. Retrieve the address of a student stored in the student_details JSON column Using JSON_VALUE

SELECT student_id, 
       first_name, 
       last_name,
       JSON_VALUE(student_details, '$.address.city') AS city
FROM students;

4. Retrieve the courses that a student is enrolled in, including course details like course_name and fee Using JSON_TABLE

SELECT student_id, 
       first_name, 
       last_name,
       course.course_id,
       course.course_name,
       course.fee
FROM students,
     JSON_TABLE(student_details, '$.courses[*]' 
        COLUMNS (
            course_id NUMBER PATH '$.course_id',
            course_name VARCHAR2(50) PATH '$.course_name',
            fee NUMBER PATH '$.fee'
        )
     ) AS course;

5. Retrieve a list of all courses that a student is enrolled in, formatted as a JSON array Using JSON_OBJECT and JSON_ARRAYAGG

SELECT student_id, 
       first_name, 
       last_name,
       JSON_ARRAYAGG(
           JSON_OBJECT('course_id' VALUE course_id, 'course_name' VALUE course_name, 'fee' VALUE fee)
       ) AS courses
FROM students,
     JSON_TABLE(student_details, '$.courses[*]' 
        COLUMNS (
            course_id NUMBER PATH '$.course_id',
            course_name VARCHAR2(50) PATH '$.course_name',
            fee NUMBER PATH '$.fee'
        )
     ) AS course
GROUP BY student_id, first_name, last_name;


6. Find students who are enrolled in a course with a fee greater than 600 Using JSON_EXISTS

SELECT student_id, first_name, last_name
FROM students
WHERE JSON_EXISTS(student_details, '$.courses[*]?(@.fee > 600)');


7. Retrieve a list of all students enrolled in each course Using JSON_ARRAYAGG

SELECT course_id, 
       JSON_ARRAYAGG(
           JSON_OBJECT('student_id' VALUE student_id, 'student_name' VALUE CONCAT(first_name, ' ', last_name))
       ) AS enrolled_students
FROM students,
     JSON_TABLE(student_details, '$.courses[*]' 
        COLUMNS (course_id NUMBER PATH '$.course_id')
     ) AS course
GROUP BY course_id;

8. Retrieve the zip code from the student's address with JSON_VALUE

SELECT student_id, 
       first_name, 
       last_name,
       JSON_VALUE(student_details, '$.address.zip') AS zip_code
FROM students;

9. Find students enrolled in courses with a total fee greater than 1000 Using JSON_TABLE and HAVING

SELECT student_id, 
       first_name, 
       last_name
FROM students,
     JSON_TABLE(student_details, '$.courses[*]' 
        COLUMNS (
            course_id NUMBER PATH '$.course_id',
            course_name VARCHAR2(50) PATH '$.course_name',
            fee NUMBER PATH '$.fee'
        )
     ) AS course
GROUP BY student_id, first_name, last_name
HAVING SUM(course.fee) > 1000;

---------------------------------------------------------------------------------------------------------------------------------------------------------

Shopping cart

1. Create a Table with JSON Column

CREATE TABLE Shopping_Cart (
    cart_id NUMBER PRIMARY KEY,
    customer_id NUMBER,
    cart_details CLOB CHECK (cart_details IS JSON)
);

2. Insert Data into the Table

INSERT INTO Shopping_Cart (cart_id, customer_id, cart_details)
VALUES (1, 101, 
        '{"items": [{"product_id": 101, "product_name": "Laptop", "price": 1000, "quantity": 1},
                    {"product_id": 102, "product_name": "Smartphone", "price": 500, "quantity": 2}]}');
        
INSERT INTO Shopping_Cart (cart_id, customer_id, cart_details)
VALUES (2, 102, 
        '{"items": [{"product_id": 103, "product_name": "Tablet", "price": 300, "quantity": 3},
                    {"product_id": 104, "product_name": "Headphones", "price": 100, "quantity": 1}]}');

3. Extract Product Names from the Shopping Cart Using JSON_VALUE

SELECT cart_id,
       JSON_VALUE(cart_details, '$.items[0].product_name') AS first_product_name,
       JSON_VALUE(cart_details, '$.items[1].product_name') AS second_product_name
FROM Shopping_Cart;

4. Extract the Total Number of Items in Each Cart

SELECT cart_id, 
       JSON_VALUE(cart_details, '$.items[0].quantity') AS first_item_quantity,
       JSON_VALUE(cart_details, '$.items[1].quantity') AS second_item_quantity
FROM Shopping_Cart;

5. Extract the Entire Items Array Using JSON_QUERY

SELECT cart_id, 
       JSON_QUERY(cart_details, '$.items') AS items
FROM Shopping_Cart;

6. Flatten the Cart Data into a Relational Format Using JSON_TABLE

SELECT cart_id,
       customer_id,
       jt.product_id,
       jt.product_name,
       jt.price,
       jt.quantity
FROM Shopping_Cart,
     JSON_TABLE(cart_details, '$.items[*]'
        COLUMNS (
            product_id NUMBER PATH '$.product_id',
            product_name VARCHAR2(100) PATH '$.product_name',
            price NUMBER PATH '$.price',
            quantity NUMBER PATH '$.quantity'
        )
     ) jt;

7. Add a New Product to the Cart Using JSON_OBJECT

UPDATE Shopping_Cart
SET cart_details = JSON_OBJECT(
    'items' VALUE JSON_ARRAY(
        JSON_OBJECT('product_id' VALUE 105, 'product_name' VALUE 'Smartwatch', 'price' VALUE 150, 'quantity' VALUE 1)
    )
)
WHERE cart_id = 1;

8. Find Carts Containing Items With Price Greater Than 500

SELECT cart_id,
       JSON_VALUE(cart_details, '$.items[0].product_name') AS first_product_name
FROM Shopping_Cart
WHERE JSON_VALUE(cart_details, '$.items[0].price') > 500;

9. Find Carts With a Total Quantity Greater Than 3

SELECT cart_id, 
       SUM(JSON_VALUE(cart_details, '$.items[*].quantity')) AS total_quantity
FROM Shopping_Cart
GROUP BY cart_id
HAVING SUM(JSON_VALUE(cart_details, '$.items[*].quantity')) > 3;

10. Return a Custom JSON Object with Cart Summary Using JSON_OBJECT

SELECT cart_id,
       JSON_OBJECT(
           'customer_id' VALUE customer_id,
           'total_amount' VALUE (SELECT SUM(JSON_VALUE(cart_details, '$.items[*].price')) FROM Shopping_Cart WHERE cart_id = c.cart_id),
           'total_items' VALUE (SELECT COUNT(*) FROM JSON_TABLE(cart_details, '$.items[*]' COLUMNS (product_id NUMBER PATH '$.product_id')))
       ) AS cart_summary
FROM Shopping_Cart c;

-----------------------------------------------------------------------------------------------------------------------------------------------------

Movie system

Movies:
movie_id	title	release_year	genre_id
1	"The Matrix"	1999	1
2	"Inception"	2010	2
3	"The Dark Knight"	2008	2
4	"Avatar"	2009	1
5	"The Godfather"	1972	3
6	"Pulp Fiction"	1994	3
7	"The Shawshank Redemption"	1994	3
8	"Titanic"	1997	4
Genres:
genre_id	genre_name
1	Sci-Fi
2	Action
3	Drama
4	Romance
Actors:
actor_id	first_name	last_name
1	Keanu	Reeves
2	Leonardo	DiCaprio
3	Christian	Bale
4	Robert	Downey Jr.
5	Marlon	Brando
6	John	Travolta
7	Tim	Robbins
8	Kate	Winslet
9	Morgan	Freeman
Movie_Actors:
movie_id	actor_id
1	1
2	2
3	3
4	4
5	5
6	6
7	7
8	8
1	2
2	3
3	4
6	5
7	9
5	9

Reviews:
review_id	movie_id	rating	review_text
1	1	9	"A groundbreaking sci-fi film!"
2	2	8	"A mind-bending thriller!"
3	3	10	"A masterpiece of action!"
4	4	7	"Visually stunning, but slow."
5	5	9	"A timeless classic."
6	6	8	"Quirky, but unforgettable."
7	7	10	"One of the best dramas ever."
8	8	8	"A tear-jerker with great chemistry."
9	1	7	"A fun but confusing ride."
10	2	9	"Brilliantly executed."

1. Find all movies with their genre name and release year.
SELECT m.title, g.genre_name, m.release_year
FROM Movies m
JOIN Genres g ON m.genre_id = g.genre_id;
Output:
title	genre_name	release_year
The Matrix	Sci-Fi	1999
Inception	Action	2010
The Dark Knight	Action	2008
Avatar	Sci-Fi	2009
The Godfather	Drama	1972
Pulp Fiction	Drama	1994
The Shawshank Redemption	Drama	1994
Titanic	Romance	1997

2. Get all actors who have acted in a movie from 2000 and later.
SELECT a.first_name||' '||a.last_name as actor_name
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Movies m ON ma.movie_id = m.movie_id
WHERE m.release_year >= 2000
order by actor_name desc;
Output:
first_name	last_name
Leonardo	DiCaprio
Christian	Bale
Robert	Downey Jr.
Keanu	Reeves
Morgan	Freeman

3. Get the average rating for each movie.
SELECT m.title, AVG(r.rating) AS average_rating
FROM Movies m
JOIN Reviews r ON m.movie_id = r.movie_id
GROUP BY m.title
order by average_rating desc;
Output:
title	average_rating
The Matrix	8.0
Inception	8.5
The Dark Knight	10.0
Avatar	7.0
The Godfather	9.0
Pulp Fiction	8.0
The Shawshank Redemption	10.0
Titanic	8.0

4. Find actors who acted in multiple movies.
SELECT a.first_name, a.last_name
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
GROUP BY a.first_name, a.last_name
HAVING COUNT(ma.movie_id) > 1;
Output:
first_name	last_name
Leonardo	DiCaprio
Christian	Bale
Keanu	Reeves

5. Get the movie titles that have a rating greater than 8 and are in the 'Drama' genre.
SELECT m.title
FROM Movies m
JOIN Genres g ON m.genre_id = g.genre_id
JOIN Reviews r ON m.movie_id = r.movie_id
WHERE g.genre_name = 'Drama'
AND r.rating > 8;
Output:
title
The Shawshank Redemption
The Godfather

6. Get the names of all actors who starred in movies with a rating higher than 9.
SELECT DISTINCT a.first_name, a.last_name
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Reviews r ON ma.movie_id = r.movie_id
WHERE r.rating > 9;
Output:
first_name	last_name
Christian	Bale
Morgan	Freeman

7. Find movies with no reviews.
SELECT m.title
FROM Movies m
LEFT JOIN Reviews r ON m.movie_id = r.movie_id
WHERE r.review_id IS NULL;
Output:
title
Avatar

8. Get movies released after 2000 that have an average rating greater than 8.
SELECT m.title, m.release_year
FROM Movies m
JOIN Reviews r ON m.movie_id = r.movie_id
WHERE m.release_year > 2000
GROUP BY m.title, m.release_year
HAVING AVG(r.rating) > 8;



Output:
title	release_year
Inception	2010
The Dark Knight	2008

9. Find the actors who have acted in the most highly-rated movies (rating above 9).
SELECT a.first_name, a.last_name, COUNT(ma.movie_id) AS movie_count
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Reviews r ON ma.movie_id = r.movie_id
WHERE r.rating > 9
GROUP BY a.first_name, a.last_name
ORDER BY movie_count DESC;
Output:
first_name	last_name	movie_count
Christian	Bale	1
Keanu	Reeves	1

10. Get the names of actors who have acted in both "The Matrix" and "Inception".
SELECT a.first_name, a.last_name
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Movies m ON ma.movie_id = m.movie_id
WHERE m.title IN ('The Matrix', 'Inception')
GROUP BY a.first_name, a.last_name
HAVING COUNT(DISTINCT m.title) = 2;
Output:
first_name	last_name
Keanu	Reeves

11. Find all actors who acted in movies with a rating between 8 and 9.
SELECT DISTINCT a.first_name, a.last_name
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Reviews r ON ma.movie_id = r.movie_id
WHERE r.rating BETWEEN 8 AND 9;

Output:
first_name	last_name
Leonardo	DiCaprio
Christian	Bale
Keanu	Reeves
Robert	Downey Jr.
Tim	Robbins
Kate	Winslet

12. Get movies with their respective number of reviews, ordered by the most reviewed.
SELECT m.title, COUNT(r.review_id) AS review_count
FROM Movies m
LEFT JOIN Reviews r ON m.movie_id = r.movie_id
GROUP BY m.title
ORDER BY review_count DESC;

Output:
title	review_count
The Matrix	2
Inception	2
The Dark Knight	1
Avatar	0
The Godfather	1
Pulp Fiction	1
The Shawshank Redemption	1
Titanic	1

13. Find the highest-rated movie for each genre.
SELECT 
    g.genre_name,g.genre_id,
    m.title AS highest_rated_movie,
    r.rating AS highest_rating
FROM Movies m
JOIN Genres g ON m.genre_id = g.genre_id
JOIN Reviews r ON m.movie_id = r.movie_id
WHERE r.rating = (
    SELECT MAX(rating)
    FROM Reviews r1
    JOIN Movies m1 ON r1.movie_id = m1.movie_id
    WHERE m1.genre_id = g.genre_id
)
ORDER BY g.genre_name; 

Output:
genre_name	title	highest_rating
Action	The Dark Knight	10
Drama	The Shawshank Redemption	10
Romance	Titanic	8
Sci-Fi	The Matrix	9

14. Get all movies released in the 1990s with their genre and average rating.
SELECT m.title, g.genre_name, AVG(r.rating) AS avg_rating
FROM Movies m
JOIN Genres g ON m.genre_id = g.genre_id
JOIN Reviews r ON m.movie_id = r.movie_id
WHERE m.release_year BETWEEN 1990 AND 1999
GROUP BY m.title, g.genre_name;

Output:
title	genre_name	avg_rating
Pulp Fiction	Drama	8.0
The Shawshank Redemption	Drama	10.0
Titanic	Romance	8.0

15. Get all actors who have acted in movies from the 'Sci-Fi' or 'Action' genres.
SELECT distinct a.first_name||' '||a.last_name as Actor_name
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Movies m ON ma.movie_id = m.movie_id
JOIN Genres g ON m.genre_id = g.genre_id
WHERE g.genre_name IN ('Sci-Fi', 'Action')
order by actor_name desc;

Output:
first_name	last_name
Keanu	Reeves
Leonardo	DiCaprio
Christian	Bale
Robert	Downey Jr.
Morgan	Freeman

16. Get the number of movies released each year.
SELECT m.release_year, COUNT(m.movie_id) AS movie_count
FROM Movies m
GROUP BY m.release_year
ORDER BY m.release_year DESC;

Output:
release_year	movie_count
2010	1
2009	1
2008	1
1999	1
1997	1
1994	2
1972	1
________________________________________
17.  Find movies where actors have appeared in only one movie.
SELECT m.title
FROM Movies m
WHERE m.movie_id IN (
    SELECT ma.movie_id
    FROM Movie_Actors ma
    GROUP BY ma.movie_id
    HAVING COUNT(ma.actor_id) = 1
);
Output:
title
Avatar

Write a query to find movies that have received more than and equal to 2 reviews and the average rating for those movies.
SELECT 
    m.title,
    AVG(r.rating) AS average_rating,
    COUNT(r.review_id) AS review_count
FROM Movies m
JOIN Reviews r ON m.movie_id = r.movie_id
GROUP BY m.title
HAVING COUNT(r.review_id) >= 2
ORDER BY average_rating DESC;

Write a query to find actors who have acted in movies of multiple genres.

SELECT 
    a.first_name || ' ' || a.last_name AS actor_name,
    COUNT(DISTINCT m.genre_id) AS genres_count
FROM Actors a
JOIN Movie_Actors ma ON a.actor_id = ma.actor_id
JOIN Movies m ON ma.movie_id = m.movie_id
GROUP BY a.actor_id, a.first_name, a.last_name
HAVING COUNT(DISTINCT m.genre_id) > 1
ORDER BY actor_name DESC;

Write a query to find the movies with their corresponding genre and the number of reviews each movie has and sort based on review count in descending order.

SELECT 
    m.title,
    g.genre_name,
    COUNT(r.review_id) AS review_count
FROM Movies m
JOIN Genres g ON m.genre_id = g.genre_id
LEFT JOIN Reviews r ON m.movie_id = r.movie_id
GROUP BY m.title, g.genre_name
ORDER BY review_count DESC;


Write a query to get the number of actors per genre who have acted in at least one movie and sorted based on count in descending order

SELECT 
    g.genre_name,
    COUNT(DISTINCT a.actor_id) AS actor_count
FROM Genres g
JOIN Movies m ON g.genre_id = m.genre_id
JOIN Movie_Actors ma ON m.movie_id = ma.movie_id
JOIN Actors a ON ma.actor_id = a.actor_id
GROUP BY g.genre_name
ORDER BY actor_count DESC;

-------------------------------------------------------------------------------------------------------------------------------------------------------

REG_EXP Function

CREATE TABLE employees (
    employee_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    email VARCHAR2(100),
    phone_number VARCHAR2(15),
    job_title VARCHAR2(50)
);

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(1, 'Alice', 'Smith', 'alice.smith@example.com', '(123) 456-7890', 'Software Engineer');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(2, 'Bob', 'Johnson', 'bob.johnson@example.com', '(234) 567-8901', 'Data Scientist');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(3, 'Charlie', 'Brown', 'charlie.brown@example.com', '(345) 678-9012', 'Product Manager');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(4, 'David', 'Lee', 'david.lee@example.com', '(456) 789-0123', 'HR Manager');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(5, 'Eve', 'Davis', 'eve.davis@example.com', '(567) 890-1234', 'Executive Assistant');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(6, 'Frank', 'Miller', 'frank.miller@company.org', '(678) 901-2345', 'Marketing Manager');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(7, 'Grace', 'Wilson', 'grace.wilson@example.com', '(789) 012-3456', 'Software Engineer');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(8, 'Heidi', 'Moore', 'heidi.moore@company.org', '(890) 123-4567', 'Data Scientist');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(9, 'Ivan', 'Taylor', 'ivan.taylor@example.com', '(901) 234-5678', 'Product Manager');

INSERT INTO employees (employee_id, first_name, last_name, email, phone_number, job_title) VALUES
(10, 'Julia', 'Clark', 'julia.clark@example.com', '(012) 345-6789', 'HR Assistant');


1. REGEXP_LIKE function in Oracle is used to check whether a string matches a regular expression pattern. 

Syntax:
REGEXP_LIKE (column_name, pattern [, match_option [, return_option [, start_position [, match_occurrence [, return_subexpression ]]]]])

Parameters:
column_name: The column name to be searched (e.g., email, first_name, etc.).
pattern: The regular expression pattern to search for in the column.
match_option (optional): Specifies the matching behavior. Common options include:
'i' : Case-insensitive matching.
'c' : Case-sensitive matching (default).
'n' : Allows the dot (.) to match newlines.
'm' : Treats the string as having multiple lines, so ^ and $ match the start and end of each line.
return_option (optional): Specifies what the function should return:
0 or false (default): Returns TRUE if the pattern matches, FALSE otherwise.
1 or true: Returns TRUE if the pattern matches, FALSE otherwise, but in a Boolean context.
start_position (optional): The position in the string to begin the search (defaults to 1, i.e., start from the beginning).
match_occurrence (optional): The occurrence of the pattern to match. Use 0 to match all occurrences (default).
return_subexpression (optional): If the pattern contains subexpressions, this specifies which subexpression to return.

1. Case-Insensitive Match for Email Pattern:

SELECT employee_id, email
FROM employees
WHERE REGEXP_LIKE(email, '@example\.com$', 'i');

This query will return all employees whose email addresses end with @example.com, case-insensitive.

SELECT employee_id, email
FROM employees
WHERE REGEXP_LIKE(email, '@Example\.com$');   //case sensitive


2. Employee Names Starting with 'A':

SELECT employee_id, first_name
FROM employees
WHERE REGEXP_LIKE(first_name, '^A', 'i');

This will return all employees whose first names start with the letter 'A', regardless of case.

3. Match Phone Numbers with Specific Format:
Assume phone_number is in the format (123) 456-7890 (with parentheses, space, and hyphen).

SELECT employee_id, phone_number
FROM employees
WHERE REGEXP_LIKE(phone_number, '^\(\d{3}\) \d{3}-\d{4}$');

This will return all employees whose phone numbers match the specified format.

4. Match Employees with Middle Initial (Assuming Name Format: First Middle Last):

SELECT employee_id, first_name, middle_name, last_name
FROM employees
WHERE REGEXP_LIKE(first_name || ' ' || middle_name || ' ' || last_name, '^[A-Za-z]+ [A-Za-z]\. [A-Za-z]+$');

This will return employees with a first name, middle initial, and last name. The middle name is a single letter followed by a period.

5. Search for Employees with Specific Job Titles (Case-Insensitive):
If the job_title column contains titles like "Manager", "manager", "Executive", etc., and you want to find those who have "Manager" as part of the title:

SELECT employee_id, job_title
FROM employees
WHERE REGEXP_LIKE(job_title, 'Manager', 'i');

This will return all employees whose job title contains "Manager" (case-insensitive).

6. Using match_occurrence and start_position:
If you want to find the second occurrence of a pattern within the column, you can specify the occurrence:

SELECT employee_id, email
FROM employees
WHERE REGEXP_LIKE(email, 'a', 'i', 1, 2);

This will return employees whose email has a second occurrence of the letter 'a', case-insensitive.

7. Return Subexpression (Example with Capturing Groups):
If you have a pattern with capturing groups (like extracting a portion of the string), you can use the return_subexpression argument. Here's an example:


SELECT employee_id, email,
       REGEXP_SUBSTR(email, '([A-Za-z0-9._%+-]+)@', 1, 1, NULL, 1) AS username
FROM employees
WHERE REGEXP_LIKE(email, '^[A-Za-z0-9._%+-]+@');

This will return the part of the email before the "@" symbol (the username) for each employee.


2. REGEXP_INSTR function is used to search for a regular expression pattern within a string and returns the position of the first occurrence of the pattern. 

Complete Syntax of REGEXP_INSTR:

REGEXP_INSTR (
    string,
    pattern,
    start_position,
    match_occurrence,
    return_option,
    match_modifier,
    subexpression_start_position,
    subexpression_length
)

Parameters:
string: The string (or column) to search in.
pattern: The regular expression pattern to search for.
start_position (optional): The position to start the search. Default is 1 (i.e., the beginning of the string).
match_occurrence (optional): The occurrence of the match to return. Default is 1 (i.e., the first occurrence).
return_option (optional): Specifies what should be returned:
0 or TRUE: Returns the position of the match (default).
1: Returns the match itself.

match_modifier (optional): Modifiers that control the matching behavior (e.g., 'i' for case-insensitive, 'm' for multi-line matching, etc.).
subexpression_start_position (optional): The start position of the subexpression (for patterns with capturing groups).
subexpression_length (optional): The length of the subexpression to return (if applicable).

Return Value:
By default, REGEXP_INSTR returns the position of the first character of the first match. If no match is found, it returns 0.
If return_option is set to 1, it returns the match string instead of the position.
Example Queries for REGEXP_INSTR on Employee Table
Let’s assume you are working with the same employees table, and we'll use REGEXP_INSTR to perform various operations on the email and phone_number columns.

1. Find the Position of '@' in the Email Address:

SELECT employee_id, email, REGEXP_INSTR(email, '@', 1, 1) AS at_position
FROM employees;

Explanation: This will return the position of the first occurrence of the '@' symbol in each employee's email address.

2. Find the Position of the First Number in the Phone Number:

SELECT employee_id, phone_number, REGEXP_INSTR(phone_number, '\d', 1, 1) AS first_digit_position
FROM employees;

Explanation: This will return the position of the first digit in the phone_number column. The regular expression \d matches any digit.

3. Find the First Occurrence of a Substring in the Job Title (Case-Insensitive Match):

SELECT employee_id, job_title, REGEXP_INSTR(job_title, 'Engineer', 1, 1, 0, 'i') AS engineer_position
FROM employees;

Explanation: This will return the position of the first occurrence of the word "Engineer" (case-insensitive) in the job_title column.

4. Find the Position of the First Space in the Full Name (Concatenated First and Last Names):

SELECT employee_id, first_name, last_name, 
       REGEXP_INSTR(first_name || ' ' || last_name, ' ', 1, 1) AS space_position
FROM employees;

Explanation: This will return the position of the first space between the first_name and last_name.

5. Return the Email Domain Using Subexpression (Capture Group):
If you want to extract the domain part of the email (everything after the '@'), you can use a regular expression with a capture group.

SELECT employee_id, email,
       REGEXP_INSTR(email, '@([A-Za-z0-9.-]+)', 1, 1, 0, NULL, 1) AS email_domain
FROM employees;

Explanation: This will return the domain part of the email address (e.g., "example.com"). The ([A-Za-z0-9.-]+) is a capturing group that matches the domain part of the email.

6. Find the Position of the First Digit in the Phone Number Using a Subexpression:

SELECT employee_id, phone_number, 
       REGEXP_INSTR(phone_number, '\d', 1, 1, 0) AS first_digit_position
FROM employees;

Explanation: This query finds the position of the first digit in the phone_number column.

7. Find the Position of the First Occurrence of 'Manager' in Job Titles (Case-Insensitive):

SELECT employee_id, job_title, 
       REGEXP_INSTR(job_title, 'Manager', 1, 1, 0, 'i') AS manager_position
FROM employees;

Explanation: This will return the position of the first occurrence of the word "Manager" (case-insensitive) in the job_title column.

Example Output:
For the query to find the position of the '@' in the email:

SELECT employee_id, email, REGEXP_INSTR(email, '@', 1, 1) AS at_position
FROM employees;

3. REGEXP_SUBSTR function is used to return the substring that matches a regular expression pattern within a string. This function is useful when you want to extract a portion of a string that matches a specified regular expression pattern.

Complete Syntax of REGEXP_SUBSTR:

REGEXP_SUBSTR (
    string,
    pattern,
    start_position,
    match_occurrence,
    return_option,
    match_modifier,
    subexpression_start_position,
    subexpression_length
)

Parameters:
string: The string (or column) in which to search.
pattern: The regular expression pattern to search for.
start_position (optional): The position to start the search from. Default is 1 (the beginning of the string).
match_occurrence (optional): The occurrence of the match to return. Default is 1 (the first match).
return_option (optional): Specifies what to return:
0 or TRUE (default): Returns the substring that matches the pattern.
1: Returns the full match (same as TRUE in most cases).
match_modifier (optional): Modifiers that control the matching behavior (e.g., 'i' for case-insensitive, 'm' for multi-line matching).
subexpression_start_position (optional): The start position of the subexpression (if you're working with capturing groups).
subexpression_length (optional): The length of the subexpression to return (if applicable).
Return Value:
REGEXP_SUBSTR returns the substring that matches the regular expression pattern. If no match is found, it returns NULL.

1. Extract the Domain from the Email Address:
If you want to extract the domain part (e.g., example.com) from an email address:

SELECT employee_id, email,
       REGEXP_SUBSTR(email, '@([A-Za-z0-9.-]+)', 1, 1, NULL, 1) AS email_domain
FROM employees;

Explanation: The regular expression '@([A-Za-z0-9.-]+)' captures the domain part after the @ symbol. The 1 at the end specifies the first captured subexpression (the domain).

2. Extract the First Word (First Name) from the Full Name (Concatenated First and Last Name):

SELECT employee_id, first_name, last_name,
       REGEXP_SUBSTR(first_name || ' ' || last_name, '^\S+', 1, 1) AS first_word
FROM employees;

Explanation: The regular expression ^\S+ matches the first non-space sequence of characters at the beginning of the string. This would return the first name from the concatenated first_name and last_name.

3. Extract the Area Code from the Phone Number (Assuming the Format is (XXX) XXX-XXXX):

SELECT employee_id, phone_number,
       REGEXP_SUBSTR(phone_number, '\((\d{3})\)', 1, 1, NULL, 1) AS area_code
FROM employees;

Explanation: The regular expression \((\d{3})\) captures the area code (the three digits inside the parentheses). The 1 at the end specifies the first captured subexpression, which is the area code.

4. Extract the Job Title if it Contains 'Manager' (Case-Insensitive Match):

SELECT employee_id, job_title,
       REGEXP_SUBSTR(job_title, 'Manager', 1, 1, 0, 'i') AS manager_title
FROM employees;

Explanation: The query returns the word "Manager" if it appears in the job_title (case-insensitive due to 'i' modifier). It will return NULL if "Manager" isn't present.

5. Extract the First Digit in the Phone Number:

SELECT employee_id, phone_number,
       REGEXP_SUBSTR(phone_number, '\d', 1, 1) AS first_digit
FROM employees;

Explanation: The regular expression \d matches the first digit in the phone_number column. This will return the first digit found in the phone number.

6. Extract the Middle Initial from the Full Name (Assuming the Format: First Middle Last):

SELECT employee_id, first_name, middle_name, last_name,
       REGEXP_SUBSTR(first_name || ' ' || middle_name || ' ' || last_name, '\s([A-Za-z])\s', 1, 1, NULL, 1) AS middle_initial
FROM employees;

Explanation: The regular expression \s([A-Za-z])\s captures a single letter between spaces (assumed to be the middle initial). This will return the middle initial for employees with a middle name.

7. Extract the Last Name from the Full Name (Concatenated First and Last Name):

SELECT employee_id, first_name, last_name,
       REGEXP_SUBSTR(first_name || ' ' || last_name, '\s([A-Za-z]+)$', 1, 1, NULL, 1) AS last_name_extracted FROM employees;

Explanation: The regular expression \s([A-Za-z]+)$ matches the last word in the string (assumed to be the last name) by looking for the sequence of alphabetic characters at the end of the string.

Example Output:
For the query to extract the email domain:

SELECT employee_id, email,
       REGEXP_SUBSTR(email, '@([A-Za-z0-9.-]+)', 1, 1, NULL, 1) AS email_domain
FROM employees;


4. REGEXP_REPLACE function is used to search for a regular expression pattern in a string and replace it with a specified replacement string. This is useful when you want to modify the content of a string based on patterns.

Complete Syntax of REGEXP_REPLACE:

REGEXP_REPLACE (
    string,
    pattern,
    replace_string,
    start_position,
    match_occurrence,
    return_option,
    match_modifier
)

Parameters:
string: The string (or column) in which to search and replace.
pattern: The regular expression pattern to search for.
replace_string: The string that will replace the matching pattern.
start_position (optional): The position to start the search. Default is 1 (the beginning of the string).
match_occurrence (optional): The occurrence of the match to replace. Default is 0, which means all matches will be replaced.
return_option (optional): Specifies what to return:
0 (default): Returns the modified string.
1: Returns the modified string and the number of replacements.
match_modifier (optional): Modifiers that control the matching behavior (e.g., 'i' for case-insensitive, 'm' for multi-line matching, 'n' for allowing . to match newlines, etc.).

Return Value:
The function returns the string with the pattern replaced by the replace_string. If no match is found, the original string is returned.

1. Remove All Non-Digit Characters from Phone Number:

SELECT employee_id, phone_number,
       REGEXP_REPLACE(phone_number, '\D', '') AS clean_phone_number
FROM employees;

Explanation: This will remove all non-digit characters from the phone_number column (leaving only the digits). The regular expression '[^\d]' matches any character that is not a digit.

2. Replace Domain in Email Address with a New Domain:

SELECT employee_id, email,
       REGEXP_REPLACE(email, '@[A-Za-z0-9.-]+', '@newdomain.com') AS updated_email
FROM employees;

Explanation: This will replace the domain part of the email address (everything after the @) with @newdomain.com. The regular expression '@[A-Za-z0-9.-]+' matches the domain part of the email address.

3. Convert Phone Numbers to a Standard Format (Assume Format: (XXX) XXX-XXXX):

SELECT employee_id, phone_number,
       REGEXP_REPLACE(phone_number, '(\d{3})(\d{3})(\d{4})', '(\1) \2-\3') AS formatted_phone_number FROM employees;

Explanation: This will reformat the phone number into the standard format (XXX) XXX-XXXX. The regular expression (\d{3})(\d{3})(\d{4}) groups the digits into three parts and then inserts them into the desired format.

4. Remove Extra Spaces from Job Titles (Trim Multiple Spaces Between Words):

SELECT employee_id, job_title,
       REGEXP_REPLACE(job_title, '\s+', ' ') AS trimmed_job_title
FROM employees;

Explanation: This query will replace multiple spaces between words in the job_title column with a single space. The regular expression \s+ matches one or more whitespace characters.

5. Replace All Lowercase 'manager' with 'MANAGER' in Job Titles (Case-Insensitive Match):

SELECT employee_id, job_title,
       REGEXP_REPLACE(job_title, 'manager', 'MANAGER', 1, 0, 'i') AS updated_job_title
FROM employees;

Explanation: This will replace the word "manager" with "MANAGER" in the job_title column, ignoring case (due to the 'i' modifier). The query will replace all occurrences of "manager", regardless of case.

6. Replace All Non-Alphabetic Characters in First Name:

SELECT employee_id, first_name,
       REGEXP_REPLACE(first_name, '[^A-Za-z]', '') AS clean_first_name
FROM employees;

Explanation: This will remove all non-alphabetic characters from the first_name column. The regular expression '[^A-Za-z]' matches any character that is not an alphabet letter.

7. Add a Prefix to Email Address (e.g., "new_" to the Username):

SELECT employee_id, email,
       REGEXP_REPLACE(email, '^([A-Za-z0-9._%+-]+)', 'new_\1') AS prefixed_email
FROM employees;

Explanation: This will add the prefix new_ to the username part of the email address (everything before the @). The regular expression ^([A-Za-z0-9._%+-]+) captures the username part, and \1 refers to the captured username, which is then prefixed with new_.

8. Replace All Occurrences of 'Engineer' with 'Software Developer' in Job Titles:

SELECT employee_id, job_title,
       REGEXP_REPLACE(job_title, 'Engineer', 'Software Developer') AS updated_job_title
FROM employees;

Explanation: This will replace all occurrences of the word "Engineer" with "Software Developer" in the job_title column.

Example Output:
For the query to remove all non-digit characters from the phone number:

SELECT employee_id, phone_number,
       REGEXP_REPLACE(phone_number, '[^\d]', '') AS clean_phone_number
FROM employees;

5. REGEXP_COUNT function is used to return the number of occurrences of a regular expression pattern in a string. This function is useful when you need to count how many times a specific pattern appears in a string.

Complete Syntax of REGEXP_COUNT:

REGEXP_COUNT (
    string,
    pattern,
    start_position,
    match_occurrence,
    return_option,
    match_modifier
)

Parameters:
string: The string (or column) in which to search for the pattern.
pattern: The regular expression pattern to search for.
start_position (optional): The position to start the search from. Default is 1 (the beginning of the string).
match_occurrence (optional): The occurrence of the match to return. Default is 0, which means it counts all occurrences.
return_option (optional): Specifies what to return:
0 (default): Returns the count of matches.
1: Returns the first match (not typically used for counting occurrences).
match_modifier (optional): Modifiers that control the matching behavior (e.g., 'i' for case-insensitive, 'm' for multi-line matching, etc.).

Return Value:
REGEXP_COUNT returns an integer value representing the number of matches found in the string. If no match is found, it returns 0.

1. Count the Number of Digits in the Phone Number:

SELECT employee_id, phone_number,
       REGEXP_COUNT(phone_number, '\d') AS digit_count
FROM employees;

Explanation: This query will count the number of digits in each employee's phone_number. The regular expression \d matches any digit.

2. Count the Occurrences of '@' in Email Address:

SELECT employee_id, email,
       REGEXP_COUNT(email, '@') AS at_symbol_count
FROM employees;

Explanation: This will count how many times the '@' symbol appears in the email column. The pattern '@' simply looks for the '@' symbol in each email.

3. Count the Number of Words in the Job Title (Separated by Spaces):

SELECT employee_id, job_title,
       REGEXP_COUNT(job_title, '\w+') AS word_count
FROM employees;

Explanation: This will count the number of words in the job_title. The regular expression \w+ matches sequences of alphanumeric characters (words). This count will return the number of words in each job_title.

4. Count the Occurrences of 'Manager' in Job Titles (Case-Insensitive Match):

SELECT employee_id, job_title,
       REGEXP_COUNT(job_title, 'Manager', 1, 0, 'i') AS manager_count
FROM employees;

Explanation: This will count how many times the word "Manager" appears in the job_title column, case-insensitively. The 'i' modifier ensures the search ignores case (e.g., "manager", "MANAGER", "ManAgEr" all count).

5. Count the Occurrences of Digits in the Email Address:

SELECT employee_id, email,
       REGEXP_COUNT(email, '\d') AS digit_in_email_count
FROM employees;

Explanation: This will count how many digits appear in the email address. The regular expression \d is used to match any digit in the email.

6. Count the Number of Vowels (A, E, I, O, U) in the First Name:

SELECT employee_id, first_name,
       REGEXP_COUNT(first_name, '[AEIOUaeiou]') AS vowel_count
FROM employees;

Explanation: This will count how many vowels (both uppercase and lowercase) appear in each employee's first_name. The pattern [AEIOUaeiou] matches any vowel.

7. Count the Occurrences of 'Software' in Job Titles (Exact Match, Case-Insensitive):

SELECT employee_id, job_title,
       REGEXP_COUNT(job_title, '\bSoftware\b', 1, 0, 'i') AS software_count
FROM employees;

Explanation: This query will count the number of times the word "Software" appears in the job_title column. The word boundary \b ensures that it matches the word "Software" as a whole, and the 'i' modifier makes it case-insensitive.

Example Output:
For the query to count the number of digits in the phone number:

SELECT employee_id, phone_number,
       REGEXP_COUNT(phone_number, '\d') AS digit_count
FROM employees;

-----------------------------------------------------------------------------------------------------------------------------------------------------------

REG_EXP Handson

order_id	customer_id	order_date	 order_status	shipping_zip	product_code	total_amount
1001		501				2025-02-01	   Shipped			90210		PROD12345			250.75	
1002		502				2025-02-02		Pending		12345		PROD67890			120.00	
1003		503				2025-02-03		Canceled		90211		PROD23456			300.50	
1004		504				2025-02-04		Shipped		90212		PROD98765			50.00	
1005		505				2025-02-05		Shipped		55555		PROD54321			150.00	
1006		506				2025-02-06		Pending		90213		PROD11111			225.25	
1007		507				2025-02-07		Shipped		90214		PROD22222			375.00	
1008		508				2025-02-08		Canceled		90215		PROD33333			500.00	
1009		509				2025-02-09		Shipped		90216		PROD44444			350.00	
1010		510				2025-02-10		Shipped		90217		PROD55555			450.00

1. Check if order_status is either 'Shipped', 'Pending', or 'Canceled'

SELECT order_id, order_status
FROM orders
WHERE REGEXP_LIKE(order_status, '^(Shipped|Pending|Canceled)$');

2. Find orders where shipping_zip starts with '902'

SELECT order_id, shipping_zip
FROM orders
WHERE REGEXP_LIKE(shipping_zip, '^902');

3. Find orders with invalid product codes (i.e., those that contain non-alphanumeric characters)

SELECT order_id, product_code
FROM orders
WHERE REGEXP_LIKE(product_code, '[^A-Za-z0-9]');

4. Find the position of the first numeric digit in order_notes

SELECT order_id, REGEXP_INSTR(order_notes, '\d', 1, 1) AS digit_position
FROM orders
WHERE REGEXP_INSTR(order_notes, '\d', 1, 1) > 0;

5. Find the position of the first occurrence of the word "damaged" in order_notes

SELECT order_id, REGEXP_INSTR(order_notes, 'damaged', 1, 1) AS damaged_position
FROM orders
WHERE REGEXP_INSTR(order_notes, 'damaged', 1, 1) > 0;

6. Extract the first date (in YYYY-MM-DD format) from order_notes

SELECT order_id, REGEXP_SUBSTR(order_notes, '\d{4}-\d{2}-\d{2}', 1, 1) AS extracted_date
FROM orders
WHERE REGEXP_SUBSTR(order_notes, '\d{4}-\d{2}-\d{2}', 1, 1) IS NOT NULL;

7. Extract the first three digits from shipping_zip

SELECT order_id, REGEXP_SUBSTR(shipping_zip, '^\d{3}', 1, 1) AS first_three_digits
FROM orders
WHERE REGEXP_SUBSTR(shipping_zip, '^\d{3}', 1, 1) IS NOT NULL;

8. Replace all non-numeric characters in shipping_zip with empty strings

SELECT order_id, REGEXP_REPLACE(shipping_zip, '[^0-9]', '') AS clean_zip
FROM orders;

9. Replace all instances of "damaged" with "returned" in order_notes

SELECT order_id, REGEXP_REPLACE(order_notes, 'damaged', 'returned', 1, 0, 'i') AS updated_notes
FROM orders;

10. Count how many times the word "Shipped" appears in order_notes

SELECT order_id, REGEXP_COUNT(order_notes, 'Shipped') AS shipped_count
FROM orders;

11. Count the number of digits in order_notes

SELECT order_id, REGEXP_COUNT(order_notes, '\d') AS digit_count
FROM orders;

-------------------------------------------------------------------------------------
Academy management system

1. students Table

student_id		student_name	student_email					student_phone
1001			John Doe		john.doe@example.com			123-456-7890
1002			Jane Smith		jane.smith@school.org		(555) 123-4567
1003			Emily Davis	emily.davis@gmail.com		987-654-3210
1004			Michael Brown	michael_brown@edu.com		555-111-2222
1005			Sarah Lee		sarah.lee@university.edu	123.123.1234

2. courses Table

course_id		course_name						course_description
C101			Introduction to Mathematics		Basic math principles and algebra
C102			Advanced Programming	          Data structures, algorithms, and advanced 																topics
C103			History of Art				   A study of art history from the Renaissance
C104			Physics 101						Fundamentals of physics
C105			Calculus for Engineers			Calculus with an emphasis on engineering 															topics

1. Validate student email

SELECT student_name, student_email
FROM students
WHERE REGEXP_LIKE(student_email, '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$');

2. Validate student ID format (e.g., 4 digits)

SELECT student_id, student_name
FROM students
WHERE REGEXP_LIKE(student_id, '^\d{4}$');

3. Find course names that contain the word "math"

SELECT course_id, course_name
FROM courses
WHERE REGEXP_INSTR(course_name, 'math', 1, 1, 0) > 0;

4. Extract domain name from student email

SELECT student_email, REGEXP_SUBSTR(student_email, '@(.+)$', 1, 1, NULL, 1) AS domain
FROM students;

5. Extract first word of course name

SELECT course_name, REGEXP_SUBSTR(course_name, '^\S+', 1, 1) AS first_word
FROM courses;

6. Remove non-numeric characters from student phone number

SELECT student_name, REGEXP_REPLACE(student_phone, '[^0-9]', '') AS cleaned_phone
FROM students;

7. Replace spaces with underscores in course names

SELECT course_name, REGEXP_REPLACE(course_name, '\s+', '_') AS course_name_with_underscores
FROM courses;

8. Count the number of vowels in a student's name

SELECT student_name, REGEXP_COUNT(student_name, '[AEIOUaeiou]') AS vowel_count
FROM students;

--------------------------------------------------------------------------------------
Product system

CREATE TABLE products (
    product_id NUMBER PRIMARY KEY,
    product_name VARCHAR2(100),
    product_category VARCHAR2(50),
    product_description VARCHAR2(255),
    product_code VARCHAR2(20),
    price NUMBER
);

-- Sample data insertion
INSERT INTO products (product_id, product_name, product_category, product_description, product_code, price) VALUES
(1, 'Laptop', 'Electronics', 'High-performance laptop with 16GB RAM, 512GB SSD, and Intel i7 processor.', 'PROD-12345', 999.99),
(2, 'Smartphone', 'Electronics', 'Latest 5G smartphone with 128GB storage and 6.5-inch display.', 'PROD-67890', 799.49),
(3, 'Wireless Headphones', 'Electronics', 'Bluetooth-enabled wireless headphones with noise cancellation feature.', 'PROD-11223', 150.00),
(4, 'Smart Watch', 'Electronics', 'Wearable smartwatch with fitness tracking and heart rate monitor.', 'PROD-33445', 250.00),
(5, 'Running Shoes', 'Clothing', 'Comfortable running shoes with a breathable mesh upper and cushioned sole.', 'SHOE-12345', 49.99),
(6, 'Leather Jacket', 'Clothing', 'Stylish leather jacket, perfect for cold weather and casual wear.', 'JACK-67890', 120.00),
(7, 'Winter Jacket', 'Clothing', 'Insulated jacket for extreme winter conditions with a waterproof exterior.', 'JACK-11223', 199.99),
(8, 'T-shirt', 'Clothing', 'Cotton t-shirt with custom prints and available in various sizes.', 'TEE-99887', 15.99),
(9, 'Bluetooth Speaker', 'Electronics', 'Portable Bluetooth speaker with rich sound and waterproof design.', 'PROD-55432', 89.99),
(10, 'Tablet', 'Electronics', '10-inch tablet with 4GB RAM, 64GB storage, and full HD display.', 'PROD-66554', 329.99),
(11, 'Gaming Console', 'Electronics', 'Latest gaming console with 1TB storage, supports 4K resolution and VR.', 'GAME-77777', 499.99),
(12, 'Camera', 'Electronics', 'DSLR camera with 24MP resolution, 4K video recording, and Wi-Fi connectivity.', 'CAM-99888', 749.00),
(13, 'Backpack', 'Accessories', 'Durable backpack with multiple compartments for laptops, books, and accessories.', 'BAG-11223', 39.99),
(14, 'Smart Thermostat', 'Home Appliances', 'Wi-Fi enabled smart thermostat that can be controlled remotely via an app.', 'HOM-22334', 119.99),
(15, 'Electric Kettle', 'Home Appliances', '1.7-liter electric kettle with automatic shut-off and temperature control.', 'HOM-55667', 34.99),
(16, 'Portable Charger', 'Electronics', 'Compact portable charger with 20,000mAh capacity for fast charging.', 'PROD-99999', 45.99);

1. Write query to return product codes that do not match the format PROD-##### (5 digits after the dash

SELECT product_code
FROM products
WHERE NOT REGEXP_LIKE(product_code, '^PROD-\d{5}$');


2. Write query to return products whose name contains the word "headphones" (case-insensitive).

SELECT product_name
FROM products
WHERE REGEXP_LIKE(product_name, 'headphones', 'i');

3. Write query to  extracts the price from the product description (if it exists), including the optional dollar sign.

SELECT product_name,
       REGEXP_SUBSTR(product_description, '(\$?\d+(\.\d{2})?)', 1, 1) AS price
FROM products;

4. Write query returns products that contain both "running" and "shoes" (case-insensitive) in their names.

SELECT product_name, product_description
FROM products
WHERE REGEXP_LIKE(product_name, 'running', 'i') 
  AND REGEXP_LIKE(product_name, 'shoes', 'i');


5. Write query to removes all special characters, leaving only alphanumeric characters and spaces in the product descriptions.

SELECT product_name,
       REGEXP_REPLACE(product_description, '[^a-zA-Z0-9 ]', '', 1, 0) AS cleaned_description
FROM products;

6. Write query to extracts the numeric part of the product code from strings like PROD-12345

SELECT product_name,
       REGEXP_SUBSTR(product_code, '\d+', 1, 1) AS product_code_number
FROM products;

7. Write query to counts the number of times "wireless" appears in the product_description, case-insensitive 

SELECT product_name,
       REGEXP_COUNT(product_description, 'wireless', 'i') AS wireless_count
FROM products;

8. Write query to counts how many times the word "Bluetooth" appears in the product_description, case-insensitive.

SELECT product_name,
       REGEXP_COUNT(product_description, 'Bluetooth', 'i') AS bluetooth_count
FROM products;

9. Find the Position of the First Digit in Product Code

SELECT product_name,
       REGEXP_INSTR(product_code, '\d', 1, 1) AS first_digit_position
FROM products;

10. Find the Position of the Second Occurrence of the Word "Jacket" in the Product Name

SELECT product_name,
       REGEXP_INSTR(product_name, 'Jacket', 1, 2, 0, 'i') AS second_jacket_position
FROM products;

------------------------------------------------------------------------------------------------------------------------------------------------------------
WAREHOUSE SYSTEM

CREATE TABLE WAREHOUSES (
    WAREHOUSE_ID INT PRIMARY KEY,
    WAREHOUSE_NAME VARCHAR(255),
    REGION VARCHAR(255)
);

CREATE TABLE PRODUCTS (
    PRODUCT_ID INT PRIMARY KEY,
    PRODUCT_NAME VARCHAR(255),
    CATEGORY VARCHAR(255)
);

CREATE TABLE INVENTORY (
    WAREHOUSE_ID INT,
    PRODUCT_ID INT,
    QUANTITY INT,
    FOREIGN KEY (WAREHOUSE_ID) REFERENCES WAREHOUSES(WAREHOUSE_ID),
    FOREIGN KEY (PRODUCT_ID) REFERENCES PRODUCTS(PRODUCT_ID),
    PRIMARY KEY (WAREHOUSE_ID, PRODUCT_ID)
);

CREATE TABLE SALES (
    SALE_ID INT PRIMARY KEY,
    PRODUCT_ID INT,
    WAREHOUSE_ID INT,
    SALE_DATE DATE,
    QUANTITY_SOLD INT,
    FOREIGN KEY (PRODUCT_ID) REFERENCES PRODUCTS(PRODUCT_ID),
    FOREIGN KEY (WAREHOUSE_ID) REFERENCES WAREHOUSES(WAREHOUSE_ID)
);

-- Insert data into WAREHOUSES table
INSERT ALL 
    INTO WAREHOUSES (WAREHOUSE_ID, WAREHOUSE_NAME, REGION) VALUES (1, 'Central Depot', 'North')
    INTO WAREHOUSES (WAREHOUSE_ID, WAREHOUSE_NAME, REGION) VALUES (2, 'Southern Depot', 'South')
    INTO WAREHOUSES (WAREHOUSE_ID, WAREHOUSE_NAME, REGION) VALUES (3, 'Eastern Depot', 'East')
    INTO WAREHOUSES (WAREHOUSE_ID, WAREHOUSE_NAME, REGION) VALUES (4, 'Western Depot', 'West')
    INTO WAREHOUSES (WAREHOUSE_ID, WAREHOUSE_NAME, REGION) VALUES (5, 'Northern Depot', 'North')
SELECT * FROM dual;


-- Insert data into PRODUCTS table
INSERT ALL 
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (101, 'Laptop', 'Electronics')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (102, 'Mobile Phone', 'Electronics')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (103, 'Office Chair', 'Furniture')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (104, 'Desk', 'Furniture')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (105, 'Printer', 'Electronics')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (106, 'Monitor', 'Electronics')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (107, 'Keyboard', 'Electronics')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (108, 'Sofa', 'Furniture')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (109, 'Lamp', 'Furniture')
    INTO PRODUCTS (PRODUCT_ID, PRODUCT_NAME, CATEGORY) VALUES (110, 'Scanner', 'Electronics')
SELECT * FROM dual;

-- Insert data into INVENTORY table
INSERT ALL 
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (1, 101, 50)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (1, 102, 100)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (1, 103, 30)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (2, 101, 20)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (2, 104, 25)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (2, 105, 15)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (3, 101, 0)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (3, 103, 10)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (3, 105, 5)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (4, 101, 50)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (4, 106, 20)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (5, 105, 25)
    INTO INVENTORY (WAREHOUSE_ID, PRODUCT_ID, QUANTITY) VALUES (5, 109, 15)
SELECT * FROM dual;

-- Insert data into SALES table
INSERT ALL 
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (1, 101, 1, TO_DATE('2025-01-01', 'YYYY-MM-DD'), 10)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (2, 102, 1, TO_DATE('2025-01-03', 'YYYY-MM-DD'), 30)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (3, 103, 1, TO_DATE('2025-01-05', 'YYYY-MM-DD'), 5)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (4, 101, 2, TO_DATE('2025-01-02', 'YYYY-MM-DD'), 15)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (5, 104, 2, TO_DATE('2025-01-06', 'YYYY-MM-DD'), 20)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (6, 105, 3, TO_DATE('2025-01-07', 'YYYY-MM-DD'), 5)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (7, 106, 1, TO_DATE('2025-01-10', 'YYYY-MM-DD'), 20)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (8, 107, 2, TO_DATE('2025-01-11', 'YYYY-MM-DD'), 10)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (9, 108, 3, TO_DATE('2025-01-12', 'YYYY-MM-DD'), 4)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (10, 109, 3, TO_DATE('2025-01-14', 'YYYY-MM-DD'), 6)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (11, 110, 4, TO_DATE('2025-01-15', 'YYYY-MM-DD'), 3)
    INTO SALES (SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD) VALUES (12, 107, 5, TO_DATE('2025-01-16', 'YYYY-MM-DD'), 15)
SELECT * FROM dual;

1. Write a query to find all products in each warehouse where the available quantity is less than 10. Display the WAREHOUSE_NAME, PRODUCT_NAME, CATEGORY, and QUANTITY.

SELECT w.WAREHOUSE_NAME, p.PRODUCT_NAME, p.CATEGORY, i.QUANTITY FROM 
INVENTORY i JOIN WAREHOUSES w ON i.WAREHOUSE_ID = w.WAREHOUSE_ID
JOIN PRODUCTS p ON i.PRODUCT_ID = p.PRODUCT_ID
WHERE i.QUANTITY < 10
ORDER BY w.WAREHOUSE_NAME, p.PRODUCT_NAME;

2. Calculate the total stock of products in each warehouse.

SELECT w.WAREHOUSE_NAME, SUM(i.QUANTITY) AS TOTAL_STOCK FROM INVENTORY i
JOIN WAREHOUSES w ON i.WAREHOUSE_ID = w.WAREHOUSE_ID
GROUP BY w.WAREHOUSE_NAME ORDER BY TOTAL_STOCK DESC;

3. Find warehouses where the total stock exceeds 200 units.

SELECT w.WAREHOUSE_NAME, SUM(i.QUANTITY) AS TOTAL_STOCK FROM 
INVENTORY i JOIN WAREHOUSES w ON i.WAREHOUSE_ID = w.WAREHOUSE_ID
GROUP BY w.WAREHOUSE_NAME
HAVING SUM(i.QUANTITY) > 200
ORDER BY TOTAL_STOCK DESC;

4. Identify warehouses where the total stock is below the overall average total stock across all warehouses.

WITH AvgStock AS (
    SELECT AVG(SUM(QUANTITY)) AS OVERALL_AVERAGE
    FROM INVENTORY
    GROUP BY WAREHOUSE_ID
)
SELECT w.WAREHOUSE_NAME, SUM(i.QUANTITY) AS TOTAL_STOCK
FROM INVENTORY i
JOIN WAREHOUSES w ON i.WAREHOUSE_ID = w.WAREHOUSE_ID
GROUP BY w.WAREHOUSE_NAME
HAVING SUM(i.QUANTITY) < (SELECT OVERALL_AVERAGE FROM AvgStock)
ORDER BY TOTAL_STOCK ASC;


5. Calculate the total quantity sold for each product category across all warehouses.

SELECT p.CATEGORY,SUM(s.QUANTITY_SOLD) AS TOTAL_SALES FROM SALES s
JOIN PRODUCTS p ON s.PRODUCT_ID = p.PRODUCT_ID
GROUP BY p.CATEGORY
ORDER BY TOTAL_SALES DESC;

6. List products where the total quantity sold across all warehouses is less than 50 units.

SELECT p.PRODUCT_NAME,SUM(s.QUANTITY_SOLD) AS TOTAL_SALES FROM SALES s
JOIN PRODUCTS p ON s.PRODUCT_ID = p.PRODUCT_ID
GROUP BY p.PRODUCT_NAME
HAVING SUM(s.QUANTITY_SOLD) < 50
ORDER BY TOTAL_SALES ASC;

7. Find the product with the maximum stock in each warehouse.

SELECT w.WAREHOUSE_NAME,
       p.PRODUCT_NAME,
       i.QUANTITY AS MAX_STOCK
FROM INVENTORY i
JOIN WAREHOUSES w ON i.WAREHOUSE_ID = w.WAREHOUSE_ID
JOIN PRODUCTS p ON i.PRODUCT_ID = p.PRODUCT_ID
WHERE i.QUANTITY = (
    SELECT MAX(QUANTITY)
    FROM INVENTORY
    WHERE WAREHOUSE_ID = i.WAREHOUSE_ID
)
ORDER BY w.WAREHOUSE_NAME;


8. List warehouses that have not sold any products.

SELECT w.WAREHOUSE_NAME FROM WAREHOUSES w
LEFT JOIN SALES s ON w.WAREHOUSE_ID = s.WAREHOUSE_ID
WHERE s.SALE_ID IS NULL
ORDER BY w.WAREHOUSE_NAME;

9. Rank products by total sales quantity across all warehouses

SELECT PRODUCT_ID, SUM(QUANTITY_SOLD) AS TOTAL_SALES,
    RANK() OVER (ORDER BY SUM(QUANTITY_SOLD) DESC) AS SALES_RANK
FROM SALES
GROUP BY PRODUCT_ID;


10. Compare current and previous product sales in each warehouse

SELECT SALE_ID, PRODUCT_ID, WAREHOUSE_ID, SALE_DATE, QUANTITY_SOLD,
    LAG(QUANTITY_SOLD) OVER (PARTITION BY WAREHOUSE_ID ORDER BY SALE_DATE) AS PREV_SALE,
    LEAD(QUANTITY_SOLD) OVER (PARTITION BY WAREHOUSE_ID ORDER BY SALE_DATE) AS NEXT_SALE
FROM SALES;

--------------------------------------------------------------------------------------------------------------------------------------------------------------
WINDOWS FUNCTION HANDSON

Schema Definition:
sales Table:

CREATE TABLE sales (
    sale_id INT PRIMARY KEY,
    customer_id INT,
    product_id INT,
    sale_date DATE,
    sale_amount DECIMAL(10, 2)
);

Sample Data for sales Table:

INSERT INTO sales (sale_id, customer_id, product_id, sale_date, sale_amount) VALUES
(1, 101, 1, TO_DATE('2023-01-10', 'YYYY-MM-DD'), 150.00),
(2, 102, 2, TO_DATE('2023-01-12', 'YYYY-MM-DD'), 200.00),
(3, 101, 1, TO_DATE('2023-01-15', 'YYYY-MM-DD'), 100.00),
(4, 103, 3, TO_DATE('2023-01-20', 'YYYY-MM-DD'), 300.00),
(5, 101, 2, TO_DATE('2023-02-01', 'YYYY-MM-DD'), 250.00),
(6, 102, 1, TO_DATE('2023-02-05', 'YYYY-MM-DD'), 175.00),
(7, 101, 3, TO_DATE('2023-02-10', 'YYYY-MM-DD'), 120.00),
(8, 104, 2, TO_DATE('2023-02-15', 'YYYY-MM-DD'), 225.00);


1. Scenario:  You want to list the sales transactions of each customer and assign a unique sequence number to each sale ordered by sale date.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY sale_date) AS row_num
FROM sales
ORDER BY customer_id, sale_date;

Explanation:

This query assigns a unique number (row_num) for each sale within a customer_id, ordered by the sale_date.
For each customer, the sales are numbered sequentially based on the order they occurred.

2. Scenario: You want to rank sales by amount for each customer, where sales with the same amount should get the same rank, but there will be gaps in ranking.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    RANK() OVER (PARTITION BY customer_id ORDER BY sale_amount DESC) AS rank
FROM sales
ORDER BY customer_id, rank;

Explanation:

RANK() is used here to rank sales within each customer_id based on the sale_amount in descending order.
If two sales have the same amount, they will share the same rank, but the next rank will be skipped (i.e., if two sales share rank 1, the next sale will have rank 3).

3. Scenario: Ranking sales based on sale amount without gaps for ties.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY sale_amount DESC) AS dense_rank
FROM sales
ORDER BY customer_id, dense_rank;

4. Scenario: You want to compare each sale amount with the next sale amount for the same customer.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    LEAD(sale_amount, 1) OVER (PARTITION BY customer_id ORDER BY sale_date) AS next_sale_amount
FROM sales
ORDER BY customer_id, sale_date;

5. Scenario: Finding the previous sale amount for each sale.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    LAG(sale_amount, 1) OVER (PARTITION BY customer_id ORDER BY sale_date) AS previous_sale_amount
FROM sales
ORDER BY customer_id, sale_date;

6. find the top 3 highest sales for each customer.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY sale_amount DESC) AS row_num
FROM sales
WHERE row_num <= 3
ORDER BY customer_id, row_num;

7. Scenario: You want to rank the sales for each customer based on sale_amount and find the sales with the same rank across different customers.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    RANK() OVER (ORDER BY sale_amount DESC) AS overall_rank
FROM sales
ORDER BY overall_rank;

8. Scenario: You want to group customers who have the same total sales amount into the same rank.

SELECT 
    customer_id,
    SUM(sale_amount) AS total_sales,
    DENSE_RANK() OVER (ORDER BY SUM(sale_amount) DESC) AS sales_rank
FROM sales
GROUP BY customer_id
ORDER BY sales_rank;

9. Scenario: Identify customers with the highest and lowest sales.

SELECT 
    customer_id,
    SUM(sale_amount) AS total_sales,
    RANK() OVER (ORDER BY SUM(sale_amount) DESC) AS sales_rank
FROM sales
GROUP BY customer_id
ORDER BY sales_rank;

10. Scenario: Find the first and last sale for each customer.

SELECT 
    sale_id,
    customer_id,
    product_id,
    sale_date,
    sale_amount,
    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY sale_date) AS first_sale,
    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY sale_date DESC) AS last_sale
FROM sales
WHERE first_sale = 1 OR last_sale = 1
ORDER BY customer_id, sale_date;

-------------------------------------------------------------------------------------

Employee system

CREATE TABLE employee (
    emp_id NUMBER PRIMARY KEY,
    emp_name VARCHAR2(100),
    department_id NUMBER,
    salary NUMBER,
    hire_date DATE
);


-- Insert data into employee table
INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (1, 'John', 10, 50000, TO_DATE('2010-01-01', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (2, 'Alice', 20, 60000, TO_DATE('2012-03-15', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (3, 'Bob', 10, 70000, TO_DATE('2014-05-10', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (4, 'Charlie', 30, 40000, TO_DATE('2011-07-19', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (5, 'David', 20, 65000, TO_DATE('2013-09-25', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (6, 'Eve', 30, 45000, TO_DATE('2015-02-11', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (7, 'Frank', 10, 55000, TO_DATE('2016-11-30', 'YYYY-MM-DD'));

INSERT INTO employee (emp_id, emp_name, department_id, salary, hire_date) 
VALUES (8, 'Grace', 20, 75000, TO_DATE('2017-06-21', 'YYYY-MM-DD'));

1. Assigns a rank to each row within a partition, with gaps in ranking for ties.

SELECT emp_id, emp_name, department_id, salary,
       RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS rank
FROM employee;

2. Query to assign ranks to employees without gaps when there is a tie.

SELECT emp_id, emp_name, department_id, salary,
       DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS dense_rank
FROM employee;

3. Query to  return the salary of the next employee within the same department, ordered by descending salary.

SELECT emp_id, emp_name, department_id, salary,
       LEAD(salary, 1) OVER (PARTITION BY department_id ORDER BY salary DESC) AS next_salary
FROM employee;

4. Query to return the salary of the previous employee within the same department, ordered by descending salary.

SELECT emp_id, emp_name, department_id, salary,
       LAG(salary, 1) OVER (PARTITION BY department_id ORDER BY salary DESC) AS prev_salary
FROM employee;

5. Retrieve the top N highest-paid employees from each department.

SELECT emp_id, emp_name, department_id, salary,
       ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY salary DESC) AS row_num
FROM employee
WHERE row_num <= 3;

6. Employees with their rank within the company based on salary.

SELECT emp_id, emp_name, department_id, salary,
       RANK() OVER (ORDER BY salary DESC) AS company_rank
FROM employee;

7. Compare salary with the next employee's salary in the same department.

SELECT emp_id, emp_name, department_id, salary,
       LEAD(salary, 1) OVER (PARTITION BY department_id ORDER BY hire_date) AS next_salary
FROM employee;

8. Compare salary with the previous employee's salary in the same department.

SELECT emp_id, emp_name, department_id, salary,
       LAG(salary, 1) OVER (PARTITION BY department_id ORDER BY hire_date) AS prev_salary
FROM employee;

9. Set a default value for the previous salary if no previous row exists.

SELECT emp_id, emp_name, department_id, salary,
       LAG(salary, 1, 0) OVER (PARTITION BY department_id ORDER BY salary DESC) AS prev_salary
FROM employee;

---------------------------------------------------------------------------------------

Schema for items Table:

CREATE TABLE items (
    item_id NUMBER PRIMARY KEY,
    item_name VARCHAR2(100),
    category VARCHAR2(50),
    price NUMBER,
    stock_quantity NUMBER,
    date_added DATE
);

-- Insert data into items table
INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (1, 'Laptop', 'Electronics', 1000, 50, TO_DATE('2023-01-10', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (2, 'Smartphone', 'Electronics', 800, 200, TO_DATE('2023-02-15', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (3, 'Headphones', 'Electronics', 200, 150, TO_DATE('2023-03-20', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (4, 'Chair', 'Furniture', 150, 100, TO_DATE('2023-01-30', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (5, 'Table', 'Furniture', 500, 30, TO_DATE('2023-02-01', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (6, 'Couch', 'Furniture', 800, 20, TO_DATE('2023-04-01', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (7, 'Refrigerator', 'Appliances', 1200, 40, TO_DATE('2023-05-15', 'YYYY-MM-DD'));

INSERT INTO items (item_id, item_name, category, price, stock_quantity, date_added)
VALUES (8, 'Blender', 'Appliances', 150, 80, TO_DATE('2023-06-10', 'YYYY-MM-DD'));

1. Assigns a unique sequential number to each item in the items table, ordered by price (highest to lowest).

SELECT item_id, item_name, category, price, stock_quantity,
       ROW_NUMBER() OVER (ORDER BY price DESC) AS row_num
FROM items;

2. Ranks items within each category based on price, with gaps in ranking for ties.

SELECT item_id, item_name, category, price, stock_quantity,
       RANK() OVER (PARTITION BY category ORDER BY price DESC) AS rank
FROM items;

3. Shows the price of the next item in the same category when ordered by date_added.

SELECT item_id, item_name, category, price, stock_quantity,
       LEAD(price, 1) OVER (PARTITION BY category ORDER BY date_added) AS next_item_price
FROM items;

4. Shows the price of the previous item in the same category when ordered by date_added.

SELECT item_id, item_name, category, price, stock_quantity,
       LAG(price, 1) OVER (PARTITION BY category ORDER BY date_added) AS prev_item_price
FROM items;

5. Retrieve the top 3 most expensive items in each category.

SELECT item_id, item_name, category, price, stock_quantity,
       ROW_NUMBER() OVER (PARTITION BY category ORDER BY price DESC) AS row_num
FROM items
WHERE row_num <= 3;

6. Compare the price ranking for items across all categories.

SELECT item_id, item_name, category, price, stock_quantity,
       RANK() OVER (ORDER BY price DESC) AS overall_rank
FROM items;

7. Ranking the items across all categories based on their price without gaps.

SELECT item_id, item_name, category, price, stock_quantity,
       DENSE_RANK() OVER (ORDER BY price DESC) AS overall_dense_rank
FROM items;

8. Compare the price of an item with the price of the next item by stock_quantity in ascending order.

SELECT item_id, item_name, category, price, stock_quantity,
       LEAD(price, 1) OVER (ORDER BY stock_quantity) AS next_price_by_stock
FROM items;

9. Use LEAD() to track price increase or decrease between consecutive items based on date_added.

SELECT item_id, item_name, category, price, stock_quantity, date_added,
       LEAD(price, 1) OVER (ORDER BY date_added) AS next_item_price,
       CASE 
           WHEN price < LEAD(price, 1) OVER (ORDER BY date_added) THEN 'Price Increase'
           WHEN price > LEAD(price, 1) OVER (ORDER BY date_added) THEN 'Price Decrease'
           ELSE 'No Change'
       END AS price_trend
FROM items;

10.  Get the rank of items by price, but only for items that have more than a certain quantity in stock (e.g., stock > 50).

SELECT item_id, item_name, category, price, stock_quantity, date_added,
       ROW_NUMBER() OVER (ORDER BY price DESC) AS row_num
FROM items
WHERE stock_quantity > 50;

-------------------------------------------------------------------------------------------------------------------------------------------------------------
PERFORMANCE OPTIMIZATION

Performance optimization in Oracle is a broad topic, and there are several techniques and best practices that can be applied to improve the performance of Oracle queries, applications, and databases in general. Here are some of the key strategies:

1. Optimizing SQL Queries
The most common area for optimization is the SQL query itself. Here are some techniques for optimizing queries:

a. Use of Proper Indexing
Indexes are one of the most effective ways to improve query performance, but they need to be used wisely.

Create indexes on columns frequently used in WHERE clauses, JOIN conditions, or ORDER BY clauses.
Composite Indexes: If your query involves multiple columns in the WHERE or JOIN clause, consider creating a composite index.
Bitmap Indexes: For low cardinality columns (columns with few distinct values), bitmap indexes can be very efficient.
Avoid Too Many Indexes: Having too many indexes can degrade performance during insert, update, and delete operations, as indexes need to be updated. So, it's important to balance query optimization and data modification performance.

b. Avoid SELECT * (Wildcard)
Using SELECT * retrieves all columns from a table, which may lead to performance issues, especially when only a few columns are needed.

Select only the columns you need to minimize data retrieval and reduce I/O.

c. Use EXISTS vs. IN
For subqueries, EXISTS is often more efficient than IN because IN requires the subquery to return all matching rows before comparison, while EXISTS stops when a match is found.

-- Inefficient
SELECT * FROM orders WHERE customer_id IN (SELECT customer_id FROM customers WHERE city = 'New York');

-- Efficient
SELECT * FROM orders WHERE EXISTS (SELECT 1 FROM customers WHERE customers.customer_id = orders.customer_id AND city = 'New York');

d. Avoid Using Functions on Indexed Columns
When you use a function (e.g., TO_CHAR(), UPPER(), etc.) on an indexed column in the WHERE clause, Oracle cannot use the index efficiently. If possible, refactor the query to avoid applying functions on indexed columns.

-- Inefficient: Function on indexed column
SELECT * FROM employees WHERE UPPER(last_name) = 'SMITH';

-- Better: Avoid function on indexed column
SELECT * FROM employees WHERE last_name = 'Smith';

e. Optimize Joins
Joins can be resource-intensive, so it's important to write them efficiently:

Use proper join types: Use INNER JOIN if you're sure you only want matching rows; use LEFT JOIN only if necessary.
Join on indexed columns: Ensure that you're joining on indexed columns.
Filter early: Apply filtering conditions (WHERE clauses) as early as possible to reduce the dataset size for joins.

f. Optimize Aggregation
Aggregation can be expensive, especially on large datasets. To optimize aggregation:

Use grouping sets or rollup for multidimensional aggregation.
Minimize the data set before applying aggregation (e.g., filter data before applying GROUP BY).

SELECT department_id, AVG(salary) FROM employees WHERE salary > 50000 GROUP BY department_id;

2. Using Execution Plans
a. Analyze Query Execution Plan
Always analyze the execution plan for queries to identify performance bottlenecks.

Use EXPLAIN PLAN to get the execution plan for a query. This can help you understand how Oracle is executing the query and where optimizations are needed.

EXPLAIN PLAN FOR 
SELECT * FROM employees WHERE department_id = 10;

Look for Full Table Scans: If a query is performing a full table scan on large tables, consider adding appropriate indexes.
Join order: Check if the join order is optimal. You might need to re-write queries or use optimizer hints to help Oracle choose a better join order.
Access Path: Make sure that Oracle is using the best access path (e.g., using indexes instead of full table scans).

b. Use of Hints
Oracle allows you to direct the optimizer using hints to influence how a query is executed. For example, you can use the USE_NL hint to force Oracle to use a nested loop join.

SELECT /*+ USE_NL(a b) */ * FROM employees a, departments b WHERE a.department_id = b.department_id;

c. Use of AUTOTRACE
The AUTOTRACE feature provides a quick way to get the execution plan and the query statistics. You can enable it in SQL*Plus:

SET AUTOTRACE ON
SELECT * FROM employees WHERE department_id = 10;

3. Database Optimization Techniques
a. Table Partitioning
Large tables can be partitioned to improve query performance by splitting the table into smaller, more manageable pieces.

Range partitioning is useful for time-series data.
List partitioning is useful when dividing data based on specific values (e.g., regions or categories).
Composite partitioning can combine range and hash partitioning for complex datasets.

CREATE TABLE sales
  (sales_id INT, sale_date DATE, amount NUMBER)
  PARTITION BY RANGE (sale_date)
  (PARTITION q1 VALUES LESS THAN (TO_DATE('2022-04-01', 'YYYY-MM-DD')),
   PARTITION q2 VALUES LESS THAN (TO_DATE('2022-07-01', 'YYYY-MM-DD')));

b. Parallel Query Execution
For long-running queries on large datasets, enable parallel query execution to speed up the processing time.

Use the PARALLEL hint to enable parallelism for a query or index creation.

SELECT /*+ PARALLEL(emp 4) */ * FROM employees emp WHERE department_id = 10;

c. Use Materialized Views
Materialized views can store the results of complex queries, allowing faster retrieval without re-executing the query each time.

CREATE MATERIALIZED VIEW mv_sales_summary AS
SELECT department_id, SUM(sales_amount) AS total_sales
FROM sales
GROUP BY department_id;

d. Reduce the Number of Redundant Database Calls
Batch your DML operations: Instead of executing multiple INSERT statements one by one, try using bulk inserts or batch processing.
Use PL/SQL blocks to execute multiple operations together in a single round trip.

4. Index Optimization
a. Use Indexes Smartly
Use BITMAP indexes when working with low-cardinality columns.
Avoid over-indexing: Too many indexes can slow down DML operations.
Consider index compression for large tables.

b. Index Maintenance
Regularly rebuild indexes to optimize their performance, especially for tables that undergo frequent updates, deletes, or inserts.

ALTER INDEX idx_name REBUILD;

c. Avoid Function-based Indexes
Be cautious when using function-based indexes; they may not be used effectively by the optimizer if the function is applied to the column in queries.

5. Database Configuration and Tuning
a. Optimizing Database Parameters
Some important Oracle parameters for performance optimization are:

DB_CACHE_SIZE: Controls the size of the buffer cache.
PGA_AGGREGATE_TARGET: Controls the amount of memory available for the Program Global Area (PGA).
SGA_TARGET: Controls the size of the System Global Area (SGA).
SORT_AREA_SIZE: Controls the memory allocated for sorting operations.
CURSOR_SHARING: Set it to FORCE to reduce the number of unique cursors and improve shared cursor usage.

b. Use Automatic Storage Management (ASM)
Oracle's Automatic Storage Management (ASM) helps manage database storage efficiently, providing features like:

Striping and mirroring for better performance.
Simplified storage management.

c. Monitor and Tune Background Processes
Monitor Oracle background processes using tools like AWR, ASH, and ADDM:

AWR (Automatic Workload Repository) reports show system performance statistics, including CPU usage, memory usage, and wait events.
ASH (Active Session History) helps identify issues in active sessions and what they were waiting for.
ADDM (Automatic Database Diagnostic Monitor) can analyze the database performance and recommend improvements.

6. Caching and Data Access
a. Use Result Caching
For frequently accessed data, use result caching to store query results in memory.

SELECT /*+ RESULT_CACHE */ * FROM employees WHERE department_id = 10;

b. Database Buffer Cache
Increase the size of the database buffer cache to hold frequently accessed data.
Keep an eye on buffer cache hit ratio to make sure it is adequately sized.
Summary
Oracle provides a variety of methods for optimizing performance, ranging from query optimization (e.g., using indexes and avoiding functions on indexed columns) to database configuration and hardware optimizations (e.g., using parallel execution and partitioning).

To optimize performance effectively:

Analyze the execution plans for slow queries.
Make use of indexes, materialized views, and partitioning.
Regularly monitor performance metrics and use Oracle's diagnostic tools.
Adjust database configuration parameters for better resource utilization.
Optimizing Oracle performance is an ongoing process that involves continuous monitoring and fine-tuning as data and workloads grow.




Partitioning in Oracle

Partitioning in Oracle is a method of dividing large tables and indexes into smaller, more manageable pieces, called partitions, which can improve query performance, simplify management, and enhance availability. Partitioning is especially useful when dealing with large amounts of data because it allows for better I/O performance, parallel query execution, and easier data management.

Types of Partitioning in Oracle
Oracle provides several partitioning methods, each suitable for different types of data access patterns and use cases:

1. Range Partitioning
Range partitioning divides data based on a range of values in a column. This is useful when data has a natural range, such as time-based data (e.g., orders placed over a period of time).

Example: Partitioning a sales table by the sale_date column into different quarters.

CREATE TABLE sales (
    sale_id NUMBER,
    sale_date DATE,
    amount NUMBER
)
PARTITION BY RANGE (sale_date) (
    PARTITION p_q1 VALUES LESS THAN (TO_DATE('2023-04-01', 'YYYY-MM-DD')),
    PARTITION p_q2 VALUES LESS THAN (TO_DATE('2023-07-01', 'YYYY-MM-DD')),
    PARTITION p_q3 VALUES LESS THAN (TO_DATE('2023-10-01', 'YYYY-MM-DD')),
    PARTITION p_q4 VALUES LESS THAN (TO_DATE('2024-01-01', 'YYYY-MM-DD'))
);

How it works: Data is stored in partitions based on the value ranges. For example, rows with sale_date between 01-JAN-2023 and 31-MAR-2023 will go into partition p_q1.

Pros:
Good for time-series data.
Efficient for querying data within specific ranges (e.g., querying data for specific months or years).

2. List Partitioning
List partitioning divides data based on a set of discrete values. It is useful when data belongs to distinct categories (e.g., regions, departments, or countries).

Example: Partitioning a table of employees based on the region they work in.

CREATE TABLE employees (
    emp_id NUMBER,
    name VARCHAR2(100),
    region VARCHAR2(50)
)
PARTITION BY LIST (region) (
    PARTITION p_north VALUES ('North'),
    PARTITION p_south VALUES ('South'),
    PARTITION p_east VALUES ('East'),
    PARTITION p_west VALUES ('West')
);

How it works: Rows with a region of 'North' go into partition p_north, and so on for other values.

Pros:
Useful when data is categorized by specific discrete values.
Queries based on specific categories (e.g., retrieving employees from the North region) will be faster.

3. Hash Partitioning
Hash partitioning divides data using a hash function. This is particularly useful when the data is evenly distributed across partitions and does not have a natural range or set of discrete values.

Example: Partitioning a transactions table by the customer_id column to evenly distribute the rows.

CREATE TABLE transactions (
    transaction_id NUMBER,
    customer_id NUMBER,
    amount NUMBER
)
PARTITION BY HASH (customer_id) 
PARTITIONS 4;  -- Divide into 4 partitions

How it works: Oracle applies a hash function on the customer_id column to distribute the rows evenly across 4 partitions.

Pros:
Great for evenly distributed data without a natural range or list.
Provides load balancing when there are many unique values in the partitioning column.

4. Composite Partitioning
Composite partitioning combines multiple partitioning methods. It is used when both a range and a list or hash partitioning scheme are beneficial.

Example: Partitioning a sales table by sale_date (range) and then further partitioning it by region (list).

CREATE TABLE sales (
    sale_id NUMBER,
    sale_date DATE,
    region VARCHAR2(50),
    amount NUMBER
)
PARTITION BY RANGE (sale_date) 
SUBPARTITION BY LIST (region) (
    PARTITION p_q1 VALUES LESS THAN (TO_DATE('2023-04-01', 'YYYY-MM-DD'))
        (SUBPARTITION p_north VALUES ('North'), SUBPARTITION p_south VALUES ('South')),
    PARTITION p_q2 VALUES LESS THAN (TO_DATE('2023-07-01', 'YYYY-MM-DD'))
        (SUBPARTITION p_east VALUES ('East'), SUBPARTITION p_west VALUES ('West'))
);

How it works: The table is first partitioned by range (sale_date) into p_q1 and p_q2 partitions, and then further subdivided by the region column into subpartitions.

Pros:
Allows for more flexible partitioning strategies.
Helps with both range and category-based access patterns.

5. Reference Partitioning
Reference partitioning is used when two or more tables need to be partitioned in a consistent manner based on a foreign key relationship. This ensures that related rows in the child table are in the same partition as rows in the parent table.

Example: Partitioning a sales table based on salesperson_id and partitioning the corresponding sales_details table the same way using reference partitioning.

CREATE TABLE salespersons (
    salesperson_id NUMBER,
    name VARCHAR2(100)
)
PARTITION BY RANGE (salesperson_id) (
    PARTITION p_s1 VALUES LESS THAN (1000),
    PARTITION p_s2 VALUES LESS THAN (2000),
    PARTITION p_s3 VALUES LESS THAN (3000)
);

CREATE TABLE sales_details (
    detail_id NUMBER,
    salesperson_id NUMBER,
    sale_amount NUMBER
)
PARTITION BY REFERENCE (salespersons);

How it works: The sales_details table will be partitioned based on the salesperson_id in the salespersons table. This ensures that sales and their corresponding details are stored in the same partition.

Pros:
Ensures that related data in child tables is partitioned in the same way as the parent table.
Reduces complexity when managing related data.

6. Interval Partitioning
Interval partitioning is a special type of range partitioning where partitions are automatically created based on intervals of a given range. It's especially useful for time-series data where data is continuously being added.

Example: Partitioning a sales table by sale_date in monthly intervals.

CREATE TABLE sales (
    sale_id NUMBER,
    sale_date DATE,
    amount NUMBER
)
PARTITION BY RANGE (sale_date) 
INTERVAL (INTERVAL '1' MONTH) 
( PARTITION p_initial VALUES LESS THAN (TO_DATE('2023-01-01', 'YYYY-MM-DD')) );

How it works: Oracle creates partitions automatically for each new month (interval). The initial partition holds data before the specified cutoff (2023-01-01), and new partitions are created automatically for each new month.

Pros:
Automatically creates partitions for future data without requiring manual intervention.
Ideal for time-series data with continuous growth.

Advantages of Partitioning
Improved Query Performance:

Partition Pruning: Oracle can skip partitions that are not relevant to the query, improving query performance.
Parallel Query Execution: Partitioned tables allow for parallel execution, which speeds up queries on large tables.
Faster Data Management:

Data can be loaded, archived, or purged at the partition level, making maintenance operations easier and faster.
Partitioned tables can be split or merged without affecting the entire table.
Improved Availability:

Individual partitions can be managed separately (e.g., moved, backed up, or restored), increasing availability.
Partitioned tables can be used with Oracle Real Application Clusters (RAC) for scalability and high availability.
Better Data Compression:

Data in each partition can be compressed independently based on usage patterns or partition characteristics.

Best Practices for Partitioning in Oracle
Partition by a frequently used column: Ideally, the partition key should be a column that is frequently used in query filters (WHERE clauses).
Use composite partitioning carefully: Composite partitioning should be applied when you need both range and list partitioning benefits, but it adds complexity.
Monitor partitioning performance: Periodically review the performance of partitioned tables to ensure that partitioning strategies are still effective as data grows.
Manage partition size: Aim to create partitions of a manageable size. Too many small partitions can reduce performance, while too few large partitions can limit partition pruning efficiency.

------------------------------------------------------------------------
EXPLAIN PLAN

The EXPLAIN PLAN statement in Oracle is used to display the execution plan of a SQL query. It shows how Oracle intends to execute a given SQL statement, including which indexes, joins, and access paths will be used. This is an essential tool for database optimization, as it helps identify inefficient operations, such as full table scans or expensive joins, that could slow down query performance.

Steps for Using EXPLAIN PLAN
Generate the Execution Plan: Use the EXPLAIN PLAN statement to generate the execution plan for a given query.
View the Plan: Query the PLAN_TABLE to see the generated execution plan.
Analyze the Output: The execution plan provides details on how Oracle will execute the query, such as whether it will use an index scan, a full table scan, a join method, and so on.

Complete Example
1. Create a Sample Schema
Let's first create some sample tables for this example.

-- Create the employees table
CREATE TABLE employees (
    emp_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    department_id NUMBER,
    salary NUMBER
);

-- Insert some sample data into employees
INSERT INTO employees VALUES (1, 'John', 'Doe', 10, 5000);
INSERT INTO employees VALUES (2, 'Jane', 'Smith', 20, 6000);
INSERT INTO employees VALUES (3, 'Alice', 'Johnson', 10, 7000);
INSERT INTO employees VALUES (4, 'Bob', 'Brown', 20, 5500);
INSERT INTO employees VALUES (5, 'Charlie', 'Davis', 30, 8000);

-- Create the departments table
CREATE TABLE departments (
    department_id NUMBER PRIMARY KEY,
    department_name VARCHAR2(50)
);

-- Insert some sample data into departments
INSERT INTO departments VALUES (10, 'HR');
INSERT INTO departments VALUES (20, 'Finance');
INSERT INTO departments VALUES (30, 'Engineering');

2. Explain Plan for a Query
Now, let’s say we want to know the execution plan for a query that retrieves employees who earn more than 6000 and are from the 'HR' department.

-- Query to get employees from HR department with salary > 6000
EXPLAIN PLAN FOR
SELECT e.emp_id, e.first_name, e.last_name, e.salary, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.salary > 6000 AND d.department_name = 'HR';

3. View the Execution Plan
After running the EXPLAIN PLAN statement, Oracle stores the execution plan in a table called PLAN_TABLE. You can view the plan by querying the PLAN_TABLE.

-- Query the execution plan
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

Sample Output of the Execution Plan:

----------------------------------------------------------------------------------------
| Id  | Operation                     | Name          | Rows  | Bytes | Cost (%CPU)|
----------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT              |               |     2 |   340 |     4   (0)|
|   1 |  NESTED LOOPS                 |               |     2 |   340 |     4   (0)|
|   2 |   TABLE ACCESS FULL           | EMPLOYEES     |     2 |   160 |     3   (0)|
|   3 |   TABLE ACCESS BY INDEX ROWID | DEPARTMENTS   |     2 |   180 |     1   (0)|
|   4 |    INDEX RANGE SCAN           | DEPT_ID_PK    |     2 |       |     1   (0)|
----------------------------------------------------------------------------------------

4. Breakdown of the Execution Plan
Operation: The type of operation being performed (e.g., TABLE ACCESS FULL, NESTED LOOPS, INDEX RANGE SCAN).

Name: The name of the table or index involved in the operation.
Rows: The estimated number of rows returned by that operation.
Bytes: The estimated number of bytes read by the operation.
Cost (%CPU): The estimated cost of the operation, which is a relative number indicating the resources Oracle expects to use.

Explanation of the Sample Output:
Operation NESTED LOOPS: This indicates that a nested loop join is being used between employees and departments.
TABLE ACCESS FULL EMPLOYEES: This indicates a full table scan of the employees table.
TABLE ACCESS BY INDEX ROWID DEPARTMENTS: This indicates that Oracle is using the DEPARTMENTS table, accessing rows by ROWID.
INDEX RANGE SCAN DEPT_ID_PK: This indicates that Oracle is using an index on the department_id column (the primary key index) to look up the rows in the departments table.

5. Displaying Execution Plan for Multiple Queries
If you want to view multiple execution plans, you can use the EXPLAIN PLAN command for each query, but instead of querying the PLAN_TABLE directly, you can use the DBMS_XPLAN.DISPLAY function to make it easier.

-- Execute multiple EXPLAIN PLANs
EXPLAIN PLAN FOR
SELECT * FROM employees WHERE salary > 6000;

EXPLAIN PLAN FOR
SELECT * FROM departments WHERE department_name = 'HR';

-- Display the execution plans for all the queries
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);
6. Using EXPLAIN PLAN with Bind Variables
You can also use bind variables in EXPLAIN PLAN. For example:

VAR dept_name VARCHAR2(50);
EXEC :dept_name := 'HR';

EXPLAIN PLAN FOR
SELECT e.emp_id, e.first_name, e.last_name, e.salary, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.salary > 6000 AND d.department_name = :dept_name;

-- Display the execution plan
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

7. Using AUTOTRACE in SQL*Plus (Alternative to EXPLAIN PLAN)
In SQL*Plus or SQLcl, you can use the AUTOTRACE feature to display the execution plan along with the query result.

SET AUTOTRACE ON EXPLAIN;

SELECT e.emp_id, e.first_name, e.last_name, e.salary, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.salary > 6000 AND d.department_name = 'HR';

This command will display both the execution plan and the actual query output, which is helpful for quickly analyzing query performance.

Summary of Common Operations in EXPLAIN PLAN
Full Table Scan (TABLE ACCESS FULL): Indicates that Oracle will scan the entire table. This can be slow for large tables, and you may want to add indexes to improve performance.
Index Range Scan (INDEX RANGE SCAN): A more efficient way to retrieve rows from a table, especially when the query uses indexed columns.
Join Methods:
Nested Loops (NESTED LOOPS): A common join method used when the inner table is small or the join condition is indexed.
Hash Join (HASH JOIN): Used for large datasets, especially when no indexes are available.
Sort Operations (SORT): Indicates that data needs to be sorted before it can be processed, such as for an ORDER BY or DISTINCT.


Example 2: Query with Joins, Subqueries, and Index Usage
Let’s assume we have two tables: orders and customers. The orders table contains order information, and the customers table contains customer details. We want to query the orders of customers who have placed orders totaling more than $10,000.

1. Create Sample Tables and Insert Data
First, let's create the tables and insert some sample data:

-- Create the customers table
CREATE TABLE customers (
    customer_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    email VARCHAR2(100)
);

-- Insert data into customers table
INSERT INTO customers VALUES (1, 'Alice', 'Johnson', 'alice.johnson@example.com');
INSERT INTO customers VALUES (2, 'Bob', 'Smith', 'bob.smith@example.com');
INSERT INTO customers VALUES (3, 'Charlie', 'Davis', 'charlie.davis@example.com');

-- Create the orders table
CREATE TABLE orders (
    order_id NUMBER PRIMARY KEY,
    customer_id NUMBER,
    order_date DATE,
    total_amount NUMBER,
    CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers (customer_id)
);

-- Insert data into orders table
INSERT INTO orders VALUES (1001, 1, TO_DATE('2023-01-01', 'YYYY-MM-DD'), 12000);
INSERT INTO orders VALUES (1002, 2, TO_DATE('2023-02-01', 'YYYY-MM-DD'), 8000);
INSERT INTO orders VALUES (1003, 3, TO_DATE('2023-03-01', 'YYYY-MM-DD'), 15000);
INSERT INTO orders VALUES (1004, 1, TO_DATE('2023-04-01', 'YYYY-MM-DD'), 2000);
INSERT INTO orders VALUES (1005, 2, TO_DATE('2023-05-01', 'YYYY-MM-DD'), 5000);

2. Create Indexes (Optional but useful for query performance)
We'll create an index on the total_amount column of the orders table to improve performance, especially since we're querying based on order totals.

-- Create an index on the total_amount column of the orders table
CREATE INDEX idx_orders_total_amount ON orders (total_amount);

3. Write the Query
Now, we want to write a query that finds customers who have placed orders totaling more than $10,000. We’ll use a subquery to calculate the total amount per customer and then filter the customers who meet this condition.

-- Query to find customers with orders totaling more than $10,000

EXPLAIN PLAN FOR
SELECT c.customer_id, c.first_name, c.last_name, c.email
FROM customers c
WHERE c.customer_id IN (
    SELECT o.customer_id
    FROM orders o
    GROUP BY o.customer_id
    HAVING SUM(o.total_amount) > 10000
);

4. View the Execution Plan
After running the EXPLAIN PLAN statement, we can view the execution plan by querying the PLAN_TABLE using the DBMS_XPLAN.DISPLAY function.

-- View the execution plan
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

Sample Output of the Execution Plan:


----------------------------------------------------------------------------------------
| Id  | Operation                     | Name          | Rows  | Bytes | Cost (%CPU)|
----------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT              |               |     1 |    40 |     4   (0)|
|   1 |  FILTER                       |               |       |       |            |
|   2 |   INLIST ITERATOR             |               |     3 |    60 |     2   (0)|
|   3 |    HASH GROUP BY              |               |     3 |    60 |     2   (0)|
|   4 |     TABLE ACCESS FULL         | ORDERS        |    10 |   200 |     2   (0)|
----------------------------------------------------------------------------------------

5. Breakdown of the Execution Plan
Operation SELECT STATEMENT: This is the top-level operation, representing the overall query.

Operation FILTER: The filter step represents the IN subquery. It filters the rows from the outer query (customers) based on the customer IDs returned by the subquery.

Operation INLIST ITERATOR: This is used for processing the IN condition. It iterates over the customer IDs from the subquery result and returns the matching rows from the outer query (customers).

Operation HASH GROUP BY: The HASH GROUP BY operation is used to group the orders by customer_id in the subquery and calculate the SUM(total_amount) for each group.

Operation TABLE ACCESS FULL: This indicates a full table scan of the orders table. Since there is no index on customer_id or total_amount in the orders table for this query, Oracle performs a full scan to aggregate the order totals.

6. Optimizing the Query
We can optimize the query by creating an index on the customer_id column in the orders table to speed up the grouping and filtering process. Let’s create the index:

-- Create an index on customer_id in the orders table

CREATE INDEX idx_orders_customer_id ON orders (customer_id);

Now, if we run the same query with EXPLAIN PLAN, the execution plan might change to use the newly created index for a more efficient lookup.

7. Running the Query with Optimizations
After creating the index, rerun the EXPLAIN PLAN and check for changes in the execution plan. The TABLE ACCESS might change to an INDEX RANGE SCAN or INDEX FULL SCAN instead of a full table scan, making the query more efficient.

Summary of Operations in the Execution Plan:
Full Table Scan (TABLE ACCESS FULL): This operation scans the entire table without using an index. Full table scans are generally slower for large tables.

Inlist Iterator (INLIST ITERATOR): This is used when processing an IN condition. It matches rows based on the list generated by a subquery.

Group By (HASH GROUP BY): The grouping operation used to calculate aggregate values such as SUM(). Oracle chooses hash-based grouping for large datasets.

Filter (FILTER): Represents a filtering condition in the query, in this case, the IN operator.

----------------------------------------------------------------------------

HINTS

In Oracle, hints are special instructions that you can embed in your SQL queries to guide the Oracle optimizer in choosing a specific execution plan. Hints can be used to influence various aspects of the execution plan, such as the join method, access path, or the use of specific indexes. Using hints is a powerful way to optimize query performance when the Oracle optimizer does not automatically choose the most efficient plan.

Example: Using Hints in Oracle
Let's walk through a complete example that demonstrates how to use hints in Oracle to optimize a query's execution plan.

1. Create Sample Tables and Insert Data
We'll first create two sample tables: customers and orders. The customers table contains customer data, and the orders table contains order information.

-- Create the customers table
CREATE TABLE customers (
    customer_id NUMBER PRIMARY KEY,
    first_name VARCHAR2(50),
    last_name VARCHAR2(50),
    email VARCHAR2(100)
);

-- Insert data into the customers table
INSERT INTO customers VALUES (1, 'Alice', 'Johnson', 'alice.johnson@example.com');
INSERT INTO customers VALUES (2, 'Bob', 'Smith', 'bob.smith@example.com');
INSERT INTO customers VALUES (3, 'Charlie', 'Davis', 'charlie.davis@example.com');
INSERT INTO customers VALUES (4, 'David', 'Wilson', 'david.wilson@example.com');

-- Create the orders table
CREATE TABLE orders (
    order_id NUMBER PRIMARY KEY,
    customer_id NUMBER,
    order_date DATE,
    total_amount NUMBER,
    CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES customers (customer_id)
);

-- Insert data into the orders table
INSERT INTO orders VALUES (1001, 1, TO_DATE('2023-01-01', 'YYYY-MM-DD'), 12000);
INSERT INTO orders VALUES (1002, 2, TO_DATE('2023-02-01', 'YYYY-MM-DD'), 8000);
INSERT INTO orders VALUES (1003, 3, TO_DATE('2023-03-01', 'YYYY-MM-DD'), 15000);
INSERT INTO orders VALUES (1004, 4, TO_DATE('2023-04-01', 'YYYY-MM-DD'), 2000);
INSERT INTO orders VALUES (1005, 1, TO_DATE('2023-05-01', 'YYYY-MM-DD'), 5000);

2. Query to Join Tables (Without Any Hints)
Let's write a query that retrieves the customers and their orders. This query will join the customers and orders tables and calculate the total amount spent by each customer.


SELECT c.customer_id, c.first_name, c.last_name, SUM(o.total_amount) AS total_spent
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.first_name, c.last_name;

3. Using EXPLAIN PLAN (Without Hints)
Before applying any hints, let's generate the execution plan to see how Oracle handles the query:

EXPLAIN PLAN FOR
SELECT c.customer_id, c.first_name, c.last_name, SUM(o.total_amount) AS total_spent
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.first_name, c.last_name;

-- View the execution plan
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

Sample Execution Plan (Without Hints):

-------------------------------------------------------------------------------------
| Id  | Operation                  | Name         | Rows  | Bytes | Cost (%CPU) |
-------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT           |              |     4 |   240 |     3   (0) |
|   1 |  HASH GROUP BY             |              |     4 |   240 |     3   (0) |
|   2 |   NESTED LOOPS             |              |     4 |   240 |     2   (0) |
|   3 |    TABLE ACCESS FULL       | CUSTOMERS    |     4 |    60 |     1   (0) |
|   4 |    TABLE ACCESS BY INDEX ROWID | ORDERS    |    10 |   200 |     1   (0) |
|   5 |     INDEX RANGE SCAN       | FK_CUSTOMER  |    10 |       |     1   (0) |
-------------------------------------------------------------------------------------
In this plan:

Table Access Full (CUSTOMERS): A full table scan is performed on the customers table.
Index Range Scan (FK_CUSTOMER): Oracle uses an index (FK_CUSTOMER) to access the orders table based on customer_id.
This plan seems reasonable, but let's say we want to force the optimizer to use an index on customers instead of doing a full table scan, as the table might grow larger over time.

4. Using a Hint to Force Index Usage
Oracle allows you to specify hints in the SQL query to suggest or force the optimizer to use a particular access path or join method. Here’s how to modify the query to force Oracle to use an index scan on the customers table instead of a full table scan.


SELECT /*+ INDEX(customers idx_customers_customer_id) */ 
       c.customer_id, c.first_name, c.last_name, SUM(o.total_amount) AS total_spent
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.first_name, c.last_name;

5. Using EXPLAIN PLAN with the Hint
Now, let's run EXPLAIN PLAN again to check if the index is being used:

EXPLAIN PLAN FOR
SELECT /*+ INDEX(customers idx_customers_customer_id) */ 
       c.customer_id, c.first_name, c.last_name, SUM(o.total_amount) AS total_spent
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.first_name, c.last_name;

-- View the execution plan
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

Sample Execution Plan (With the Hint):

-------------------------------------------------------------------------------------
| Id  | Operation                  | Name         | Rows  | Bytes | Cost (%CPU) |
-------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT           |              |     4 |   240 |     3   (0) |
|   1 |  HASH GROUP BY             |              |     4 |   240 |     3   (0) |
|   2 |   NESTED LOOPS             |              |     4 |   240 |     2   (0) |
|   3 |    INDEX RANGE SCAN        | IDX_CUSTOMERS |     4 |    60 |     1   (0) |
|   4 |    TABLE ACCESS BY INDEX ROWID | ORDERS    |    10 |   200 |     1   (0) |
|   5 |     INDEX RANGE SCAN       | FK_CUSTOMER  |    10 |       |     1   (0) |
-------------------------------------------------------------------------------------
INDEX RANGE SCAN (IDX_CUSTOMERS): The index idx_customers_customer_id is now being used to scan the customers table, as requested by the hint.

6. Using Other Hints for Join Methods
You can also use hints to influence the join method. For instance, let's try using a MERGE JOIN hint to specify that Oracle should use the merge join method rather than a nested loop join.

SELECT /*+ USE_MERGE(c o) */ 
       c.customer_id, c.first_name, c.last_name, SUM(o.total_amount) AS total_spent
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.first_name, c.last_name;
This hint tells Oracle to use the merge join method between customers and orders.

7. Common Hints in Oracle
Here are some commonly used Oracle hints:

INDEX(table_name index_name): Forces the use of a specific index.
FULL(table_name): Forces a full table scan.
NESTED LOOPS: Forces a nested loops join method.
HASH JOIN: Forces a hash join method.
MERGE JOIN: Forces a merge join method.
USE_NL(table1 table2): Forces the optimizer to use a nested loop join between two tables.
LEADING(table1 table2): Forces the optimizer to join the specified tables in the given order.
PARALLEL: Enables parallel query execution.

Conclusion
Hints are a powerful feature in Oracle that allows you to influence the optimizer’s decision-making process to improve query performance. However, using hints should be done cautiously and sparingly, as they can override the optimizer’s decisions, which may lead to less optimal plans in different situations or as data distribution changes over time.

In this example, we:

Used the INDEX hint to force Oracle to use a specific index.
Analyzed the execution plan before and after applying the hint to ensure it had the desired effect.
Mentioned other useful hints such as HASH JOIN, MERGE JOIN, and NESTED LOOPS.

-----------------------------------------------------------------------------------------------------------------------------------------------------------





	




